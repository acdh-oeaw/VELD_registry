veld_data__akp_ner_linkedcat___linkedcat___veld.yaml:
  url: https://github.com/veldhub/veld_data__akp_ner_linkedcat/blob/main/linkedcat/veld.yaml
  content:
    x-veld:
      data:
        file_type: csv
        description: "Prefered dataset is not this one, but linkedcat2! This dataset\
          \ was created by applying a custom trained SpaCy NER model an APIS / \xD6\
          BL data, on data set 'linkedcat2' at our solr index. The csv file is split\
          \ into id column, character start index of recognized entity, character\
          \ end index of entity, label of entity type, and a small context window."
        topic:
        - NLP
        - Named Entity Recognition
        content:
        - NER data
        - inferenced NLP data
veld_data__akp_ner_linkedcat___linkedcat2___veld.yaml:
  url: https://github.com/veldhub/veld_data__akp_ner_linkedcat/blob/main/linkedcat2/veld.yaml
  content:
    x-veld:
      data:
        file_type: csv
        description: "Prefered dataset is this one, not linkedcat! This dataset was\
          \ created by applying a custom trained SpaCy NER model an APIS / \xD6BL\
          \ data, on data set 'linkedcat2' at our solr index. The csv file is split\
          \ into id column, character start index of recognized entity, character\
          \ end index of entity, label of entity type, and a small context window."
        topic:
        - NLP
        - Named Entity Recognition
        content:
        - NER data
        - inferenced NLP data
veld_data__amc_we_training_data___203_vert_rftt_inhalt_nodup___veld.yaml:
  url: https://github.com/veldhub/veld_data__amc_we_training_data/blob/main/203_vert_rftt_inhalt_nodup/veld.yaml
  content:
    x-veld:
      data:
        description: 'Entire AMC: no metadata, only text, one sentence per line; Created
          by Hannes Pirker.'
        file_type: txt
        content:
        - raw text
        - newspaper texts
        topic: NLP
        additional:
          data size: 63G
          number of lines: 652802789
veld_data__amc_we_training_data___203_vert_rftt_inhalt_nodup__uniq___veld.yaml:
  url: https://github.com/veldhub/veld_data__amc_we_training_data/blob/main/203_vert_rftt_inhalt_nodup__uniq/veld.yaml
  content:
    x-veld:
      data:
        description: 'Entire AMC: no metadata, only text, one sentence per line, each
          sentence made unique by ordering AMC sentences alphabetically and removing
          dupcliates; Created by Hannes Pirker.'
        file_type: txt
        content:
        - raw text
        - newspaper texts
        topic: NLP
        additional:
          data size: 58G
          number of lines: 521785159
veld_data__amc_we_training_data___203_vert_rftt_inhalt_nodup__uniq__stripped___veld.yaml:
  url: https://github.com/veldhub/veld_data__amc_we_training_data/blob/main/203_vert_rftt_inhalt_nodup__uniq__stripped/veld.yaml
  content:
    x-veld:
      data:
        description: 'Entire AMC: unique sentence data, cleaned from non-alphanumeric
          junk before ''A'' (anything before line number 54,993) and after ''Z'' (anything
          after line number 521,781,020)'
        file_type: txt
        content:
        - raw text
        - newspaper texts
        topic: NLP
        additional:
          data size: 58G
          number of lines: 521726028
veld_data__amc_we_training_data___203_vert_rftt_inhalt_nodup__uniq__stripped__lowercased___veld.yaml:
  url: https://github.com/veldhub/veld_data__amc_we_training_data/blob/main/203_vert_rftt_inhalt_nodup__uniq__stripped__lowercased/veld.yaml
  content:
    x-veld:
      data:
        description: 'Entire AMC: unique sentences, stripped from non-alphanumeric
          lines, lowercased.'
        file_type: txt
        content:
        - raw text
        - newspaper texts
        topic: NLP
        additional:
          data size: 58G
          number of lines: 521726064
veld_data__amc_we_training_data___203_vert_rftt_inhalt_nodup__uniq__stripped__lowercased__punctuation_removed___veld.yaml:
  url: https://github.com/veldhub/veld_data__amc_we_training_data/blob/main/203_vert_rftt_inhalt_nodup__uniq__stripped__lowercased__punctuation_removed/veld.yaml
  content:
    x-veld:
      data:
        description: 'Entire AMC: unique sentences, stripped from non-alphanumeric
          lines, lowercased, punctuation removed.'
        file_type: txt
        content:
        - raw text
        - newspaper texts
        topic: NLP
        additional:
          data size: 56G
          number of lines: 521726064
? veld_data__amc_we_training_data___203_vert_rftt_inhalt_nodup__uniq__stripped__lowercased__punctuation_removed__cleaned___veld.yaml
: url: https://github.com/veldhub/veld_data__amc_we_training_data/blob/main/203_vert_rftt_inhalt_nodup__uniq__stripped__lowercased__punctuation_removed__cleaned/veld.yaml
  content:
    x-veld:
      data:
        description: 'Entire AMC: unique sentences, stripped from non-alphanumeric
          lines, lowercased, punctuation removed, removed sentences with too many
          non-alphanumeric characters.'
        file_type: txt
        content:
        - raw text
        - newspaper texts
        topic: NLP
        path: data.txt
        additional:
          data size: 54G
          number of lines: 485820330
          min_percentage_char: 80
veld_data__amc_we_training_data___203_vert_rftt_inhalt_nodup__uniq__stripped__sampled___veld.yaml:
  url: https://github.com/veldhub/veld_data__amc_we_training_data/blob/main/203_vert_rftt_inhalt_nodup__uniq__stripped__sampled/veld.yaml
  content:
    x-veld:
      data:
        description: '10% AMC: stripped from non-alphanumeric lines, 10% sampled.'
        file_type: txt
        content:
        - raw text
        - newspaper texts
        topic: NLP
        additional:
          data size: 5.8G
          number of lines: 52172602
          percentage_sample: 10.0
          sample_random_seed: '42'
veld_data__amc_we_training_data___203_vert_rftt_inhalt_nodup__uniq__stripped__sampled__lowercased___veld.yaml:
  url: https://github.com/veldhub/veld_data__amc_we_training_data/blob/main/203_vert_rftt_inhalt_nodup__uniq__stripped__sampled__lowercased/veld.yaml
  content:
    x-veld:
      data:
        description: '10% AMC: stripped from non-alphanumeric lines, 10% sampled,
          lowercased.'
        file_type: txt
        content:
        - raw text
        - newspaper texts
        topic: NLP
        additional:
          data size: 5.8G
          number of lines: 52172602
? veld_data__amc_we_training_data___203_vert_rftt_inhalt_nodup__uniq__stripped__sampled__lowercased__punctuation_removed___veld.yaml
: url: https://github.com/veldhub/veld_data__amc_we_training_data/blob/main/203_vert_rftt_inhalt_nodup__uniq__stripped__sampled__lowercased__punctuation_removed/veld.yaml
  content:
    x-veld:
      data:
        description: '10% AMC: stripped from non-alphanumeric lines, 10% sampled,
          lowercased, punctuation removed.'
        file_type: txt
        content:
        - raw text
        - newspaper texts
        topic: NLP
        additional:
          data size: 5.6G
          number of lines: 52172610
? veld_data__amc_we_training_data___203_vert_rftt_inhalt_nodup__uniq__stripped__sampled__lowercased__punctuation_removed__cleaned___veld.yaml
: url: https://github.com/veldhub/veld_data__amc_we_training_data/blob/main/203_vert_rftt_inhalt_nodup__uniq__stripped__sampled__lowercased__punctuation_removed__cleaned/veld.yaml
  content:
    x-veld:
      data:
        description: '10% AMC: stripped from non-alphanumeric lines, 10% sampled,
          lowercased, punctuation removed, removed sentences with too many non-alphanumeric
          characters.'
        file_type: txt
        content:
        - raw text
        - newspaper texts
        topic: NLP
        path: data.txt
        additional:
          data size: 5.4G
          number of clean lines: 48582220
          number of dirty removed lines: 3590390
          minimum number of characters in percentage of each line: 80.0
veld_data__apis_oebl__ner_gold___data_cleaned___veld.yaml:
  url: https://github.com/veldhub/veld_data__apis_oebl__ner_gold/blob/main/data_cleaned/veld.yaml
  content:
    x-veld:
      data:
        file_type: json
        description: Overlapping entities are removed, index offsets corrected, and
          duplicates removed. Also texts without any entities are removed too, since
          it's not known if they don't contain any entities (which often is not true;
          quite a few of them contain entities) or if the annotators simply didn't
          go through them (which is more likely, hence they were removed). In the
          original uncleaned data, some entity types are suffixed with numbers (e.g.
          `PER-1337`). These were used for identifying entities in a project context,
          but are probably of less use for NER NLP training. This dataset keeps the
          identifiers.
        content:
        - gold data
        - NER gold data
        - NLP gold data
        topic:
        - NLP
        - Named Entity Recognition
        additional:
          total count of entities: 26364
          individual count of entities:
            ORG: 5256
            ORG-5398: 847
            PER: 3637
            PER-5421: 146
            PER-5420: 2120
            PER-5422: 21
            LOC: 5224
            LOC-5388: 1808
            PER-5424: 144
            PER-5418: 1077
            ORG-5611: 592
            LOC-5391: 925
            PER-5715: 35
            LOC-5399: 325
            ORG-5622: 585
            ORG-5642: 670
            ORG-5630: 28
            PER-5412: 589
            PER-5414: 127
            PER-5413: 214
            ORG-5682: 10
            PER-5432: 324
            LOC-5390: 333
            ORG-5686: 43
            ORG-5689: 58
            ORG-5657: 52
            ORG-5791: 3
            ORG-5697: 70
            ORG-5612: 75
            PER-5775: 109
            ORG-5634: 67
            ORG-5648: 16
            ORG-5395: 1
            ORG-5683: 61
            PER-5411: 80
            ORG-5776: 12
            ORG-5675: 13
            PER-5781: 57
            ORG-5658: 69
            ORG-5643: 5
            ORG-5616: 17
            ORG-5679: 6
            ORG-5396: 31
            PER-5428: 34
            PER-5769: 2
            PER-5415: 58
            ORG-5667: 7
            PER-5801: 6
            PER-5800: 16
            ORG-5812: 1
            PER-5417: 97
            ORG-5660: 3
            PER-5423: 7
            ORG-5806: 8
            ORG-5677: 54
            ORG-5760: 7
            ORG-5688: 7
            ORG-5662: 22
            PER-5783: 8
            ORG-5690: 10
            ORG-5652: 1
            ORG-5646: 20
            ORG-5691: 3
            ORG-5613: 3
            ORG-5792: 8
            LOC-5787: 3
            ORG-5645: 9
            LOC-5403: 1
            ORG-5659: 6
            LOC-5400: 2
            ORG-5610: 5
            ORG-5651: 1
            ORG-5777: 2
            ORG-5617: 2
            ORG-5618: 2
            ORG-5778: 4
            PER-5785: 5
            ORG-5631: 7
            ORG-5701: 1
            ORG-5656: 2
            PER-5759: 1
            ORG-5624: 3
            PER-5430: 5
            ORG-5621: 1
            ORG-5640: 6
            LOC-5401: 2
            ORG-5676: 3
            ORG-5639: 4
            ORG-5674: 3
            PER-5416: 1
            LOC-5392: 1
            LOC-5402: 2
            ORG-5654: 4
            ORG-5620: 1
            ORG-5672: 5
            ORG-5879: 1
            PER-5425: 3
            ORG-5698: 2
veld_data__apis_oebl__ner_gold___data_cleaned_simplified___veld.yaml:
  url: https://github.com/veldhub/veld_data__apis_oebl__ner_gold/blob/main/data_cleaned_simplified/veld.yaml
  content:
    x-veld:
      data:
        file_type: json
        description: Same as the cleaned data, but with simplified entities (e.g.
          `PER` instead of `PER-1337`). Probably it's best to use this data set for
          NER training.
        content:
        - gold data
        - NER gold data
        - NLP gold data
        topic:
        - NLP
        - Named Entity Recognition
        additional:
          total count of entities: 14313
          individual count of entities:
            ORG: 5356
            PER: 3698
            LOC: 5259
veld_data__apis_oebl__ner_gold___data_uncleaned___veld.yaml:
  url: https://github.com/veldhub/veld_data__apis_oebl__ner_gold/blob/main/data_uncleaned/veld.yaml
  content:
    x-veld:
      data:
        file_type: json
        description: "The original, but united, data coming from APIS / \xD6BL."
        content:
        - gold data
        - NER gold data
        - NLP gold data
        topic:
        - NLP
        - Named Entity Recognition
        additional:
          total count of entities: 27729
          individual count of entities:
            ORG: 5620
            ORG-5398: 848
            PER: 3637
            PER-5421: 146
            PER-5420: 2120
            PER-5422: 21
            LOC: 6224
            LOC-5388: 1808
            PER-5424: 144
            PER-5418: 1077
            ORG-5611: 592
            LOC-5391: 925
            PER-5715: 35
            LOC-5399: 325
            ORG-5622: 585
            ORG-5642: 670
            ORG-5630: 28
            PER-5412: 589
            PER-5414: 127
            PER-5413: 214
            ORG-5682: 10
            PER-5432: 324
            LOC-5390: 333
            ORG-5686: 43
            ORG-5689: 58
            ORG-5657: 52
            ORG-5791: 3
            ORG-5697: 70
            ORG-5612: 75
            PER-5775: 109
            ORG-5634: 67
            ORG-5648: 16
            ORG-5395: 1
            ORG-5683: 61
            PER-5411: 80
            ORG-5776: 12
            ORG-5675: 13
            PER-5781: 57
            ORG-5658: 69
            ORG-5643: 5
            ORG-5616: 17
            ORG-5679: 6
            ORG-5396: 31
            PER-5428: 34
            PER-5769: 2
            PER-5415: 58
            ORG-5667: 7
            PER-5801: 6
            PER-5800: 16
            ORG-5812: 1
            PER-5417: 97
            ORG-5660: 3
            PER-5423: 7
            ORG-5806: 8
            ORG-5677: 54
            ORG-5760: 7
            ORG-5688: 7
            ORG-5662: 22
            PER-5783: 8
            ORG-5690: 10
            ORG-5652: 1
            ORG-5646: 20
            ORG-5691: 3
            ORG-5613: 3
            ORG-5792: 8
            LOC-5787: 3
            ORG-5645: 9
            LOC-5403: 1
            ORG-5659: 6
            LOC-5400: 2
            ORG-5610: 5
            ORG-5651: 1
            ORG-5777: 2
            ORG-5617: 2
            ORG-5618: 2
            ORG-5778: 4
            PER-5785: 5
            ORG-5631: 7
            ORG-5701: 1
            ORG-5656: 2
            PER-5759: 1
            ORG-5624: 3
            PER-5430: 5
            ORG-5621: 1
            ORG-5640: 6
            LOC-5401: 2
            ORG-5676: 3
            ORG-5639: 4
            ORG-5674: 3
            PER-5416: 1
            LOC-5392: 1
            LOC-5402: 2
            ORG-5654: 4
            ORG-5620: 1
            ORG-5672: 5
            ORG-5879: 1
            PER-5425: 3
            ORG-5698: 2
veld_data__apis_spacy_ner_models___m1___model-best___veld.yaml:
  url: https://github.com/veldhub/veld_data__apis_spacy_ner_models/blob/main/m1/model-best/veld.yaml
  content:
    x-veld:
      data:
        file_type: spaCy model
        content:
        - spaCy model
        - NLP model
        additional:
          performance:
            ents_f: 0.7800650054
            ents_p: 0.7831762146
            ents_r: 0.7769784173
            ents_per_type:
              LOC:
                p: 0.8150943396
                r: 0.8105065666
                f: 0.8127939793
              ORG:
                p: 0.7168674699
                r: 0.698630137
                f: 0.7076313181
              PER:
                p: 0.8290598291
                r: 0.8410404624
                f: 0.8350071736
            tok2vec_loss: 102.1628509774
            ner_loss: 3583.9829101562
veld_data__apis_spacy_ner_models___m2___model-best___veld.yaml:
  url: https://github.com/veldhub/veld_data__apis_spacy_ner_models/blob/main/m2/model-best/veld.yaml
  content:
    x-veld:
      data:
        file_type: spaCy model
        content:
        - spaCy model
        - NLP model
        additional:
          performance:
            ents_f: 0.7813646368
            ents_p: 0.7971556886
            ents_r: 0.7661870504
            ents_per_type:
              LOC:
                p: 0.8352713178
                r: 0.808630394
                f: 0.8217349857
              ORG:
                p: 0.7250996016
                r: 0.7123287671
                f: 0.7186574531
              PER:
                p: 0.8490566038
                r: 0.7803468208
                f: 0.813253012
            tok2vec_loss: 120.6995862189
            ner_loss: 3537.5532226562
veld_data__demo_inference_input_ts-vienna-2024___veld.yaml:
  url: https://github.com/veldhub/veld_data__demo_inference_input_ts-vienna-2024/blob/main/veld.yaml
  content:
    x-veld:
      data:
        file_type: txt
        description: A single txt file, used as inference input to a self-trained
          updipe model as a demonstration
        topic:
        - NLP
        - Universal Dependencies
        content:
        - raw text
veld_data__demo_train_data_ts-vienna-2024___veld.yaml:
  url: https://github.com/veldhub/veld_data__demo_train_data_ts-vienna-2024/blob/main/veld.yaml
  content:
    x-veld:
      data:
        file_type: conllu
        description: A single conllu file, used to train a updipe model as a demonstration
        topic:
        - NLP
        - Universal Dependencies
        content:
        - linguistically enriched text
        - tokenized text
        - lemmatized text
veld_data__eltec_conllu_stats___veld.yaml:
  url: https://github.com/veldhub/veld_data__eltec_conllu_stats/blob/main/veld.yaml
  content:
    x-veld:
      data:
        description: eltec analysis on its conllu data inferenced with udpipe
        file_type: json
        content:
        - statistics
        - linguistic data
        - annotated literature
        topic:
        - NLP
        - Tokenization
        - Lemmatization
        - Part Of Speech
        - Dependency Parsing
        - Universal Dependencies
        - Grammatical Annotation
veld_data__eltec_original_selection___veld.yaml:
  url: https://github.com/veldhub/veld_data__eltec_original_selection/blob/main/veld.yaml
  content:
    x-veld:
      data:
        description: parent git repo that integrates various ELTeC corpora as submodules
          for downstream processing.
        file_type: xml
        content:
        - TEI
        - annotated literature
veld_data__fasttext_models___m1___veld.yaml:
  url: https://github.com/veldhub/veld_data__fasttext_models/blob/main/m1/veld.yaml
  content:
    x-veld:
      data:
        description: test training
        file_type: fastText model
        topic:
        - NLP
        - Word Embeddings
        additional:
          model_id: m1
          train_data_description: sample wikipedia, single txt, one sentence per line,
            lowercased, removed punctuation
          training_architecture: fasttext
          train_data_size: 686M
          train_data_md5_hash: 05e9002eeaab646a6d82af02eaf86a13
          training_epochs: 10
          training_vector_size: 200
          training_window_size: 5
          training_duration (minutes): 37.4
          model_data_size: 4.0G
veld_data__fasttext_models___m3___veld.yaml:
  url: https://github.com/veldhub/veld_data__fasttext_models/blob/main/m3/veld.yaml
  content:
    x-veld:
      data:
        description: 10% AMC model
        file_type: fastText model
        topic:
        - NLP
        - Word Embeddings
        additional:
          model_id: m3
          train_data_description: 'AMC data: stripped from non-alphanumeric lines,
            10% sampled, lowercased, punctuation removed, cleaned from lines not having
            enough text'
          training_architecture: fasttext
          train_data_size: 5.4G
          train_data_md5_hash: 33167f260dbf99fa3ceebc3563302954
          training_epochs: 10
          training_vector_size: 200
          training_window_size: 5
          training_duration (minutes): 317.3
          model_data_size: 3.9G
veld_data__fasttext_models___m4___veld.yaml:
  url: https://github.com/veldhub/veld_data__fasttext_models/blob/main/m4/veld.yaml
  content:
    x-veld:
      data:
        description: 10% AMC model
        file_type: fastText model
        topic:
        - NLP
        - Word Embeddings
        additional:
          model_id: m4
          train_data_description: 'AMC data: stripped from non-alphanumeric lines,
            10% sampled, lowercased, punctuation removed, cleaned from lines not having
            enough text'
          training_architecture: fasttext
          train_data_size: 5.4G
          train_data_md5_hash: 33167f260dbf99fa3ceebc3563302954
          training_epochs: 50
          training_vector_size: 200
          training_window_size: 5
          training_duration (minutes): 1585
          model_data_size: 3.9G
veld_data__fasttext_models___m5___veld.yaml:
  url: https://github.com/veldhub/veld_data__fasttext_models/blob/main/m5/veld.yaml
  content:
    x-veld:
      data:
        description: 10% AMC model
        file_type: fastText model
        topic:
        - NLP
        - Word Embeddings
        additional:
          model_id: m5
          train_data_description: 'AMC data: stripped from non-alphanumeric lines,
            10% sampled, lowercased, punctuation removed, cleaned from lines not having
            enough text'
          training_architecture: fasttext
          train_data_size: 5.4G
          train_data_md5_hash: 33167f260dbf99fa3ceebc3563302954
          training_epochs: 10
          training_vector_size: 300
          training_window_size: 5
          training_duration (minutes): 393.1
          model_data_size: 5.8G
veld_data__fasttext_models___m6___veld.yaml:
  url: https://github.com/veldhub/veld_data__fasttext_models/blob/main/m6/veld.yaml
  content:
    x-veld:
      data:
        description: 100% AMC model
        file_type: fastText model
        topic:
        - NLP
        - Word Embeddings
        additional:
          model_id: m6
          train_data_description: null
          training_architecture: fasttext
          train_data_size: 54G
          train_data_md5_hash: 7e9b50396f77babeef827beff7e506ef
          training_epochs: 10
          training_vector_size: 300
          training_window_size: 5
          training_duration (minutes): 4731
          model_data_size: 18G
veld_data__fasttext_models___m7___veld.yaml:
  url: https://github.com/veldhub/veld_data__fasttext_models/blob/main/m7/veld.yaml
  content:
    x-veld:
      data:
        description: 100% AMC model
        file_type: fastText model
        topic:
        - NLP
        - Word Embeddings
        additional:
          model_id: m7
          train_data_description: null
          training_architecture: fasttext
          train_data_size: 54G
          train_data_md5_hash: 7e9b50396f77babeef827beff7e506ef
          training_epochs: 10
          training_vector_size: 200
          training_window_size: 5
          training_duration (minutes): 3380
          model_data_size: 12G
veld_data__fasttext_models___m8___veld.yaml:
  url: https://github.com/veldhub/veld_data__fasttext_models/blob/main/m8/veld.yaml
  content:
    x-veld:
      data:
        description: 100% AMC model
        file_type: fastText model
        topic:
        - NLP
        - Word Embeddings
        additional:
          model_id: m8
          train_data_description: null
          training_architecture: fasttext
          train_data_size: 54G
          train_data_md5_hash: 7e9b50396f77babeef827beff7e506ef
          training_epochs: 10
          training_vector_size: 200
          training_window_size: 10
          training_duration (minutes): 4923
          model_data_size: 12G
veld_data__fasttext_models___m9___veld.yaml:
  url: https://github.com/veldhub/veld_data__fasttext_models/blob/main/m9/veld.yaml
  content:
    x-veld:
      data:
        description: 100% AMC model
        file_type: fastText model
        topic:
        - NLP
        - Word Embeddings
        additional:
          model_id: m9
          train_data_description: 'Entire AMC: unique sentences, stripped from non-alphanumeric
            lines, lowercased, punctuation removed, removed sentences with too many
            non-alphanumeric characters.'
          training_architecture: fasttext
          train_data_size: 54G
          train_data_md5_hash: 7e9b50396f77babeef827beff7e506ef
          training_epochs: 10
          training_vector_size: 300
          training_window_size: 10
          training_duration (minutes): 6513
          model_data_size: 18G
veld_data__glove_models___m1___veld.yaml:
  url: https://github.com/veldhub/veld_data__glove_models/blob/main/m1/veld.yaml
  content:
    x-veld:
      data:
        description: glove test model
        file_type:
        - GloVe model
        - bin
        - txt
        topic:
        - NLP
        - Word Embeddings
        additional:
          model_id: m1
          train_data_description: sample wikipedia, single txt, one article per line,
            lowercased, removed punctuation
          training_architecture: glove
          train_data_size: 681M
          train_data_md5_hash: ba86437d073c0cf19e0f54c8dbc52547
          verbose: '2'
          memory: '4.0'
          vocab_min_count: '5'
          vector_size: '200'
          max_iter: '10'
          window_size: '15'
          binary: '2'
          num_threads: '14'
          x_max: '10'
          training_duration (minutes): 44.11
          model_data_size: 16G
veld_data__glove_models___m3___veld.yaml:
  url: https://github.com/veldhub/veld_data__glove_models/blob/main/m3/veld.yaml
  content:
    x-veld:
      data:
        description: 1% AMC model
        file_type:
        - GloVe model
        - bin
        - txt
        topic:
        - NLP
        - Word Embeddings
        additional:
          model_id: m3
          train_data_description: 1% of AMC
          training_architecture: glove
          train_data_size: 552M
          train_data_md5_hash: 05514cc05c6d61fcb3b20076372e2b8a
          verbose: '2'
          memory: '4.0'
          vocab_min_count: '5'
          vector_size: '200'
          max_iter: '10'
          window_size: '15'
          binary: '2'
          num_threads: '14'
          x_max: '10'
          training_duration (minutes): 24.8
          model_data_size: 9.1G
veld_data__word2vec_models___m3___veld.yaml:
  url: https://github.com/veldhub/veld_data__word2vec_models/blob/main/m3/veld.yaml
  content:
    x-veld:
      data:
        description: 10% AMC model
        file_type: word2vec model
        topic:
        - NLP
        - Word Embeddings
        additional:
          model_id: m3
          training_architecture: word2vec
          train_data_description: 'AMC data: stripped from non-alphanumeric lines,
            10% sampled, lowercased, punctuation removed, cleaned from lines not having
            enough text'
          train_data_size: 5.4G
          train_data_md5_hash: 33167f260dbf99fa3ceebc3563302954
          training_vector_size: 200
          training_epochs: 10
          window: 5
          min_count: 5
          training_duration (minutes): 165.3
          model_data_size: 2.4G
veld_data__word2vec_models___m4___veld.yaml:
  url: https://github.com/veldhub/veld_data__word2vec_models/blob/main/m4/veld.yaml
  content:
    x-veld:
      data:
        description: 10% AMC model
        file_type: word2vec model
        topic:
        - NLP
        - Word Embeddings
        additional:
          model_id: m4
          training_architecture: word2vec
          train_data_description: 'AMC data: stripped from non-alphanumeric lines,
            10% sampled, lowercased, punctuation removed, cleaned from lines not having
            enough text'
          train_data_size: 5.4G
          train_data_md5_hash: 33167f260dbf99fa3ceebc3563302954
          training_vector_size: 200
          training_epochs: 50
          window: 5
          min_count: 5
          training_duration (minutes): 786.8
          model_data_size: 2.4G
veld_data__word2vec_models___m5___veld.yaml:
  url: https://github.com/veldhub/veld_data__word2vec_models/blob/main/m5/veld.yaml
  content:
    x-veld:
      data:
        description: 10% AMC model
        file_type: word2vec model
        topic:
        - NLP
        - Word Embeddings
        additional:
          model_id: m5
          training_architecture: word2vec
          train_data_description: 'AMC data: stripped from non-alphanumeric lines,
            10% sampled, lowercased, punctuation removed, cleaned from lines not having
            enough text'
          train_data_size: 5.4G
          train_data_md5_hash: 33167f260dbf99fa3ceebc3563302954
          training_vector_size: 300
          training_epochs: 10
          window: 5
          min_count: 5
          training_duration (minutes): 188.4
          model_data_size: 3.6G
veld_data__word2vec_models___m6___veld.yaml:
  url: https://github.com/veldhub/veld_data__word2vec_models/blob/main/m6/veld.yaml
  content:
    x-veld:
      data:
        description: 100% AMC model
        file_type: word2vec model
        topic:
        - NLP
        - Word Embeddings
        additional:
          model_id: m6
          training_architecture: word2vec
          train_data_description: null
          train_data_size: 54G
          train_data_md5_hash: 7e9b50396f77babeef827beff7e506ef
          training_vector_size: 300
          training_epochs: 10
          window: 5
          min_count: 5
          training_duration (minutes): 4573
          model_data_size: 17G
veld_data__word2vec_models___m7___veld.yaml:
  url: https://github.com/veldhub/veld_data__word2vec_models/blob/main/m7/veld.yaml
  content:
    x-veld:
      data:
        description: 100% AMC model
        file_type: word2vec model
        topic:
        - NLP
        - Word Embeddings
        additional:
          model_id: m7
          training_architecture: word2vec
          train_data_description: null
          train_data_size: 54G
          train_data_md5_hash: 7e9b50396f77babeef827beff7e506ef
          training_vector_size: 200
          training_epochs: 10
          window: 5
          min_count: 5
          training_duration (minutes): 1915
          model_data_size: 11G
veld_data__word2vec_models___m8___veld.yaml:
  url: https://github.com/veldhub/veld_data__word2vec_models/blob/main/m8/veld.yaml
  content:
    x-veld:
      data:
        description: 100% AMC model
        file_type: word2vec model
        topic:
        - NLP
        - Word Embeddings
        additional:
          model_id: m8
          training_architecture: word2vec
          train_data_description: null
          train_data_size: 54G
          train_data_md5_hash: 7e9b50396f77babeef827beff7e506ef
          training_vector_size: 300
          training_epochs: 10
          window: 10
          min_count: 5
          training_duration (minutes): 10128
          model_data_size: 17G
veld_data__word2vec_models___m9___veld.yaml:
  url: https://github.com/veldhub/veld_data__word2vec_models/blob/main/m9/veld.yaml
  content:
    x-veld:
      data:
        description: 100% AMC model
        file_type: word2vec model
        topic:
        - NLP
        - Word Embeddings
        additional:
          model_id: m9
          training_architecture: word2vec
          train_data_description: 'Entire AMC: unique sentences, stripped from non-alphanumeric
            lines, lowercased, punctuation removed, removed sentences with too many
            non-alphanumeric characters.'
          train_data_size: 54G
          train_data_md5_hash: 7e9b50396f77babeef827beff7e506ef
          training_vector_size: 200
          training_epochs: 10
          window: 10
          min_count: 5
          training_duration (minutes): 1847
          model_data_size: 261M
veld_data__wordembeddings_evaluation___evaluation_gold_data___capitalized___veld.yaml:
  url: https://github.com/veldhub/veld_data__wordembeddings_evaluation/blob/main/evaluation_gold_data/capitalized/veld.yaml
  content:
    x-veld:
      data:
        description: custom evaluation data for evaluating word embeddings models.
          Words are capitalized.
        topic:
        - NLP
        - Word Embeddings
        file_type: yaml
        content:
        - evaluation data
        - NLP gold data
veld_data__wordembeddings_evaluation___evaluation_gold_data___lowercase___veld.yaml:
  url: https://github.com/veldhub/veld_data__wordembeddings_evaluation/blob/main/evaluation_gold_data/lowercase/veld.yaml
  content:
    x-veld:
      data:
        description: custom evaluation data for evaluating word embeddings models.
          Words are all lowercase.
        topic:
        - NLP
        - Word Embeddings
        file_type: yaml
        content:
        - evaluation data
        - NLP gold data
veld_code__akp_ner_inference___veld_infer.yaml:
  url: https://github.com/veldhub/veld_code__akp_ner_inference/blob/main/veld_infer.yaml
  content:
    x-veld:
      code:
        description: apply NER models on linkedcat data for usage of the inferenced
          entites in the AKP project
        topic:
        - NLP
        - Machine Learning
        - Named Entity Recognition
        input:
        - volume: /veld/input/
          file_type: spaCy model
          content:
          - NLP model
          - NER model
        output:
        - volume: /veld/output/
          file_type: csv
          environment_var: out_csv_file
          description: inferenced NLP / NER data.
          content:
          - inferenced NLP data
          - NLP data
          - NER data
        config:
        - environment_var: solr_core_url
          description: url pointing to a solr core from where text data should be
            loaded
          var_type: str
    services:
      veld_infer:
        build: .
        command: jupyter notebook --ip='*' --allow-root --NotebookApp.token='' --NotebookApp.password=''
        ports:
        - 8888:8888
        working_dir: /veld/code/
        volumes:
        - ./src:/veld/code/
        environment:
          solr_core_url: null
          out_csv_file: null
veld_code__analyse_conllu___veld.yaml:
  url: https://github.com/veldhub/veld_code__analyse_conllu/blob/main/veld.yaml
  content:
    x-veld:
      code:
        description: 'A statistical summary on conllu data, to count linguistic features
          of a conllu file: - count of total tokens - count of total lemma - count
          of lemma normalized by token (to put the lemma in relation with token) -
          count of occurrence of each (Universal Dependencies) part of speech tag
          Can be adapted to other use cases and made more flexible, but is primarily
          used in this chain veld: https://github.com/veldhub/veld_chain__eltec_udpipe_inference'
        topic:
        - NLP
        - Machine Learning
        - Tokenization
        - Lemmatization
        - Part Of Speech
        - Dependency Parsing
        - Universal Dependencies
        - Grammatical Annotation
        input:
        - volume: /veld/input/
          file_type: conllu
        output:
        - volume: /veld/output/
          file_type: json
          content:
          - statistics
          - NLP statistics
    services:
      veld:
        build: .
        command: jupyter notebook --allow-root --ip='*' --NotebookApp.token='' --NotebookApp.password=''
        ports:
        - 8888:8888
        working_dir: /veld/code/
        volumes:
        - ./src:/veld/code/
veld_code__apache_jena_fuseki___veld_export.yaml:
  url: https://github.com/veldhub/veld_code__apache_jena_fuseki/blob/main/veld_export.yaml
  content:
    x-veld:
      code:
        description: Exports data from an Apache Fuseki triplestore given a rq query
          file, into several serialization formats.
        topic:
        - ETL
        - RDF
        - triplestore
        input:
          volume: /veld/input/
          environment_var: in_query_file
          description: Contains the sparql query that is ran at the triplestore
          file_type: rq
          content: sparql query
        output:
          volume: /veld/output/
          environment_var: out_file
          description: Output file where the query results should be writte into.
          file_type:
          - csv
          - json
          - tsv
          - xml
        config:
        - environment_var: out_format
          var_type: str
          description: sets the output format. Can only be one of `csv`, `json`, `tsv`,
            `xml`
        - environment_var: fuseki_server_url
          var_type: str
          optional: true
          default: http://veld_run_server
          description: The url of the Fuseki triplestore
        - environment_var: fuseki_server_port
          var_type: int
          default: 3030
          optional: true
          description: The port of the Fuseki triplestore
        - environment_var: fuseki_dataset_name
          var_type: str
          description: The dataset name of the Fuseki triplestore
    services:
      veld_export:
        build: .
        command: bash /veld/code/scripts/export.sh
        volumes:
        - ./scripts/:/veld/code/scripts/
        - ./data/queries/:/veld/input/
        - ./data/export/:/veld/output/
        networks:
        - veld_fuseki
        environment:
          in_query_file: null
          out_file: null
          out_format: null
          fuseki_server_url: http://veld_run_server
          fuseki_server_port: 3030
          fuseki_dataset_name: null
    networks:
      veld_fuseki: null
veld_code__apache_jena_fuseki___veld_import_rdf.yaml:
  url: https://github.com/veldhub/veld_code__apache_jena_fuseki/blob/main/veld_import_rdf.yaml
  content:
    x-veld:
      code:
        description: Import script to batch import rdf data from a folder into an
          apache fuseki triplestore. Note that if this service should connect to a
          triplestore running in another docker compose service, the relevant `networks`
          section might be necessary to set accordingly.
        topic:
        - ETL
        - RDF
        - triplestore
        - database
        input:
          volume: /veld/input/
          environment_var: in_rdf_file
          file_type: xml
          description: A folder containing RDF/XML files. If var `in_rdf_file` is
            set, that file is imported; if not, the folder is recursively searched.
          content: RDF/XML
        config:
        - environment_var: fuseki_server_url
          var_type: str
          description: URL under which a triplestore is connected to.
        - environment_var: fuseki_server_port
          var_type: int
          description: port under which a triplestore is connected to.
        - environment_var: fuseki_dataset_name
          var_type: str
          description: Name of the dataset, into which the rdf data is imported to.
            If it doesn't exist, it is created.
        - environment_var: fuseki_dataset_type
          var_type: str
          description: If the dataset is created, then this var sets its type. See
            https://jena.apache.org/documentation/fuseki2/fuseki-configuration.html#Datasets
            for more information.
        - environment_var: fuseki_graph_uri
          var_type: str
          description: Graph URI under which the data is imported to.
    services:
      veld_import_rdf:
        build: .
        command: bash /veld/code/scripts/import_rdf.sh
        volumes:
        - ./scripts/:/veld/code/scripts/
        - ./data/input/:/veld/input/
        networks:
        - veld_fuseki
        environment:
          in_rdf_file: null
          fuseki_server_url: http://veld_run_server
          fuseki_server_port: 3030
          fuseki_dataset_name: null
          fuseki_dataset_type: tdb2
          fuseki_graph_uri: default
    networks:
      veld_fuseki: null
veld_code__apache_jena_fuseki___veld_run_server.yaml:
  url: https://github.com/veldhub/veld_code__apache_jena_fuseki/blob/main/veld_run_server.yaml
  content:
    x-veld:
      code:
        description: An Apache Fuseki triplestore instance. Note that, changing the
          port is recommended to be done via the compose' file `ports` section (if
          present, then best in the inhereting chain veld). And other docker services
          needing to connect to this server must be added to a docker network `veld_fuseki`.
        topic:
        - RDF
        - triplestore
        - database
        input:
          volume: /veld/input/config/
          description: The shiro.ini file for configuring the triplestore instance.
            A working default is provided with this code veld. See https://shiro.apache.org/
            for more information.
          optional: true
        storage:
          volume: /veld/storage/
          file_type: apache fuseki triplestore data
          content:
          - triplestore data
          - rdf data
          description: storage place for the entire data of a apache fuseki triplestore
            instance.
    services:
      veld_run_server:
        build: .
        entrypoint: bash /veld/code/scripts/copy_config.sh
        command: /veld/code/fuseki-server
        volumes:
        - ./scripts/:/veld/code/scripts/
        - ./data/fuseki_data/:/veld/storage/
        - ./data/fuseki_config/:/veld/input/config/
        ports:
        - 3030:3030
        networks:
        - veld_fuseki
    networks:
      veld_fuseki: null
veld_code__bert_embeddings___veld_infer_and_create_index.yaml:
  url: https://github.com/veldhub/veld_code__bert_embeddings/blob/main/veld_infer_and_create_index.yaml
  content:
    x-veld:
      code: null
    services:
      infer_and_create_index:
        build: .
        command: python /veld/code/infer_and_create_index.py
        volumes:
        - ./src/:/veld/code/
veld_code__conllueditor___veld.yaml:
  url: https://github.com/veldhub/veld_code__conllueditor/blob/main/veld.yaml
  content:
    x-veld:
      code:
        description: a veldified code, enapsulating the conllueditor web server from
          https://github.com/Orange-OpenSource/conllueditor . It uses a pre-built
          image from dockerhub. After starting this docker container, the web service
          can be reached at http://localhost:8888/ .
        topic:
        - NLP
        - Universal Dependencies
        - Tokenization
        - Lemmatization
        - Part Of Speech
        - Dependency Parsing
        - Grammatical Annotation
        storage:
          volume: /data/
          description: the storage folder for all the conllu files to be processed.
          file_type: conllu
          environment_var: filename
    services:
      veld_conllueditor:
        image: jheinecke/conllueditor:latest
        ports:
        - 8888:5555
        volumes:
        - ./data/:/data/
        user: 1000:1000
        environment:
          filename: null
veld_code__downloader___veld.yaml:
  url: https://github.com/veldhub/veld_code__downloader/blob/main/veld.yaml
  content:
    x-veld:
      code:
        description: A download helper, for simple or batch downloads. Also offers
          automatic compressed file extraction.
        topic: ETL
        input:
          volume: /veld/input/
          file_type: csv
          content: download urls and target file names
          environment_var: in_csv_file
          description: Besides downloading directly from a given url, the downloader
            may also process a csv file for batch downloading. The first column of
            the csv must be the url, and the optional second column a designated file
            name. Column names are ignored by default (by var `csv_has_headers` being
            set to `true`). Note that the var `in_csv_file` can not be set at the
            same time as `url`, since the former designates batch processing while
            the latter designates a single download.
        output:
          volume: /veld/output/
          environment_var: out_file
          description: optional. If `out_file` is unset, this script will fetch the
            file name from the resource.
          optional: true
        config:
        - environment_var: url
          var_type: str
          description: The url where some resource is located and should be downloaded
            from.
        - environment_var: do_extract
          var_type: bool
          default: false
          description: If set to `true`, the generic extraction tool `dtrx` will be
            used on the downloaded file to extract its data.
        - environment_var: csv_has_headers
          var_type: bool
          default: true
          description: Designates if the csv file has headers or not. Set to `true`
            by default and headers are ignored by the script. Must be set to `false`
            when no headers are present, because otherwise the first data row is assumed
            to be headers and thus ignored.
    services:
      veld_downloader:
        build: .
        command: sh /veld/code/downloader.sh
        volumes:
        - ./downloader.sh:/veld/code/downloader.sh
        - ./data/output/:/veld/output/
        environment:
          in_csv_file: null
          url: null
          out_file: null
          do_extract: false
          csv_has_headers: true
veld_code__fasttext___veld_export.yaml:
  url: https://github.com/veldhub/veld_code__fasttext/blob/main/veld_export.yaml
  content:
    x-veld:
      code:
        description: exports a fasttext model to a pkl file containing a python dict,
          where the keys are words and its values are the learned vectors, represented
          as high-dimensional numpy arrays.
        topic:
        - ETL
        - NLP
        - Machine Learning
        - Word Embeddings
        input:
          volume: /veld/input/
          environment_var: in_model_file
          file_type: fastText model
          content: Word Embeddings vectors
        output:
          volume: /veld/output/
          environment_var: out_vector_file
          file_type: pkl
          content:
          - Word Embeddings model
          - Word Embeddings vectors
    services:
      veld_export:
        build: .
        command: python /veld/code/export.py
        volumes:
        - ./src/export/:/veld/code/
        environment:
          in_model_file: null
          out_vector_file: null
veld_code__fasttext___veld_jupyter_notebook.yaml:
  url: https://github.com/veldhub/veld_code__fasttext/blob/main/veld_jupyter_notebook.yaml
  content:
    x-veld:
      code:
        description: a fasttext training and inference jupyter notebook.
        topic:
        - NLP
        - Machine Learning
        - Word Embeddings
    services:
      veld_jupyter_notebook:
        build: .
        command: jupyter notebook --allow-root --ip='*' --NotebookApp.token='' --NotebookApp.password=''
        ports:
        - 8888:8888
        volumes:
        - ./src/jupyter_notebook/:/veld/code/:z
        - ./data/:/veld/storage/:z
veld_code__fasttext___veld_train.yaml:
  url: https://github.com/veldhub/veld_code__fasttext/blob/main/veld_train.yaml
  content:
    x-veld:
      code:
        description: A fasttext training setup.
        topic:
        - NLP
        - Machine Learning
        - Word Embeddings
        input:
        - volume: /veld/input/
          file_type: txt
          environment_var: in_train_data_file
          description: training data must be expressed as one sentence per line.
          content: raw text
        output:
        - volume: /veld/output/
          file_type: fastText model
          environment_var: out_model_file
          content: Word Embeddings
        config:
        - environment_var: vector_size
          description: 'hyperparameter: the dimension of the vectors to be trained.'
          var_type: int
          default: 200
        - environment_var: epochs
          description: 'hyperparameter: the number of epochs of the training.'
          var_type: int
          default: 50
        - environment_var: window_size
          description: 'hyperparameter: the size of the context window of each token.'
          var_type: int
          default: 5
    services:
      veld_train:
        build: .
        command: sh /veld/code/train.sh
        volumes:
        - ./src/train/:/veld/code/:z
        - ./data/training_data/:/veld/input/:z
        - ./data/models/:/veld/output/:z
        environment:
          in_train_data_file: null
          out_model_file: null
          model_description: null
          vector_size: 200
          epochs: 50
          window_size: 5
veld_code__flair___veld_infer.yaml:
  url: https://github.com/veldhub/veld_code__flair/blob/main/veld_infer.yaml
  content:
    x-veld:
      code:
        description: null
        topic: null
        additional: null
        input:
        - volume: /veld/input/
          file_type: null
          content: null
          environemnt_var: null
        output:
        - volume: /veld/output/
          file_type: null
          content: null
          environemnt_var: null
        config:
        - environemnt_var: null
          description: null
          var_type: null
          default: null
          optional: null
    services:
      veld_infer:
        build: .
        command: bash /veld/code/run.sh infer
        ports:
        - 8888:8888
        volumes:
        - ./src/:/veld/code/
        - ./data/models_cache/:/veld/input/models_cache/
        environment:
          run_interactively: true
          in_file: ''
          out_file: ''
veld_code__flair___veld_train.yaml:
  url: https://github.com/veldhub/veld_code__flair/blob/main/veld_train.yaml
  content:
    x-veld:
      code:
        description: null
        topic: null
        additional: null
        input:
        - volume: /veld/input/
          file_type: null
          content: null
          environemnt_var: null
        output:
        - volume: /veld/output/
          file_type: null
          content: null
          environemnt_var: null
        config:
        - environemnt_var: null
          description: null
          var_type: null
          default: null
          optional: null
    services:
      veld_train:
        build: .
        command: bash /veld/code/run.sh train
        ports:
        - 8888:8888
        volumes:
        - ./src/:/veld/code/
        environment:
          run_interactively: true
veld_code__glove___veld_export.yaml:
  url: https://github.com/veldhub/veld_code__glove/blob/main/veld_export.yaml
  content:
    x-veld:
      code:
        description: exports a glove model to a pkl file containing a python dict,
          where the keys are words and its values are the learned vectors, represented
          as high-dimensional numpy arrays.
        topic:
        - ETL
        - NLP
        - Machine Learning
        - Word Embeddings
        input:
          volume: /veld/input/
          environment_var: in_vector_file
          file_type: txt
          content:
          - GloVe model
          - Word Embeddings model
          - Word Embeddings vectors
        output:
          volume: /veld/output/
          environment_var: out_vector_file
          file_type: pkl
          content:
          - Word Embeddings model
          - Word Embeddings vectors
    services:
      veld_export:
        build: .
        command: python3 /veld/code/export.py
        volumes:
        - ./src/main/export/:/veld/code/
        environment:
          in_vector_file: null
          out_vector_file: null
veld_code__glove___veld_jupyter_notebook.yaml:
  url: https://github.com/veldhub/veld_code__glove/blob/main/veld_jupyter_notebook.yaml
  content:
    x-veld:
      code:
        description: A jupyter notebook that loads GloVe vectors and provides some
          convenient functions to use them.
        topic:
        - NLP
        - Machine Learning
        - Word Embeddings
    services:
      veld_jupyter_notebook:
        build: .
        command: jupyter notebook --allow-root --ip='*' --NotebookApp.token='' --NotebookApp.password=''
        ports:
        - 8888:8888
        volumes:
        - ./src/main/jupyter_notebook/:/veld/code/:z
        - ./data/:/veld/storage/:z
veld_code__glove___veld_train.yaml:
  url: https://github.com/veldhub/veld_code__glove/blob/main/veld_train.yaml
  content:
    x-veld:
      code:
        description: A GloVe training setup.
        topic:
        - NLP
        - Machine Learning
        - Word Embeddings
        input:
        - volume: /veld/input/
          environment_var: in_corpus_file
          description: In the txt file, each line must be one sentence
          file_type: txt
          content: natural text
        output:
        - volume: /veld/output/
          environment_var: out_vocab_file
          file_type: GloVe model
          content:
          - NLP model
          - Word Embeddings model
        - volume: /veld/output/
          environment_var: out_cooccurrence_file
          file_type: GloVe model
          content:
          - NLP model
          - Word Embeddings model
        - volume: /veld/output/
          environment_var: out_cooccurrence_shuf_file
          file_type: GloVe model
          content:
          - NLP model
          - Word Embeddings model
        - volume: /veld/output/
          environment_var: out_vector_file
          file_type: GloVe model
          content:
          - NLP model
          - Word Embeddings model
        config:
        - environment_var: verbose
          var_type: int
          default: 2
        - environment_var: memory
          var_type: float
          default: 4.0
        - environment_var: vocab_min_count
          var_type: int
          default: 5
        - environment_var: vector_size
          var_type: int
          default: 50
        - environment_var: max_iter
          var_type: int
          default: 15
        - environment_var: window_size
          var_type: int
          default: 15
        - environment_var: binary
          var_type: int
          default: 2
        - environment_var: num_threads
          var_type: int
          default: 8
        - environment_var: x_max
          var_type: int
          default: 10
    services:
      veld_train:
        build: .
        platform: linux/amd64
        volumes:
        - ./src/main/train/:/veld/code/:z
        - ./data/training_data/:/veld/input/:z
        - ./data/models/:/veld/output/:z
        command: sh /veld/code/train.sh
        environment:
          in_corpus_file: null
          out_vocab_file: null
          out_cooccurrence_file: null
          out_cooccurrence_shuf_file: null
          out_vector_file: null
          model_id: null
          model_description: null
          verbose: 2
          memory: 4.0
          vocab_min_count: 5
          vector_size: 50
          max_iter: 15
          window_size: 15
          binary: 2
          num_threads: 8
          x_max: 10
veld_code__inception___veld.yaml:
  url: https://github.com/veldhub/veld_code__inception/blob/main/veld.yaml
  content:
    x-veld:
      code:
        description: An veldified inception instance. See https://github.com/inception-project/inception
          for more information.
        topic:
        - NLP
        - Annotation
        - Universal Dependencies
        - Tokenization
        - Lemmatization
        - Part Of Speech
        - Dependency Parsing
        - Grammatical Annotation
        storage:
        - volume: /export/
          service: veld_inception_app
          content: inception metadata
        - volume: /var/lib/mysql/
          service: veld_inception_db
          content: maria db
    services:
      veld_inception_app:
        image: ghcr.io/inception-project/inception:latest
        ports:
        - 8080:8080
        environment:
        - INCEPTION_DB_DIALECT=org.hibernate.dialect.MariaDB106Dialect
        - INCEPTION_DB_URL=jdbc:mariadb://veld_inception_db:3306/inception?useSSL=false&useUnicode=true&characterEncoding=UTF-8
        - INCEPTION_DB_USERNAME=${DBUSER:-inception}
        - INCEPTION_DB_PASSWORD=${DBPASSWORD:-inception}
        volumes:
        - ./data/inception_app/:/export/
        depends_on:
          veld_inception_db:
            condition: service_healthy
        networks:
          inception-net: null
      veld_inception_db:
        image: mariadb:11.4
        environment:
        - MARIADB_RANDOM_ROOT_PASSWORD=yes
        - MARIADB_DATABASE=inception
        - MARIADB_USER=${DBUSER:-inception}
        - MARIADB_PASSWORD=${DBPASSWORD:-inception}
        - MARIADB_AUTO_UPGRADE=1
        volumes:
        - ./data/inception_db/:/var/lib/mysql/
        command:
        - --character-set-server=utf8mb4
        - --collation-server=utf8mb4_bin
        healthcheck:
          test:
          - CMD
          - mariadb-admin
          - ping
          - -h
          - localhost
          - -p${DBPASSWORD:-inception}
          - -u${DBUSER:-inception}
          interval: 20s
          timeout: 10s
          retries: 10
        networks:
          inception-net: null
    networks:
      inception-net: null
veld_code__jupyter_notebook_base___veld.yaml:
  url: https://github.com/veldhub/veld_code__jupyter_notebook_base/blob/main/veld.yaml
  content:
    x-veld:
      code:
        description: template veld code repo for a juptyer notebook
    services:
      veld:
        build: .
        command: jupyter notebook --allow-root --ip='*' --NotebookApp.token='' --NotebookApp.password=''
        ports:
        - 8888:8888
        working_dir: /veld/code/
        volumes:
        - ./src:/veld/code/
        - ./volumes/input/:/veld/input/
        - ./volumes/output/:/veld/output/
veld_code__pypi_publisher___veld_publish.yaml:
  url: https://github.com/veldhub/veld_code__pypi_publisher/blob/main/veld_publish.yaml
  content:
    x-veld:
      code:
        description: This code veld encapsulates a publishing workflow to pypi.org
          .
        topic:
        - pypi
        - packaging
        inputs:
          volume: /veld/input/
          content: python code base
          description: Any suitable python code base containing a setup.py or pyproject.toml
            .
        config:
        - environment_var: TWINE_USERNAME
          description: Contains the username, or better, just `__token__` if a token
            is used which was created on pypi.org .
          default: __token__
          var_type: str
        - environment_var: TWINE_PASSWORD
          description: 'Contains the password, or better, a token which was created
            on pypi.org .

            IMPORTANT: DON''T HARDCODE THE TOKEN HERE!

            Rather define this environment variable on the host, by either: - PREFERRED:
            do this manually before calling this docker compose service. On linux
            and mac, this can be done with `export TWINE_PASSWORD=<TOKEN>` and on
            windows with `set TWINE_PASSWORD=<TOKEN>` (and the same way for `TWINE_USERNAME`)
            before launching a docker compose service. - LESS PREFERRED: only do this
            if you know .gitignore: you may persist it in a `.env` file (with the
            content simply being `hf_token=<TOKEN>`) file next to the chain veld yaml
            file, which docker would automatically load, and then add the `.env` to
            `.gitignore`!'
          var_type: str
        - environment_var: testing
          description: If set to true, it will publish to test.pypi.org . If set to
            false, it will publish to pypi.org .
          var_type: bool
    services:
      veld_publish:
        build: .
        volumes:
        - ./veld_publish.sh:/veld/code/veld_publish.sh
        command: bash /veld/code/veld_publish.sh
        working_dir: /veld/input/
        environment:
          TWINE_USERNAME: __token__
          TWINE_PASSWORD: null
          testing: true
veld_code__simple_docker_test___veld.yaml:
  url: https://github.com/veldhub/veld_code__simple_docker_test/blob/main/veld.yaml
  content:
    x-veld:
      code:
        description: prints information about the python intepreter within the docker
          container.
        topic: Testing
    services:
      veld:
        build: .
        command: python /veld/code/test.py
        volumes:
        - ./test.py:/veld/code/test.py
veld_code__spacy___veld_convert.yaml:
  url: https://github.com/veldhub/veld_code__spacy/blob/main/veld_convert.yaml
  content:
    x-veld:
      code:
        description: prepare data for spacy NER training, since spacy expects the
          entity annotation indices to be precisely at the beginning and end of the
          words, and also no overlapping entity annotations. Then it converts the
          data to spaCy docbin, and prepares it for training by splitting it into
          train, dev, eval subsets, and shuffling them randomly.
        topic:
        - ETL
        - NLP
        - Machine Learning
        input:
        - volume: /veld/input/
          file_type: json
          description: name of the csv file, containing NER gold data
          environment_var: in_json_file
          content: NER gold data
        output:
        - volume: /veld/output/docbin/
          description: path to folder where spacy docbin files will be stored with
            file names `train.spacy, dev.spacy, eval.spacy`
          file_type: spaCy docbin
          content: NER gold data
        - volume: /veld/output/log/
          environment_var: out_log_file
          description: log file of conversion
          file_type: txt
          content: log
        config:
        - environment_var: model_base
          description: spacy model to be used for conversion.
          var_type: str
        - environment_var: percentage_train
          description: percentage of data allocated to training set
          var_type: int
          default: 80
        - environment_var: percentage_dev
          description: percentage of data allocated to dev set
          var_type: int
          default: 10
        - environment_var: percentage_eval
          description: percentage of data allocated to eval set
          var_type: int
          default: 10
        - environment_var: seed
          description: seed for initial random shuffling of training data
          var_type: int
          default: 42
    services:
      veld_convert:
        build: .
        command: python /veld/code/convert.py
        volumes:
        - ./src/:/veld/code/
        - ./data/models_base_cache/:/tmp/models_base_cache/
        - ./data/training_data_json/:/veld/input/
        - ./data/docbin/:/veld/output/docbin/
        - ./:/veld/output/log/
        environment:
          in_json_file: null
          out_log_file: null
          model_base: null
          percentage_train: 80
          percentage_dev: 10
          percentage_eval: 10
          seed: 42
veld_code__spacy___veld_create_config.yaml:
  url: https://github.com/veldhub/veld_code__spacy/blob/main/veld_create_config.yaml
  content:
    x-veld:
      code:
        description: 'Creating a spacy config by encapsulating `init config` ( https://spacy.io/api/cli#init-config
          ) and `init fill-config` ( https://spacy.io/api/cli#init-fill-config ) .
          The output is ai config file used for training; see more here: https://spacy.io/usage/training/#config'
        topic:
        - NLP
        - Machine Learning
        output:
        - volume: /veld/output/
          file_type: cfg
          environment_var: out_spacy_config
          content: spacy training config
          description: See https://spacy.io/usage/training/#config
        config:
        - environment_var: lang
          description: See https://spacy.io/api/cli#init-config
          var_type: str
        - environment_var: tagger
          description: See https://spacy.io/api/cli#init-config
          var_type: bool
          default: false
          optional: true
        - environment_var: parser
          description: See https://spacy.io/api/cli#init-config
          var_type: bool
          default: false
          optional: true
        - environment_var: ner
          description: See https://spacy.io/api/cli#init-config
          var_type: bool
          default: false
          optional: true
        - environment_var: entity_linker
          description: See https://spacy.io/api/cli#init-config
          var_type: bool
          default: false
          optional: true
        - environment_var: entity_ruler
          description: See https://spacy.io/api/cli#init-config
          var_type: bool
          default: false
          optional: true
        - environment_var: textcat
          description: See https://spacy.io/api/cli#init-config
          var_type: bool
          default: false
          optional: true
        - environment_var: textcat_multilabel
          description: See https://spacy.io/api/cli#init-config
          var_type: bool
          default: false
          optional: true
        - environment_var: lemmatizer
          description: See https://spacy.io/api/cli#init-config
          var_type: bool
          default: false
          optional: true
        - environment_var: trainable_lemmatizer
          description: See https://spacy.io/api/cli#init-config
          var_type: bool
          default: false
          optional: true
        - environment_var: morphologizer
          description: See https://spacy.io/api/cli#init-config
          var_type: bool
          default: false
          optional: true
        - environment_var: attribute_ruler
          description: See https://spacy.io/api/cli#init-config
          var_type: bool
          default: false
          optional: true
        - environment_var: senter
          description: See https://spacy.io/api/cli#init-config
          var_type: bool
          default: false
          optional: true
        - environment_var: sentencizer
          description: See https://spacy.io/api/cli#init-config
          var_type: bool
          default: false
          optional: true
        - environment_var: tok2vec
          description: See https://spacy.io/api/cli#init-config
          var_type: bool
          default: false
          optional: true
        - environment_var: transformer
          description: See https://spacy.io/api/cli#init-config
          var_type: bool
          default: false
          optional: true
        - environment_var: optimize_efficiency
          description: See https://spacy.io/api/cli#init-config
          var_type: bool
          default: false
          optional: true
        - environment_var: optimize_accuracy
          description: See https://spacy.io/api/cli#init-config
          var_type: bool
          default: false
          optional: true
        - environment_var: gpu
          description: See https://spacy.io/api/cli#init-config
          var_type: bool
          default: false
          optional: true
        - environment_var: pretraining
          description: See https://spacy.io/api/cli#init-config
          var_type: bool
          default: false
          optional: true
    services:
      veld_create_config:
        build: .
        working_dir: /veld/code/
        command: bash /veld/code/create_config.sh
        volumes:
        - ./src/:/veld/code/
        - ./data/configs/:/veld/output/
        environment:
          out_config_file: null
          lang: de
          tagger: false
          parser: false
          ner: false
          entity_linker: false
          entity_ruler: false
          textcat: false
          textcat_multilabel: false
          lemmatizer: false
          trainable_lemmatizer: false
          morphologizer: false
          attribute_ruler: false
          senter: false
          sentencizer: false
          tok2vec: false
          transformer: false
          optimize_efficiency: null
          optimize_accuracy: null
          gpu: false
          pretraining: false
veld_code__spacy___veld_publish_to_hf.yaml:
  url: https://github.com/veldhub/veld_code__spacy/blob/main/veld_publish_to_hf.yaml
  content:
    x-veld:
      code:
        description: 'simple service to push spacy models to huggingface. Important:
          Only works from spacy v3.* onwards!'
        topic:
        - NLP
        - ETL
        input:
        - volume: /veld/input/
          file_type: spaCy model
          content: NLP model
        config:
        - environment_var: model_name
          description: 'name of the model, to be used for huggingface metadata. IMPORTANT:
            do not put double underscores into the model name, as this crashes spacy
            while publishing.'
          var_type: str
          optional: true
        - environment_var: version
          description: 'version of the model, to be used for huggingface metadata.
            IMPORTANT: spacy crashes when the version tag contains the character `v`
            in front of numeric+dot version identifiers: E.g. `v1.1` crashes, while
            `1.1` works.'
          var_type: str
          optional: true
        - environment_var: hf_token
          description: 'huggingface authentication token.

            IMPORTANT: DON''T HARDCODE THE TOKEN HERE!

            Rather define this environment variable on the host, by either: - PREFERRED:
            do this manually before calling this docker compose service. On linux
            and mac, this can be done with `export hf_token=<TOKEN>` and on windows
            with `set hf_token=<TOKEN>` before launching a docker compose service.
            - LESS PREFERRED: only do this if you know .gitignore: you may persist
            it in a `.env` file (with the content simply being `hf_token=<TOKEN>`)
            file next to the chain veld yaml file, which docker would automatically
            load, and then add the `.env` to `.gitignore`!'
          var_type: str
    services:
      veld_publish_to_hf:
        build: .
        command: bash /veld/code/publish_to_hf.sh
        volumes:
        - ./src/:/veld/code/
        environment:
          model_name: null
          version: null
          hf_token: $hf_token
veld_code__spacy___veld_train.yaml:
  url: https://github.com/veldhub/veld_code__spacy/blob/main/veld_train.yaml
  content:
    x-veld:
      code:
        description: A spacy trainig setup, utilizing spacy v3's config system.
        topic:
        - NLP
        - Machine Learning
        input:
        - volume: /veld/input/docbin/
          file_type: spaCy docbin
          environment_var: in_train_docbin_file
          content:
          - NLP gold data
          - ML gold data
          - gold data
        - volume: /veld/input/docbin/
          file_type: spaCy docbin
          environment_var: in_dev_docbin_file
          content:
          - NLP gold data
          - ML gold data
          - gold data
        - volume: /veld/input/docbin/
          file_type: spaCy docbin
          environment_var: in_eval_docbin_file
          content:
          - NLP gold data
          - ML gold data
          - gold data
        - volume: /veld/input/config/
          file_type: cfg
          environment_var: in_spacy_config
          content: spacy training config
          description: See https://spacy.io/usage/training/#config
        output:
        - volume: /veld/output/
          file_type: spaCy model
          content: NLP model
        - volume: /veld/output/
          file_type: txt
          environment_var: out_train_log_file
          description: training log file
          content: log
        - volume: /veld/output/
          file_type: txt
          environment_var: out_eval_log_file
          description: evaluation log file
          content: log
        config:
        - environment_var: model_base
          description: spacy model to be used for downstream training.
          var_type: str
    services:
      veld_train:
        build: .
        working_dir: /veld/code/
        command: bash /veld/code/train.sh
        volumes:
        - ./src/:/veld/code/
        - ./data/models_base_cache/:/tmp/models_base_cache/
        - ./data/docbin/:/veld/input/docbin/
        - ./data/config/:/veld/input/config/
        - ./data/model/:/veld/output/
        environment:
          in_train_docbin_file: null
          in_dev_docbin_file: null
          in_eval_docbin_file: null
          model_base: null
          out_train_log_file: null
          out_eval_log_file: null
veld_code__teitok-tools___veld_parseudpipe.yaml:
  url: https://github.com/veldhub/veld_code__teitok-tools/blob/main/veld_parseudpipe.yaml
  content:
    x-veld:
      code:
        description: 'This code veld encapsulates and veldifies the parseudpipe script.
          All its config here are passed down to the script. For more information
          on its usage and config, see: https://github.com/ufal/teitok-tools?tab=readme-ov-file#parseudpipe'
        topic:
        - NLP
        - ETL
        - Tokenization
        - Universal Dependencies
        input:
        - volume: /veld/input/
          file_type: xml
          environment_var: in_xml_file
        output:
        - volume: /veld/output/
          file_type: xml
          environment_var: out_xml_file
        config:
        - environment_var: model
          description: which UDPIPE model to use
          var_type: str
          optional: true
        - environment_var: lang
          description: language of the texts (if no model is provided)
          var_type: str
          optional: true
        - environment_var: token
          description: token node
          var_type: str
          optional: true
        - environment_var: tokxp
          description: token XPath
          var_type: str
          optional: true
        - environment_var: sent
          description: sentence node
          var_type: str
          optional: true
        - environment_var: sentxp
          description: sentence XPath
          var_type: str
          optional: true
        - environment_var: atts
          description: attributes to use for the word form
          var_type: str
          optional: true
    services:
      veld_parseudpipe:
        build: .
        volumes:
        - ./:/veld/code/
        command: bash /veld/code/veld_parseudpipe.sh
        environment:
          in_xml_file: null
          out_xml_file: null
          model: null
          lang: null
          token: null
          tokxp: null
          sent: null
          sentxp: null
          atts: null
veld_code__teitok-tools___veld_udpipe2teitok.yaml:
  url: https://github.com/veldhub/veld_code__teitok-tools/blob/main/veld_udpipe2teitok.yaml
  content:
    x-veld:
      code:
        description: 'This code veld encapsulates and veldifies the udpipe2teitok
          script. All its config here are passed down to the script. For more information
          on its usage and config, see: https://github.com/ufal/teitok-tools?tab=readme-ov-file#udpipe2teitok'
        topic:
        - NLP
        - Grammatical Annotation
        - Universal Dependencies
        - Tokenization
        - Lemmatization
        - Part Of Speech
        - Dependency Parsing
        input:
          volume: /veld/input/
          file_type: txt
        output:
          volume: /veld/output/
          file_type: xml
        config:
        - environment_var: model
          description: the UDPIPE model to be used (which has to be available in the
            REST API)
          var_type: str
          optional: true
        - environment_var: lang
          description: An indication of the language (either an ISO code or a name)
            in case no model is provided.
          var_type: str
          optional: true
        - environment_var: mixed
          description: mixed language corpus - use CWALI to detect the language of
            each file.
          var_type: bool
          default: false
          optional: true
    services:
      veld_udpipe2teitok:
        build: .
        volumes:
        - ./:/veld/code/
        command: bash /veld/code/veld_udpipe2teitok.sh
        environment:
          lang: null
          model: null
          mixed: false
veld_code__teitok-tools___veld_xmltokenize.yaml:
  url: https://github.com/veldhub/veld_code__teitok-tools/blob/main/veld_xmltokenize.yaml
  content:
    x-veld:
      code:
        description: 'This code veld encapsulates and veldifies the xmltokenize script.
          All its config here are passed down to the script. For more information
          on its usage and config, see: https://github.com/ufal/teitok-tools?tab=readme-ov-file#xmltokenize'
        topic:
        - NLP
        - ETL
        - Tokenization
        - Universal Dependencies
        input:
        - volume: /veld/input/
          file_type: xml
          environment_var: in_xml_file
          description: The xml file to be tokenized
        output:
        - volume: /veld/output/
          file_type: xml
          environment_var: out_xml_file
          description: The output tokenized xml
        config:
        - environment_var: textnode
          description: what to use as the text body to tokenize
          var_type: str
        - environment_var: exclude
          description: elements not to tokenize
          var_type: str
          optional: true
        - environment_var: enumerate
          description: provide a unique ID to each token
          var_type: bool
          default: false
          optional: true
        - environment_var: segment
          description: split into sentences (1=yes, 2=only) - only for TEI files
          var_type: int
          optional: true
    services:
      veld_xmltokenize:
        build: .
        volumes:
        - ./:/veld/code/
        command: bash /veld/code/veld_xmltokenize.sh
        environment:
          in_xml_file: null
          out_xml_file: null
          textnode: null
          tok: null
          exclude: null
          enumerate: false
          segment: null
veld_code__udpipe___veld_infer.yaml:
  url: https://github.com/veldhub/veld_code__udpipe/blob/main/veld_infer.yaml
  content:
    x-veld:
      code:
        description: udpipe inference setup. See https://lindat.mff.cuni.cz/services/udpipe/
          for more information on the software encapsulated here.
        topic:
        - NLP
        - Machine Learning
        - Tokenization
        - Lemmatization
        - Part Of Speech
        - Dependency Parsing
        - Universal Dependencies
        - Grammatical Annotation
        input:
        - volume: /veld/input/txt/
          environment_var: in_txt_file
          description: txt files to be inferenced on. Note that the environment var
            `in_txt_file` is optional, and if it is not present, the entire input
            folder will be processed recursively
          optional: true
          file_type: txt
          content: raw text
        - volume: /veld/input/model/
          environment_var: in_model_file
          file_type: udpipe model
          content:
          - NLP model
          - tokenizer
          - lemmatizer
        output:
        - volume: /veld/output/
          description: The file name of the output conllu is created by the corresponding
            input txt file, since recursive processing requires such automatic logic
          file_type:
          - conllu
          - tsv
          content:
          - inferenced NLP data
          - tokenized text
          - lemmatized text
          - Part Of Speech of text
          - Universal Dependencies of text
          - grammatically annotated text
          - linguistic data
        config:
        - environment_var: tokenizer
          description: if tokenizer config should be read or not
          var_type: bool
          optional: true
          default: true
        - environment_var: tokenizer_normalized_spaces
          description: 'by default, UDPipe uses custom MISC fields to exactly encode
            spaces in the original document (as described below). If true, only the
            standard CoNLL-U v2 markup (SpaceAfter=No and # newpar) is used.'
          var_type: bool
          optional: true
          default: false
        - environment_var: tokenizer_presegmented
          description: the input file is assumed to be already segmented, with each
            sentence on a separate line, and is only tokenized (respecting sentence
            breaks)
          var_type: bool
          optional: true
          default: false
        - environment_var: tokenizer_ranges
          description: for each token, a range in the original document is stored
            in the format described below.
          var_type: bool
          optional: true
          default: false
        - environment_var: tokenizer_joint_with_parsing
          description: "an experimental mode performing sentence segmentation jointly\
            \ using the tokenizer and the parser (see Milan Straka and Jana Strakov\xE1\
            : Tokenizing, POS Tagging, Lemmatizing and Parsing UD 2.0 with UDPipe\
            \ paper for details)."
          var_type: bool
          optional: true
          default: false
        - environment_var: tokenizer_joint_change_boundary_logprob
          description: for every sentence boundary not returned by the tokenizer (i.e.,
            either 0, 1 or 2 times). The joint sentence segmentation chooses such
            a segmentation, where every sentence has length at most joint_max_sentence_len
            and the sum of logprobs of all sentences is as large as possible.
          var_type: bool
          optional: true
          default: false
        - environment_var: tagger
          description: if tagger config should be read or not
          var_type: bool
          optional: true
          default: true
        - environment_var: parser
          description: if parser config should be read or not
          var_type: bool
          optional: true
          default: true
    services:
      veld_infer:
        build: .
        command: bash /veld/code/infer.sh
        volumes:
        - ./data/inference/input/txt/:/veld/input/txt/
        - ./data/inference/input/model/:/veld/input/model/
        - ./data/inference/output/:/veld/output/
        - ./src/main/:/veld/code/
        environment:
          in_txt_file: null
          in_model_file: null
          tokenizer: true
          tokenizer_normalized_spaces: false
          tokenizer_presegmented: false
          tokenizer_ranges: false
          tokenizer_joint_with_parsing: false
          tokenizer_joint_change_boundary_logprob: false
          tagger: true
          parser: true
veld_code__udpipe___veld_train.yaml:
  url: https://github.com/veldhub/veld_code__udpipe/blob/main/veld_train.yaml
  content:
    x-veld:
      code:
        description: udpipe training setup. See https://lindat.mff.cuni.cz/services/udpipe/
          for more information on the software encapsulated here.
        topic:
        - NLP
        - Machine Learning
        - Tokenization
        - Lemmatization
        - Part Of Speech
        - Dependency Parsing
        - Universal Dependencies
        - Grammatical Annotation
        input:
        - volume: /veld/input/
          environment_var: train_data_path
          file_type: conllu
          content:
          - tokenized text
          - enriched text
          - linguistic data
        output:
        - volume: /veld/output/
          environment_var: model_path
          file_type: udpipe model
          content:
          - NLP model
          - tokenizer
          - lemmatizer
        config:
        - environment_var: tokenizer
          description: if tokenizer config should be read or not
          var_type: bool
          optional: true
          default: true
        - environment_var: tokenizer_tokenize_url
          description: tokenize URLs and emails using a manually implemented recognizer
          var_type: bool
          optional: true
          default: true
        - environment_var: tokenizer_allow_spaces
          description: allow tokens to contain spaces
          var_type: bool
          optional: true
          default: true
        - environment_var: tokenizer_dimension
          description: dimension of character embeddings and of the per-character
            bidirectional GRU. Note that inference time is quadratic in this parameter.
            Supported values are only 16, 24 and 64, with 64 needed for languages
            with complicated tokenization like Japanese, Chinese or Vietnamese or
            complicated segmentation.
          var_type: int
          optional: true
          default: 24
        - environment_var: tokenizer_segment_size
          description: length of character segment used to predict token and sentence
            breaks. Larger values like 200 are needed for languges with complicated
            segmentation
          var_type: int
          optional: true
          default: 50
        - environment_var: tokenizer_epochs
          description: the number of epochs to train the tokenizer for
          var_type: int
          optional: true
          default: 100
        - environment_var: tokenizer_batch_size
          description: batch size (number of segments) used during tokenizer training
          var_type: int
          optional: true
          default: 50
        - environment_var: tokenizer_learning_rate
          description: the learning rate used during tokenizer training
          var_type: float
          optional: true
          default: 0.005
        - environment_var: tokenizer_learning_rate_final
          description: if not zero, use exponential learning rate decay so that last
            epoch uses this learning rate
          var_type: float
          optional: true
          default: 0
        - environment_var: tokenizer_dropout
          description: dropout used during tokenizer training
          var_type: float
          optional: true
          default: 0.1
        - environment_var: tokenizer_early_stopping
          description: perform early stopping, choosing training iteration maximizing
            sentences F1 score plus tokens F1 score on heldout data
          var_type: bool
          optional: true
          default: 1
        - environment_var: tagger
          description: if tagger config should be read or not
          var_type: bool
          optional: true
          default: true
        - environment_var: tagger_use_lemma
          description: use the lemma field internally to perform disambiguation; the
            lemma may be not outputted
          var_type: bool
          optional: true
          default: true
        - environment_var: tagger_provide_lemma
          description: produce the disambiguated lemma on output
          var_type: bool
          optional: true
          default: true
        - environment_var: tagger_use_xpostag
          description: use the XPOS tags internally to perform disambiguation; it
            may not be outputted
          var_type: bool
          optional: true
          default: true
        - environment_var: tagger_provide_xpostag
          description: produce the disambiguated XPOS tag on output
          var_type: bool
          optional: true
          default: true
        - environment_var: tagger_use_feats
          description: use the Feats internally to perform disambiguation; it may
            not be outputted
          var_type: bool
          optional: true
          default: true
        - environment_var: tagger_provide_feats
          description: produce the disambiguated Feats field on output
          var_type: bool
          optional: true
          default: true
        - environment_var: tagger_dictionary_max_form_analyses
          description: the maximum number of (most frequent) form analyses from UD
            training data that are to be kept in the morphological dictionary
          var_type: int
          optional: true
          default: 0
        - environment_var: tagger_dictionary_file
          description: use a given custom morphological dictionary, where each line
            contains 5 tab-separated fields FORM, LEMMA, UPOSTAG, XPOSTAG and FEATS.
            Note that this dictionary data is appended to the dictionary created from
            the UD training data, not replacing it.
          var_type: str
          optional: true
          default: null
        - environment_var: tagger_guesser_suffix_rules
          description: number of rules generated for every suffix
          var_type: int
          optional: true
          default: 8
        - environment_var: tagger_guesser_prefixes_max
          description: maximum number of form-generating prefixes to use in the guesser
          var_type: int
          optional: true
          default: 4
        - environment_var: tagger_guesser_prefix_min_count
          description: minimum number of occurrences of form-generating prefix to
            consider using it in the guesser
          var_type: int
          optional: true
          default: 10
        - environment_var: tagger_guesser_enrich_dictionary
          description: number of rules generated for forms present in training data
            (assuming that the analyses from the training data may not be all)
          var_type: int
          optional: true
          default: 6
        - environment_var: tagger_iterations
          description: number of training iterations to perform
          var_type: int
          optional: true
          default: 20
        - environment_var: tagger_early_stopping
          description: perform early stopping, choosing training iteration maximizing
            tagging accuracy on the heldout data
          var_type: bool
          optional: true
          default: 0
        - environment_var: tagger_templates
          description: MorphoDiTa feature templates to use, either lemmatizer which
            focuses more on lemmas, or tagger which focuses more on UPOS/XPOS/FEATS
          var_type: str
          optional: true
          default: null
        - environment_var: parser
          description: if parser config should be read or not
          var_type: bool
          optional: true
          default: true
        - environment_var: parser_use_gold_tags
          description: if false and a tagger exists, the Lemmas/UPOS/XPOS/FEATS for
            both the training and heldout data are generated by the tagger, otherwise
            they are taken from the gold data
          var_type: bool
          optional: true
          default: false
        - environment_var: parser_embedding_upostag
          description: the dimension of the UPos embedding used in the parser
          var_type: int
          optional: true
          default: 20
        - environment_var: parser_embedding_feats
          description: the dimension of the Feats embedding used in the parser
          var_type: int
          optional: true
          default: 20
        - environment_var: parser_embedding_xpostag
          description: the dimension of the XPos embedding used in the parser
          var_type: int
          optional: true
          default: 0
        - environment_var: parser_embedding_form
          description: the dimension of the Form embedding used in the parser
          var_type: int
          optional: true
          default: 50
        - environment_var: parser_embedding_lemma
          description: the dimension of the Lemma embedding used in the parser
          var_type: int
          optional: true
          default: 0
        - environment_var: parser_embedding_deprel
          description: the dimension of the Deprel embedding used in the parser
          var_type: int
          optional: true
          default: 20
        - environment_var: parser_embedding_form_mincount
          description: for forms not present in the pre-trained embeddings, generate
            random embeddings if the form appears at least this number of times in
            the trainig data (forms not present in the pre-trained embeddings and
            appearing less number of times are considered OOV)
          var_type: int
          optional: true
          default: 2
        - environment_var: parser_embedding_lemma_mincount
          description: for lemmas not present in the pre-trained embeddings, generate
            random embeddings if the lemma appears at least this number of times in
            the trainig data (lemmas not present in the pre-trained embeddings and
            appearing less number of times are considered OOV)
          var_type: int
          optional: true
          default: 2
        - environment_var: parser_iterations
          description: number of training iterations to use
          var_type: int
          optional: true
          default: 10
        - environment_var: parser_hidden_layer
          description: the size of the hidden layer
          var_type: int
          optional: true
          default: 200
        - environment_var: parser_batch_size
          description: batch size used during neural-network training
          var_type: int
          optional: true
          default: 10
        - environment_var: parser_learning_rate
          description: the learning rate used during neural-network training
          var_type: float
          optional: true
          default: 0.02
        - environment_var: parser_learning_rate_final
          description: the final learning rate used during neural-network training
          var_type: float
          optional: true
          default: 0.001
        - environment_var: parser_l2
          description: the L2 regularization used during neural-network training
          var_type: float
          optional: true
          default: 0.5
        - environment_var: parser_early_stopping
          description: perform early stopping, choosing training iteration maximizing
            LAS on heldout data
          var_type: bool
          optional: true
          default: false
    services:
      veld_train:
        build: .
        command: bash /veld/code/train.sh
        volumes:
        - ./data/training/input/:/veld/input/
        - ./data/training/output/:/veld/output/
        - ./src/main/:/veld/code/
        environment:
          train_data_path: null
          model_path: null
          tokenizer: true
          tokenizer_tokenize_url: true
          tokenizer_allow_spaces: null
          tokenizer_dimension: 24
          tokenizer_segment_size: 50
          tokenizer_epochs: 100
          tokenizer_batch_size: 50
          tokenizer_learning_rate: 0.005
          tokenizer_learning_rate_final: 0
          tokenizer_dropout: 0.1
          tokenizer_early_stopping: 1
          tagger: true
          tagger_use_lemma: true
          tagger_provide_lemma: null
          tagger_use_xpostag: null
          tagger_provide_xpostag: null
          tagger_use_feats: null
          tagger_provide_feats: null
          tagger_dictionary_max_form_analyses: 0
          tagger_dictionary_file: null
          tagger_guesser_suffix_rules: 8
          tagger_guesser_prefixes_max: 4
          tagger_guesser_prefix_min_count: 10
          tagger_guesser_enrich_dictionary: 6
          tagger_iterations: 20
          tagger_early_stopping: 0
          tagger_templates: null
          parser: true
          parser_use_gold_tags: null
          parser_embedding_upostag: 20
          parser_embedding_feats: 20
          parser_embedding_xpostag: 0
          parser_embedding_form: 50
          parser_embedding_lemma: 0
          parser_embedding_deprel: 20
          parser_embedding_form_mincount: 2
          parser_embedding_lemma_mincount: 2
          parser_iterations: 10
          parser_hidden_layer: 200
          parser_batch_size: 10
          parser_learning_rate: 0.02
          parser_learning_rate_final: 0.001
          parser_l2: 0.5
          parser_early_stopping: null
veld_code__wikipedia_nlp_preprocessing___data___wikipedia_json___veld_data_extracted.yaml:
  url: https://github.com/veldhub/veld_code__wikipedia_nlp_preprocessing/blob/main/data/wikipedia_json/veld_data_extracted.yaml
  content:
    x-veld:
      data:
        description: null
        topics: NLP
        contents:
        - training data
        - raw text
        file_type: json
        additional:
          data size: '0'
veld_code__wikipedia_nlp_preprocessing___veld_download_and_extract.yaml:
  url: https://github.com/veldhub/veld_code__wikipedia_nlp_preprocessing/blob/main/veld_download_and_extract.yaml
  content:
    x-veld:
      code:
        description: downloading wikipedia archive and extracting each article to
          a json file.
        topic:
        - NLP
        - Machine Learning
        - ETL
        output:
        - volume: /veld/output/
          description: a folder containing json files, where each file contains the
            content of a wikipedia article
          file_type: json
          content:
          - NLP training data
          - raw text
        config:
        - environment_var: wikipedia_dump_url
          description: url to a wikipdedia dump download, from https://dumps.wikimedia.org/
          var_type: str
        - environment_var: out_data_description
          description: short human description for the data and its purpose, will
            be persisted in a data veld yaml
          var_type: str
          optional: true
    services:
      veld_download_and_extract:
        build: .
        volumes:
        - ./src/:/veld/code/:z
        - ./data/wikipedia_json/:/veld/output/:z
        command: bash /veld/code/download_and_extract.sh
        environment:
          wikipedia_dump_url: null
          out_data_description: null
veld_code__wikipedia_nlp_preprocessing___veld_transform_wiki_json_to_txt.yaml:
  url: https://github.com/veldhub/veld_code__wikipedia_nlp_preprocessing/blob/main/veld_transform_wiki_json_to_txt.yaml
  content:
    x-veld:
      code:
        description: transforming wikipedia raw jsons to a single txt file.
        topic:
        - NLP
        - Machine Learning
        - ETL
        input:
        - volume: /veld/input/
          description: a folder containing json files, where each file contains the
            contents of a wikipedia article
          file_type: json
          content:
          - NLP training data
          - raw text
        output:
        - volume: /veld/output/
          description: single txt file, containing only raw content of wikipedia pagaes,
            split into sentences or per article with a newline each, possibly being
            only a sampled subset for testing.
          environment_var: out_txt_file
          file_type: txt
          content:
          - NLP training data
          - Word Embeddings training data
          - raw text
        config:
        - environment_var: out_data_description
          description: short human description for the data and its purpose, will
            be persisted in a data veld yaml
          var_type: str
          optional: true
        - environment_var: cpu_count
          description: number of cpu cores to be used for parallel processing
          var_type: int
          optional: true
          default: maximum number of available cpu cores
        - environment_var: set_split_sentences
          description: Should the resulting txt be split by newlines at each sentence
            boundary? If not, then newlines will be set at the end of each article.
          var_type: bool
          optional: true
          default: false
        - environment_var: sample_size_percentage
          description: As percentage, can be used to transform only a sample of the
            data, for testing purpose most likely. The sample is randomly picked,
            and a random seed can also be set with `sample_random_seed`
          var_type: float
          optional: true
          default: 100
        - environment_var: sample_random_seed
          description: a random seed in case a random sample is drawn and its randomness
            should be fixed.
          var_type: str
          optional: true
          default: null
        - environment_var: buffer_segments
          description: The interval at which progress should be printed. E.g. 100
            means to print hundred times during processing.
          var_type: int
          optional: true
          default: 100
    services:
      veld_transform_wiki_json_to_txt:
        build: .
        volumes:
        - ./src/:/veld/code/:z
        - ./data/wikipedia_json/:/veld/input/
        - ./data/wikipedia_txt/:/veld/output/
        command: python /veld/code/transform_wiki_json_to_txt.py
        environment:
          out_txt_file: null
          out_data_description: null
          cpu_count: null
          set_split_sentences: false
          sample_size_percentage: 100
          sample_random_seed: null
          buffer_segments: 100
veld_code__word2vec___veld_export.yaml:
  url: https://github.com/veldhub/veld_code__word2vec/blob/main/veld_export.yaml
  content:
    x-veld:
      code:
        description: exports a word2vec model to a pkl file containing a python dict,
          where the keys are words and its values are the learned vectors, represented
          as high-dimensional numpy arrays.
        topic:
        - ETL
        - NLP
        - Machine Learning
        - Word Embeddings
        input:
          volume: /veld/input/
          environment_var: in_model_file
          file_type: word2vec model
          content:
          - Word Embeddings model
          - Word Embeddings vectors
        output:
          volume: /veld/output/
          environment_var: out_vector_file
          file_type: pkl
          content:
          - Word Embeddings model
          - Word Embeddings vectors
    services:
      veld_export:
        build: .
        command: python /veld/code/export.py
        volumes:
        - ./src/export/:/veld/code/
        environment:
          in_model_file: null
          out_vector_file: null
veld_code__word2vec___veld_jupyter_notebook.yaml:
  url: https://github.com/veldhub/veld_code__word2vec/blob/main/veld_jupyter_notebook.yaml
  content:
    x-veld:
      code:
        description: a word2vec jupyter notebook, for quick experiments
        topic:
        - NLP
        - Machine Learning
        - Word Embeddings
        input:
        - volume: /veld/input/
          description: arbitrary storage for word2vec experiments
          file_type:
          - word2vec model
          - txt
          content:
          - NLP model
          - Word Embeddings model
          - model metadata
          - NLP training data
          - Word Embeddings training data
          - raw text
        output:
        - volume: /veld/output/
          description: arbitrary storage for word2vec experiments
          file_type:
          - word2vec model
          - txt
          content:
          - NLP model
          - Word Embeddings model
          - model metadata
          - NLP training data
          - Word Embeddings training data
          - raw text
    services:
      veld_jupyter_notebook:
        build: .
        command: jupyter notebook --allow-root --ip='*' --NotebookApp.token='' --NotebookApp.password=''
        ports:
        - 8888:8888
        volumes:
        - ./src/jupyter_notebook/:/veld/code/:z
        - ./data/input/:/veld/input/:z
        - ./data/output/:/veld/output/:z
veld_code__word2vec___veld_train.yaml:
  url: https://github.com/veldhub/veld_code__word2vec/blob/main/veld_train.yaml
  content:
    x-veld:
      code:
        description: A word2vec training setup
        topic:
        - NLP
        - Machine Learning
        - Word Embeddings
        input:
        - volume: /veld/input/
          environment_var: in_train_data_file
          description: training data. Must be one single txt file, one sentence per
            line.
          file_type: txt
          content:
          - NLP training data
          - Word Embeddings training data
          - raw text
        output:
        - volume: /veld/output/
          environment_var: out_model_file
          description: self trained Word Embeddings word2vec model
          file_type: word2vec model
          content:
          - NLP model
          - Word Embeddings model
        config:
        - environment_var: train_data_description
          description: short human description for the kind of training data
          var_type: str
          optional: true
        - environment_var: model_description
          description: short human description for the overall model and its purpose
          var_type: str
          optional: true
        - environment_var: epochs
          description: 'word2vec hyperparameter: number of training epochs'
          var_type: int
          optional: true
          default: 50
        - environment_var: vector_size
          description: 'word2vec hyperparameter: number of dimensions of the word
            vectors'
          var_type: int
          default: 200
        - environment_var: window
          description: 'word2vec hyperparameter: number of surrounding context words
            to be used for training.'
          var_type: int
          default: 3
        - environment_var: min_count
          description: 'word2vec hyperparameter: minimal number of occurrence for
            each word to be used for training.'
          var_type: int
          default: 5
    services:
      veld_train:
        build: .
        command: python /veld/code/train.py
        volumes:
        - ./src/train/:/veld/code/:z
        - ./data/training_data/:/veld/input/:z
        - ./data/models/:/veld/output/:z
        environment:
          in_train_data_file: null
          out_model_file: null
          model_description: null
          epochs: 50
          vector_size: 200
          window: 3
          min_count: 5
veld_code__wordembeddings_evaluation___veld_analyse_evaluation.yaml:
  url: https://github.com/veldhub/veld_code__wordembeddings_evaluation/blob/main/veld_analyse_evaluation.yaml
  content:
    x-veld:
      code:
        description: data visualization of all evaluation data. In a jupyter notebook.
        topic:
        - NLP
        - Word Embeddings
        - Data Visualization
        input:
        - volume: /veld/
          environment_var: in_evaluation_summary_file
          description: summary of the custom evaluation logic on word embeddings
          file_type: yaml
          content: Evaluation data
        output:
        - volume: /veld/output/
          environment_var: out_visualization_html_file
          description: data visualization of all evaluation data, expressed as interactive
            html
          file_type: html
          content: data visualization
        - volume: /veld/output/
          environment_var: out_visualization_png_file
          description: data visualization of all evaluation data, expressed as png
          file_type: png
          content: data visualization
    services:
      veld_analyse_evaluation:
        build:
          context: .
          dockerfile: ./build_analyse.dockerfile
        command: jupyter notebook --allow-root --ip='*' --NotebookApp.token='' --NotebookApp.password=''
        ports:
        - 8888:8888
        volumes:
        - ./src/analyse/:/veld/code/:z
        environment:
          in_evaluation_summary_file: null
          out_visualization_html_file: null
          out_visualization_png_file: null
veld_code__wordembeddings_evaluation___veld_analyse_evaluation_non_interactive.yaml:
  url: https://github.com/veldhub/veld_code__wordembeddings_evaluation/blob/main/veld_analyse_evaluation_non_interactive.yaml
  content:
    x-veld:
      code:
        description: data visualization of all evaluation data. non-interactive version
          of the juypter code.
        topic:
        - NLP
        - Word Embeddings
        - Data Visualization
        input:
        - volume: /veld/input/
          environment_var: in_evaluation_summary_file
          description: summary of the custom evaluation logic on word embeddings
          file_type: yaml
          content: evaluation data
        output:
        - volume: /veld/output/
          environment_var: out_visualization_html_file
          description: data visualization of all evaluation data, expressed as interactive
            html
          file_type: html
          content: data visualization
        - volume: /veld/output/
          environment_var: out_visualization_png_file
          description: data visualization of all evaluation data, expressed as png
          file_type: png
          content: data visualization
    services:
      veld_analyse_evaluation:
        build:
          context: .
          dockerfile: ./build_analyse.dockerfile
        command: bash /veld/code/analyse.sh
        volumes:
        - ./src/analyse/:/veld/code/:z
        environment:
          in_evaluation_summary_file: null
          out_visualization_html_file: null
          out_visualization_png_file: null
veld_code__wordembeddings_evaluation___veld_eval_fasttext.yaml:
  url: https://github.com/veldhub/veld_code__wordembeddings_evaluation/blob/main/veld_eval_fasttext.yaml
  content:
    x-veld:
      code:
        description: custom evaluation logic on fasttext word embeddings.
        topic:
        - NLP
        - Machine Learning
        - Evaluation
        input:
        - volume: /veld/input/model/
          environment_var: in_model_file
          file_type: fastText model
          content:
          - NLP model
          - Word Embeddings model
        - volume: /veld/input/model/
          environment_var: in_model_metadata_file
          file_type: yaml
          content: metadata
        - volume: /veld/input/eval_data/
          environment_var: in_eval_gold_data_file
          file_type: yaml
          content: NLP gold data
        output:
        - volume: /veld/output/summary/
          environment_var: out_eval_summary_file
          file_type: yaml
          description: ''
        - volume: /veld/output/log/
          environment_var: out_eval_log_file
          file_type: txt
          content: log
    services:
      veld_eval_fasttext:
        build:
          context: .
          dockerfile: ./build_fasttext.dockerfile
        command: python eval_fasttext.py
        volumes:
        - ./src/:/veld/code/:z
        environment:
          in_model_file: null
          in_model_metadata_file: null
          in_2_eval_gold_data_file: null
          out_1_eval_summary_file: null
          out_2_eval_log_file: null
veld_code__wordembeddings_evaluation___veld_eval_glove.yaml:
  url: https://github.com/veldhub/veld_code__wordembeddings_evaluation/blob/main/veld_eval_glove.yaml
  content:
    x-veld:
      code:
        description: custom evaluation logic on GloVe word embeddings.
        topic:
        - NLP
        - Machine Learning
        - Evaluation
        input:
        - volume: /veld/input/model/
          environment_var: in_vector_file
          file_type: GloVe model
          content:
          - NLP model
          - Word Embeddings model
        - volume: /veld/input/model/
          environment_var: in_model_metadata_file
          file_type: yaml
          content: metadata
        - volume: /veld/input/eval_data/
          environment_var: in_eval_gold_data_file
          file_type: yaml
          content: NLP gold data
        output:
        - volume: /veld/output/summary/
          environment_var: out_eval_summary_file
          file_type: yaml
          description: ''
        - volume: /veld/output/log/
          environment_var: out_eval_log_file
          file_type: txt
          content: log
        config:
        - environment_var: model_id
          description: id of the model
          var_type: str
    services:
      veld_eval_glove:
        build:
          context: .
          dockerfile: ./build_glove.dockerfile
        command: python3 eval_glove.py
        volumes:
        - ./src/:/veld/code/:z
        environment:
          in_1_vector_file: null
          model_id: null
          in_1_model_metadata_file: null
          in_2_eval_gold_data_file: null
          out_1_eval_summary_file: null
          out_2_eval_log_file: null
veld_code__wordembeddings_evaluation___veld_eval_word2vec.yaml:
  url: https://github.com/veldhub/veld_code__wordembeddings_evaluation/blob/main/veld_eval_word2vec.yaml
  content:
    x-veld:
      code:
        description: custom evaluation logic on word2vec word embeddings.
        topic:
        - NLP
        - Machine Learning
        - Evaluation
        input:
        - volume: /veld/input/model/
          environment_var: in_model_file
          description: word2vec model file to be evaluated
          file_type: word2vec model
          content:
          - NLP model
          - word embeddings model
        - volume: /veld/input/model/
          environment_var: in_model_metadata_file
          description: word2vec model metadata
          file_type: yaml
          content: metadata
        - volume: /veld/input/eval_data/
          environment_var: in_eval_gold_data_file
          file_type: yaml
          content: NLP gold data
        output:
        - volume: /veld/output/summary/
          environment_var: out_eval_summary_file
          file_type: yaml
        - volume: /veld/output/log/
          environment_var: out_eval_log_file
          file_type: txt
          content: log
    services:
      veld_eval_word2vec:
        build:
          context: .
          dockerfile: ./build_word2vec.dockerfile
        command: python eval_word2vec.py
        volumes:
        - ./src/:/veld/code/:z
        - ./data/models/:/veld/input/1/:z
        - ./data/evaluation_gold_data/:/veld/input/2/:z
        - ./data/evaluation_results/summary/:/veld/output/1/:z
        - ./data/evaluation_results/logs/:/veld/output/2/:z
        environment:
          in_1_model_file: null
          in_1_model_metadata_file: null
          in_2_eval_gold_data_file: null
          out_1_eval_summary_file: null
          out_2_eval_log_file: null
veld_code__wordembeddings_preprocessing___veld_preprocess_clean.yaml:
  url: https://github.com/veldhub/veld_code__wordembeddings_preprocessing/blob/main/veld_preprocess_clean.yaml
  content:
    x-veld:
      code:
        description: Removes lines that don't reach a threshold regarding the ratio
          of textual content to non-textual (numbers, special characters) content.
          Splits output into clean and dirty file.
        topic:
        - NLP
        - Preprocessing
        - ETL
        input:
        - volume: /veld/input/
          environment_var: in_file
          file_type: txt
          content: raw text
        output:
        - volume: /veld/output/
          environment_var: out_file_clean
          description: clean lines, where each line's ratio is above the configured
            threshold
          file_type: txt
          content: raw text
        - volume: /veld/output/
          environment_var: out_file_dirty
          description: dirty lines, where each line's ratio is below the configured
            threshold
          file_type: txt
          content: raw text
        config:
        - environment_var: min_percentage_char
          description: threshold above which a line is considered clean. E.g. 80 means
            80% of character of a line must be textual
          var_type: int
        - environment_var: out_data_description
          description: automatic data description for generating a data veld yaml
            file
          var_type: str
        - environment_var: cpu_count
          description: number of cpu cores allocated to this processing. Defaults
            to maximum number of available cores
          var_type: int
        - environment_var: buffer_segments
          description: percentage of segments where processing results are persisted
            in between. So that processing could continue should it have crashed
          var_type: int
          default: 100
        - environment_var: sleep_duration
          description: number of seceonds between each multiprocess invokation, since
            with big data, a memory race condition can occurr. To work-around this,
            a small waiting period in between can be set with this variable.
          var_type: int
          default: 10
    services:
      veld_preprocess_clean:
        build: .
        volumes:
        - ./src/:/veld/code/:z
        command: python3 /veld/code/preprocess_clean.py
        environment:
          in_file: null
          out_file_clean: null
          out_file_dirty: null
          out_data_veld_yaml: null
          min_percentage_char: null
          out_data_description: null
          cpu_count: null
          buffer_segments: 100
          sleep_duration: 10
veld_code__wordembeddings_preprocessing___veld_preprocess_lowercase.yaml:
  url: https://github.com/veldhub/veld_code__wordembeddings_preprocessing/blob/main/veld_preprocess_lowercase.yaml
  content:
    x-veld:
      code:
        description: makes entire text lowercase
        topic:
        - NLP
        - Preprocessing
        - ETL
        input:
        - volume: /veld/input/
          environment_var: in_txt_file
          file_type: txt
          content: raw text
        output:
        - volume: /veld/output/
          environment_var: out_txt_file
          file_type: txt
          content: raw text
        config:
        - environment_var: out_data_description
          description: automatic data description for generating a data veld yaml
            file
          var_type: str
    services:
      veld_preprocess_lowercase:
        build: .
        volumes:
        - ./src/:/veld/code/:z
        command: python3 /veld/code/preprocess_lowercase.py
        environment:
          in_txt_file: null
          out_txt_file: null
          out_data_description: null
veld_code__wordembeddings_preprocessing___veld_preprocess_remove_punctuation.yaml:
  url: https://github.com/veldhub/veld_code__wordembeddings_preprocessing/blob/main/veld_preprocess_remove_punctuation.yaml
  content:
    x-veld:
      code:
        description: removes punctuation from text with spaCy pretrained models
        topic:
        - NLP
        - Preprocessing
        - ETL
        input:
        - volume: /veld/input/
          environment_var: in_txt_file
          file_type: txt
          content: raw text
        output:
        - volume: /veld/output/txt/
          environment_var: out_txt_file
          file_type: txt
          content: raw text
        - volume: /veld/output/tmp/
          file_type: txt
          content: raw text
        config:
        - environment_var: out_data_description
          description: automatic data description for generating a data veld yaml
            file
          var_type: str
        - environment_var: cpu_count
          description: number of cpu cores allocated to this processing. Defaults
            to maximum number of available cores
          var_type: int
        - environment_var: buffer_segments
          description: percentage of segments where processing results are persisted
            in between. So that processing could continue should it have crashed
          var_type: int
          default: 100
        - environment_var: sleep_duration
          description: number of seceonds between each multiprocess invokation, since
            with big data, a memory race condition can occurr. To work-around this,
            a small waiting period in between can be set with this variable.
          var_type: int
          default: 10
    services:
      veld_preprocess_remove_punctuation:
        build: .
        volumes:
        - ./src/:/veld/code/:z
        command: python3 -u /veld/code/preprocess_remove_punctuation.py
        environment:
          in_txt_file: null
          out_txt_file: null
          cpu_count: null
          buffer_segments: 100
          out_data_description: null
          sleep_duration: 10
veld_code__wordembeddings_preprocessing___veld_preprocess_sample.yaml:
  url: https://github.com/veldhub/veld_code__wordembeddings_preprocessing/blob/main/veld_preprocess_sample.yaml
  content:
    x-veld:
      code:
        description: takes a random sample of lines from a txt file. Randomness can
          be set with a seed too
        topic:
        - NLP
        - Preprocessing
        - ETL
        input:
        - volume: /veld/input/
          environment_var: in_txt_file
          file_type: txt
          content: raw text
        output:
        - volume: /veld/output/
          environment_var: out_txt_file
          file_type: txt
          content: raw text
        config:
        - environment_var: out_data_description
          description: automatic data description for generating a data veld yaml
            file
          var_type: str
        - environment_var: percentage_sample
          description: percentage of lines to be randomly sampled
          var_type: int
        - environment_var: sample_random_seed
          description: seed to make randomness stable and reproducible
          var_type: str
        - environment_var: buffer_segments
          description: percentage of segments where processing results are persisted
            in between. So that processing could continue should it have crashed
          var_type: int
          default: 100
    services:
      veld_preprocess_sample:
        build: .
        volumes:
        - ./src/:/veld/code/:z
        command: python3 /veld/code/preprocess_sample.py
        environment:
          in_file: null
          out_file: null
          out_data_description: null
          percentage_sample: null
          sample_random_seed: null
          buffer_segments: 100
veld_code__wordembeddings_preprocessing___veld_preprocess_strip.yaml:
  url: https://github.com/veldhub/veld_code__wordembeddings_preprocessing/blob/main/veld_preprocess_strip.yaml
  content:
    x-veld:
      code:
        description: removes all lines before and after given line numbers
        topic:
        - NLP
        - Preprocessing
        - ETL
        input:
        - volume: /veld/input/
          environment_var: in_file
          file_type: txt
          content: raw text
        output:
        - volume: /veld/output/
          environment_var: out_file
          file_type: txt
          content: raw text
        config:
        - environment_var: line_start
          description: line number before which lines will be stripped away. E.g.
            line_start=50 removes lines from 1-49
          var_type: int
        - environment_var: line_end
          description: line number after which lines will be stripped away. E.g. line_end=100
            removes lines from 101-end
          var_type: int
    services:
      veld_preprocess_strip:
        build: .
        volumes:
        - ./src/:/veld/code/:z
        command: bash /veld/code/preprocess_strip.sh
        environment:
          in_file: null
          out_file: null
          line_start: null
          line_end: null
veld_code__xmlanntools___veld_ann2standoff.yaml:
  url: https://github.com/veldhub/veld_code__xmlanntools/blob/main/veld_ann2standoff.yaml
  content:
    x-veld:
      code:
        description: 'A demo code veld, integrating the ann2standoff script. For more
          documentation, see: https://github.com/czcorpus/xmlanntools?tab=readme-ov-file#ann2standoff'
        topic:
        - NLP
        - ETL
        input:
        - volume: /veld/input/data/
          environment_var: in_conllu_file
          file_type:
          - conllu
          - tsv
        - volume: /veld/input/data/
          environment_var: in_txt_file
          file_type: txt
        - volume: /veld/input/config/
          environment_var: in_ann2standoff_ini_file
          file_type: ini
        output:
        - volume: /veld/output/
          environment_var: out_json_file
          file_type: json
        config:
        - environment_var: profile_name
          var_type: str
          default: DEFAULT
          optional: true
    services:
      veld_ann2standoff:
        build: .
        volumes:
        - ./:/veld/code/
        - ./data/ann2standoff/in/data/:/veld/input/data/
        - ./data/ann2standoff/in/config/:/veld/input/config/
        - ./data/ann2standoff/out/:/veld/output/
        command: bash /veld/code/veld_ann2standoff.sh
        environment:
          in_conllu_file: null
          in_txt_file: null
          in_ann2standoff_ini_file: null
          out_json_file: null
          profile_name: DEFAULT
veld_code__xmlanntools___veld_standoff2xml.yaml:
  url: https://github.com/veldhub/veld_code__xmlanntools/blob/main/veld_standoff2xml.yaml
  content:
    x-veld:
      code:
        description: 'A demo code veld, integrating the standoff2xml script. For more
          documentation, see: https://github.com/czcorpus/xmlanntools?tab=readme-ov-file#standoff2xml'
        topic:
        - NLP
        - ETL
        input:
        - volume: /veld/input/
          environment_var: in_txt_file
          file_type: txt
        - volume: /veld/input/
          environment_var: in_json_file
          file_type: json
        - volume: /veld/input/
          environment_var: in_ann_json_file
          file_type: json
        output:
        - volume: /veld/output/
          environment_var: out_ann_xml_file
          file_type: xml
        config:
        - environment_var: token_annotation
          var_type: bool
          default: false
          optional: true
        - environment_var: warn_breaking
          var_type: str
          optional: true
        - environment_var: keep_between_sentences
          var_type: bool
          default: false
          optional: true
    services:
      veld_standoff2xml:
        build: .
        volumes:
        - ./:/veld/code/
        - ./data/standoff2xml/in/:/veld/input/
        - ./data/standoff2xml/out/:/veld/output/
        command: bash /veld/code/veld_standoff2xml.sh
        environment:
          in_txt_file: null
          in_json_file: null
          in_ann_json_file: null
          out_ann_xml_file: null
          token_annotation: false
          warn_breaking: null
          keep_between_sentences: false
veld_code__xmlanntools___veld_tag_ud.yaml:
  url: https://github.com/veldhub/veld_code__xmlanntools/blob/main/veld_tag_ud.yaml
  content:
    x-veld:
      code:
        description: 'A demo code veld, integrating the tag_ud script. For more documentation,
          see: https://github.com/czcorpus/xmlanntools?tab=readme-ov-file#tag_ud'
        topic:
        - NLP
        - ETL
        input:
        - volume: /veld/input/
          environment_var: in_txt_file
          file_type: txt
        output:
        - volume: /veld/output/
          environment_var: out_conllu_file
          file_type:
          - tsv
          - conllu
        config:
        - environment_var: model
          var_type: str
        - environment_var: batch
          var_type: int
          default: 1000
          optional: true
        - environment_var: verbose
          var_type: bool
          default: false
          optional: true
    services:
      veld_tag_ud:
        build: .
        volumes:
        - ./:/veld/code/
        - ./data/tag_ud/in/:/veld/input/
        - ./data/tag_ud/out/:/veld/output/
        command: bash /veld/code/veld_tag_ud.sh
        environment:
          in_txt_file: null
          out_conllu_file: null
          model: null
          batch: 1000
          verbose: false
veld_code__xmlanntools___veld_xml2standoff.yaml:
  url: https://github.com/veldhub/veld_code__xmlanntools/blob/main/veld_xml2standoff.yaml
  content:
    x-veld:
      code:
        description: 'A demo code veld, integrating the xml2standoff script. For more
          documentation, see: https://github.com/czcorpus/xmlanntools?tab=readme-ov-file#xml2standoff'
        topic:
        - NLP
        - ETL
        input:
        - volume: /veld/input/
          environment_var: in_xml_file
          file_type: xml
        output:
        - volume: /veld/output/
          environment_var: out_txt_file
          file_type: txt
        - volume: /veld/output/
          environment_var: out_json_file
          file_type: json
        config:
        - environment_var: text_elements
          var_type: str
          optional: true
        - environment_var: exclude_elements
          var_type: str
          optional: true
        - environment_var: keep_linebreaks
          var_type: bool
          default: false
          optional: true
    services:
      veld_xml2standoff:
        build: .
        volumes:
        - ./:/veld/code/
        - ./data/xml2standoff/in/:/veld/input/
        - ./data/xml2standoff/out/:/veld/output/
        command: bash /veld/code/./veld_xml2standoff.sh
        environment:
          in_xml_file: null
          out_txt_file: null
          out_json_file: null
          text_elements: null
          exclude_elements: null
          keep_linebreaks: false
veld_code__xmlanntools___veld_xml2vrt.yaml:
  url: https://github.com/veldhub/veld_code__xmlanntools/blob/main/veld_xml2vrt.yaml
  content:
    x-veld:
      code:
        description: 'A demo code veld, integrating the xml2vrt script. For more documentation,
          see: https://github.com/czcorpus/xmlanntools?tab=readme-ov-file#xml2vrt'
        topic:
        - NLP
        - ETL
        input:
        - volume: /veld/input/data/
          environment_var: in_ann_xml_file
          file_type: xml
        - volume: /veld/input/config/
          environment_var: in_ann2standoff_ini_file
          file_type: ini
        output:
        - volume: /veld/output/
          environment_var: out_conlluish_xml_file
          file_type: xml
        config:
        - environment_var: attributes
          var_type: str
          optional: true
        - environment_var: token_element
          var_type: str
          optional: true
        - environment_var: include_elements
          var_type: str
          optional: true
        - environment_var: exclude_elements
          var_type: str
          optional: true
        - environment_var: keep_token_tags
          var_type: bool
          default: false
          optional: true
        - environment_var: keep_empty
          var_type: bool
          default: false
          optional: true
        - environment_var: discard_freetext
          var_type: bool
          default: false
          optional: true
        - environment_var: no_glue
          var_type: bool
          default: false
          optional: true
        - environment_var: glue
          var_type: str
          optional: true
        - environment_var: fragment
          var_type: bool
          default: false
          optional: true
        - environment_var: no_flattening
          var_type: bool
          default: false
          optional: true
    services:
      veld_xml2vrt:
        build: .
        volumes:
        - ./:/veld/code/
        - ./data/xml2vrt/in/data/:/veld/input/data/
        - ./data/xml2vrt/in/config/:/veld/input/config/
        - ./data/xml2vrt/out/:/veld/output/
        command: bash /veld/code/veld_xml2vrt.sh
        environment:
          in_ann_xml_file: null
          in_ann2standoff_ini_file: null
          out_conlluish_xml_file: null
          attributes: null
          token_element: null
          include_elements: null
          exclude_elements: null
          keep_token_tags: false
          keep_empty: false
          discard_freetext: false
          no_glue: false
          glue: null
          fragment: false
          no_flattening: false
veld_code__xml_xslt_transformer___veld.yaml:
  url: https://github.com/veldhub/veld_code__xml_xslt_transformer/blob/main/veld.yaml
  content:
    x-veld:
      code:
        description: generic xml / xslt transformation setup.
        topic:
        - ETL
        - Preprocessing
        input:
        - volume: /veld/input/xml/
          environment_var: in_xml_file
          description: the input xml file or folder containing xml. Note that if var
            `in_xml_file` is set, this script will only transform that file. If it's
            not set, it will go through the input folder recursively and create an
            equivalent output data structure.
          file_type: xml
          optional: true
        - volume: /veld/input/xsl/
          environment_var: in_xsl_file
          description: the input xsl file or folder containing xsl
          file_type: xslt
          optional: true
        output:
        - volume: /veld/output/
          environment_var: out_txt_file
          description: output file or folder for converted txt. Note that the var
            'out_txt_file' is only respected, when the input is a single xml file.
            If the input is a folder, the output will be an equivalent data structure
            and the var 'out_txt_file' is ignored.
          file_type:
          - xml
          - txt
    services:
      veld:
        build: .
        command: bash /veld/code/transform.sh
        volumes:
        - ./src/:/veld/code/
        environment:
          in_xsl_file: null
          in_xml_file: null
          out_txt_file: null
veld_chain__akp_ner_inference___veld_infer.yaml:
  url: https://github.com/veldhub/veld_chain__akp_ner_inference/blob/main/veld_infer.yaml
  content:
    x-veld:
      chain:
        description: This repo uses self-trained spaCy NER models on the linkedcat
          dataset to extract entities, which are stored in csv files.
        topic:
        - NLP
        - Machine Learning
        - Named Entity Recognition
    services:
      veld_infer:
        extends:
          file: ./code/veld_code__akp_ner_inference/veld_infer.yaml
          service: veld_infer
        volumes:
        - ./data/veld_data__apis_spacy_ner_models/m1/model-best/:/veld/input/
        - ./data/veld_data__akp_ner_linkedcat/linkedcat2/:/veld/output/
        environment:
          solr_core_url: http://linkedcat-solr.acdh-cluster-2.arz.oeaw.ac.at/solr/linkedcat2
          out_csv_file: linkedcat2.csv
veld_chain__apis_ner_evaluate_old_models___veld_evaluate.yaml:
  url: https://github.com/veldhub/veld_chain__apis_ner_evaluate_old_models/blob/main/veld_evaluate.yaml
  content:
    x-veld:
      chain:
        description: hard-coded evaluation of several spaCy 2.2.4 models. This chain
          veld is a wrapper of legacy code.
        topic:
        - NLP
        - Machine Learning
        - Named Entity Recognition
    services:
      veld_evaluate:
        build: ./code/
        command: python /veld/code/reevaluate_all_models.py
        volumes:
        - ./code/src/:/veld/code/
        - ./data/spacy-ner/:/veld/input/
        - ./data/spacy-ner/:/veld/output/
        environment:
          out_eval_result_file: reevaluations_all.md
veld_chain__apis_ner_transform_to_gold___veld.yaml:
  url: https://github.com/veldhub/veld_chain__apis_ner_transform_to_gold/blob/main/veld.yaml
  content:
    x-veld:
      chain:
        description: Conversion of apis ner model data to harmonized custom json format.
        topic:
        - ETL
        - Data Cleaning
    services:
      veld:
        build: ./code/
        command: python /veld/code/extract_and_clean.py
        volumes:
        - ./code/src/:/veld/code/
        - ./data/veld_data__apis_spacy_ner_legacy/:/veld/input/
        - ./data/veld_data__apis_oebl__ner_gold/data_uncleaned:/veld/output/uncleaned/
        - ./data/veld_data__apis_oebl__ner_gold/data_cleaned:/veld/output/cleaned/
        - ./data/veld_data__apis_oebl__ner_gold/data_cleaned_simplified:/veld/output/cleaned_simplified/
        - ./:/veld/output/log/
        environment:
          out_json_uncleaned_file: uncleaned.json
          out_json_cleaned_file: cleaned.json
          out_json_cleaned_simplified_file: cleaned_simplified.json
          out_log_file: extract_and_clean.log
veld_chain__automatic_tei-ification_of_gutenberg___veld_multichain_all.yaml:
  url: https://github.com/veldhub/veld_chain__automatic_tei-ification_of_gutenberg/blob/main/veld_multichain_all.yaml
  content:
    x-veld:
      chain: null
    services:
      veld_step1_download_gutenberg_metadata:
        extends:
          file: ./veld_step1_download_gutenberg_metadata.yaml
          service: veld_step1_download_gutenberg_metadata
      veld_step2_run_server:
        extends:
          file: ./veld_step2_run_server.yaml
          service: veld_step2_run_server
        depends_on:
          veld_step1_download_gutenberg_metadata:
            condition: service_completed_successfully
      veld_step3_import_rdf:
        extends:
          file: ./veld_step3_import_rdf.yaml
          service: veld_step3_import_rdf
        depends_on:
          veld_step2_run_server:
            condition: service_healthy
      veld_step4_query_books_urls:
        extends:
          file: ./veld_step4_query_books_urls.yaml
          service: veld_step4_query_books_urls
        depends_on:
          veld_step3_import_rdf:
            condition: service_completed_successfully
      veld_step5_download_gutenberg_books:
        extends:
          file: ./veld_step5_download_gutenberg_books.yaml
          service: veld_step5_download_gutenberg_books
        depends_on:
          veld_step4_query_books_urls:
            condition: service_completed_successfully
    networks:
      veld_fuseki: null
veld_chain__automatic_tei-ification_of_gutenberg___veld_step1_download_gutenberg_metadata.yaml:
  url: https://github.com/veldhub/veld_chain__automatic_tei-ification_of_gutenberg/blob/main/veld_step1_download_gutenberg_metadata.yaml
  content:
    x-veld:
      chain:
        description: Downloads and extracts the project gutenberg metadata.
        topic: ETL
    services:
      veld_step1_download_gutenberg_metadata:
        extends:
          file: ./code/veld_code__downloader/veld.yaml
          service: veld_downloader
        volumes:
        - ./data/gutenberg_rdf/:/veld/output/
        environment:
          url: https://gutenberg.org/cache/epub/feeds/rdf-files.tar.bz2
          out_file: rdf-files.tar.bz2
          do_extract: true
veld_chain__automatic_tei-ification_of_gutenberg___veld_step2_run_server.yaml:
  url: https://github.com/veldhub/veld_chain__automatic_tei-ification_of_gutenberg/blob/main/veld_step2_run_server.yaml
  content:
    x-veld:
      chain:
        description: An Apache Fuseki instance storing the entire gutenberg metadata.
        topic:
        - RDF
        - triplestore
        - database
    services:
      veld_step2_run_server:
        extends:
          file: ./code/veld_code__apache_jena_fuseki/veld_run_server.yaml
          service: veld_run_server
        volumes:
        - ./data/fuseki_data/:/veld/storage/
        - ./data/fuseki_config/:/veld/input/config/
    networks:
      veld_fuseki: null
veld_chain__automatic_tei-ification_of_gutenberg___veld_step3_import_rdf.yaml:
  url: https://github.com/veldhub/veld_chain__automatic_tei-ification_of_gutenberg/blob/main/veld_step3_import_rdf.yaml
  content:
    x-veld:
      chain:
        description: imports the gutenberg metadata into the Fuseki triplestore.
        topic:
        - ETL
        - RDF
        - triplestore
    services:
      veld_step3_import_rdf:
        extends:
          file: ./code/veld_code__apache_jena_fuseki/veld_import_rdf.yaml
          service: veld_import_rdf
        volumes:
        - ./data/gutenberg_rdf/rdf-files/cache/epub/:/veld/input/
        environment:
          fuseki_server_url: http://veld_step2_run_server
          fuseki_dataset_name: gutenberg
    networks:
      veld_fuseki: null
veld_chain__automatic_tei-ification_of_gutenberg___veld_step4_query_books_urls.yaml:
  url: https://github.com/veldhub/veld_chain__automatic_tei-ification_of_gutenberg/blob/main/veld_step4_query_books_urls.yaml
  content:
    x-veld:
      chain:
        description: Exports a csv file containing download links and file names of
          all german books that have no TEI files, but a txt, which will be used for
          automatic TEI generation further downstream.
        topic:
        - ETL
        - RDF
        - triplestore
    services:
      veld_step4_query_books_urls:
        extends:
          file: ./code/veld_code__apache_jena_fuseki/veld_export.yaml
          service: veld_export
        volumes:
        - ./data/queries/:/veld/input/
        - ./data/fuseki_export/:/veld/output/
        environment:
          in_query_file: german_books_txt_no_tei.rq
          out_file: german_books_txt_no_tei.csv
          out_format: csv
          fuseki_server_url: http://veld_step2_run_server
          fuseki_dataset_name: gutenberg
    networks:
      veld_fuseki: null
veld_chain__automatic_tei-ification_of_gutenberg___veld_step5_download_gutenberg_books.yaml:
  url: https://github.com/veldhub/veld_chain__automatic_tei-ification_of_gutenberg/blob/main/veld_step5_download_gutenberg_books.yaml
  content:
    x-veld:
      chain:
        description: Downlaods all german books without TEI, as designated by the
          previously generated csv.
        topic: ETL
    services:
      veld_step5_download_gutenberg_books:
        extends:
          file: ./code/veld_code__downloader/veld.yaml
          service: veld_downloader
        volumes:
        - ./data/fuseki_export/:/veld/input/
        - ./data/gutenberg_books/:/veld/output/
        environment:
          in_csv_file: german_books_txt_no_tei.csv
veld_chain__automatic_tei-ification_of_gutenberg___veld_step6_convert_books_to_teitok.yaml:
  url: https://github.com/veldhub/veld_chain__automatic_tei-ification_of_gutenberg/blob/main/veld_step6_convert_books_to_teitok.yaml
  content:
    x-veld:
      chain:
        description: Automatic creation of tokenized TEI files of downloaded txt books
        topic:
        - NLP
        - Grammatical Annotation
        - Universal Dependencies
        - Tokenization
        - Lemmatization
        - Part Of Speech
        - Dependency Parsing
    services:
      veld_step6_convert_books_to_teitok:
        extends:
          file: ./code/veld_code__teitok-tools/veld_udpipe2teitok.yaml
          service: veld_udpipe2teitok
        volumes:
        - ./data/gutenberg_books/:/veld/input/
        - ./data/gutenberg_teitok:/veld/output/
        environment:
          lang: de
          model: german-hdt-ud-2.6-200830
veld_chain__compare_tokenizations___code___veld_code__jupyter_analysis___veld.yaml:
  url: https://github.com/veldhub/veld_chain__compare_tokenizations/blob/main/code/veld_code__jupyter_analysis/veld.yaml
  content:
    x-veld:
      code:
        description: template veld code repo for a juptyer notebook
    services:
      veld:
        build: .
        command: jupyter notebook --allow-root --ip='*' --NotebookApp.token='' --NotebookApp.password=''
        ports:
        - 8888:8888
        working_dir: /veld/code/
        volumes:
        - ./src:/veld/code/
        - ./volumes/input/:/veld/input/
        - ./volumes/output/:/veld/output/
veld_chain__compare_tokenizations___veld_step_1_download.yaml:
  url: https://github.com/veldhub/veld_chain__compare_tokenizations/blob/main/veld_step_1_download.yaml
  content:
    x-veld:
      chain:
        description: null
        topic: null
    services:
      veld_step_1_download_xmlanntools:
        extends:
          file: ./code/veld_code__downloader/veld.yaml
          service: veld_downloader
        volumes:
        - ./data/xmlanntools/:/veld/output/
        environment:
          url: https://raw.githubusercontent.com/COST-ELTeC/ELTeC-deu/refs/heads/master/level1/DEU100.xml
          out_file: DEU100.xml
      veld_step_1_download_teitok:
        extends:
          file: ./code/veld_code__downloader/veld.yaml
          service: veld_downloader
        volumes:
        - ./data/teitok/:/veld/output/
        environment:
          url: https://raw.githubusercontent.com/COST-ELTeC/ELTeC-deu/refs/heads/master/level1/DEU100.xml
          out_file: DEU100.xml
veld_chain__compare_tokenizations___veld_step_2_xmlanntools.yaml:
  url: https://github.com/veldhub/veld_chain__compare_tokenizations/blob/main/veld_step_2_xmlanntools.yaml
  content:
    x-veld:
      chain:
        description: null
        topic: null
    services:
      veld_step_2_xmlanntools_xml2standoff:
        extends:
          file: ./code/veld_code__xmlanntools/veld_xml2standoff.yaml
          service: veld_xml2standoff
        volumes:
        - ./data/xmlanntools/:/veld/input/
        - ./data/xmlanntools/:/veld/output/
        environment:
          in_xml_file: DEU100.xml
          out_txt_file: DEU100.txt
          out_json_file: DEU100.json
      veld_step_2_xmlanntools_tag_ud:
        extends:
          file: ./code/veld_code__xmlanntools/veld_tag_ud.yaml
          service: veld_tag_ud
        volumes:
        - ./data/xmlanntools/:/veld/input/
        - ./data/xmlanntools/:/veld/output/
        environment:
          in_txt_file: DEU100.txt
          out_conllu_file: DEU100.conllu
          model: german-hdt-ud-2.5-191206
        depends_on:
          veld_step_2_xmlanntools_xml2standoff:
            condition: service_completed_successfully
      veld_step_2_xmlanntools_ann2standoff:
        extends:
          file: ./code/veld_code__xmlanntools/veld_ann2standoff.yaml
          service: veld_ann2standoff
        volumes:
        - ./data/xmlanntools/:/veld/input/data/
        - ./data/xmlanntools/:/veld/output/
        environment:
          in_conllu_file: DEU100.conllu
          in_txt_file: DEU100.txt
          out_json_file: DEU100.ann.json
          profile_name: conllu
        depends_on:
          veld_step_2_xmlanntools_tag_ud:
            condition: service_completed_successfully
      veld_step_2_xmlanntools_standoff2xml:
        extends:
          file: ./code/veld_code__xmlanntools/veld_standoff2xml.yaml
          service: veld_standoff2xml
        volumes:
        - ./data/xmlanntools/:/veld/input/
        - ./data/xmlanntools/:/veld/output/
        environment:
          in_txt_file: DEU100.txt
          in_json_file: DEU100.json
          in_ann_json_file: DEU100.ann.json
          out_ann_xml_file: DEU100.ann.xml
        depends_on:
          veld_step_2_xmlanntools_ann2standoff:
            condition: service_completed_successfully
veld_chain__compare_tokenizations___veld_step_3_teitok.yaml:
  url: https://github.com/veldhub/veld_chain__compare_tokenizations/blob/main/veld_step_3_teitok.yaml
  content:
    x-veld:
      chain:
        description: null
        topic: null
    services:
      veld_step_3_teitok:
        extends:
          file: ./code/veld_code__teitok-tools/veld_parseudpipe.yaml
          service: veld_parseudpipe
        volumes:
        - ./data/teitok/:/veld/input/
        - ./data/teitok/:/veld/output/
        environment:
          in_xml_file: DEU100.xml
          out_xml_file: DEU100.xml
          model: german-hdt-ud-2.5-191206
veld_chain__compare_tokenizations___veld_step_4_jupyter_analysis.yaml:
  url: https://github.com/veldhub/veld_chain__compare_tokenizations/blob/main/veld_step_4_jupyter_analysis.yaml
  content:
    x-veld:
      chain:
        description: null
        topic: null
    services:
      veld_step_4_jupyter_analysis:
        extends:
          file: ./code/veld_code__jupyter_analysis/veld.yaml
          service: veld
        volumes:
        - ./data/xmlanntools/:/veld/input/xmlanntools/
        - ./data/teitok/:/veld/input/teitok/
veld_chain__compare_tokenizations___veld_step_all.yaml:
  url: https://github.com/veldhub/veld_chain__compare_tokenizations/blob/main/veld_step_all.yaml
  content:
    x-veld:
      chain:
        description: null
        topic: null
    services:
      veld_step_1_download_xmlanntools:
        extends:
          file: ./veld_step_1_download.yaml
          service: veld_step_1_download_xmlanntools
      veld_step_2_xmlanntools_xml2standoff:
        extends:
          file: ./veld_step_2_xmlanntools.yaml
          service: veld_step_2_xmlanntools_xml2standoff
        depends_on:
          veld_step_1_download_xmlanntools:
            condition: service_completed_successfully
      veld_step_2_xmlanntools_tag_ud:
        extends:
          file: ./veld_step_2_xmlanntools.yaml
          service: veld_step_2_xmlanntools_tag_ud
        depends_on:
          veld_step_2_xmlanntools_xml2standoff:
            condition: service_completed_successfully
      veld_step_2_xmlanntools_ann2standoff:
        extends:
          file: ./veld_step_2_xmlanntools.yaml
          service: veld_step_2_xmlanntools_ann2standoff
        depends_on:
          veld_step_2_xmlanntools_tag_ud:
            condition: service_completed_successfully
      veld_step_2_xmlanntools_standoff2xml:
        extends:
          file: ./veld_step_2_xmlanntools.yaml
          service: veld_step_2_xmlanntools_standoff2xml
        depends_on:
          veld_step_2_xmlanntools_ann2standoff:
            condition: service_completed_successfully
      veld_step_1_download_teitok:
        extends:
          file: ./veld_step_1_download.yaml
          service: veld_step_1_download_xmlanntools
      veld_step_3_teitok:
        extends:
          file: ./veld_step_3_teitok.yaml
          service: veld_step_3_teitok
        depends_on:
          veld_step_1_download_teitok:
            condition: service_completed_successfully
      veld_step_4_jupyter_analysis:
        extends:
          file: ./veld_step_4_jupyter_analysis.yaml
          service: veld_step_4_jupyter_analysis
        depends_on:
          veld_step_2_xmlanntools_standoff2xml:
            condition: service_completed_successfully
          veld_step_3_teitok:
            condition: service_completed_successfully
veld_chain__demo_conllueditor___veld.yaml:
  url: https://github.com/veldhub/veld_chain__demo_conllueditor/blob/main/veld.yaml
  content:
    x-veld:
      chain:
        description: an example chain using the veldified version of https://github.com/Orange-OpenSource/conllueditor
          on sample data.
        topic:
        - NLP
        - Universal Dependencies
        - Tokenization
        - Lemmatization
        - Part Of Speech
        - Dependency Parsing
        - Grammatical Annotation
    services:
      veld_conllueditor:
        extends:
          file: ./code/veld_code__conllueditor/veld.yaml
          service: veld_conllueditor
        volumes:
        - ./data/:/data/
        environment:
          filename: en.conllu
veld_chain__demo_downloader___veld_demo_01__single_download.yaml:
  url: https://github.com/veldhub/veld_chain__demo_downloader/blob/main/veld_demo_01__single_download.yaml
  content:
    x-veld:
      chain:
        description: chain demonstrating download from a single url without any other
          configuration.
        topic: demo
    services:
      veld_demo_01__single_download:
        extends:
          file: ./code/veld_code__downloader/veld.yaml
          service: veld_downloader
        volumes:
        - ./data/demo_01/output/:/veld/output/
        environment:
          url: https://www.gutenberg.org/cache/epub/52521/pg52521.txt
veld_chain__demo_downloader___veld_demo_02__single_download__designate_file_name.yaml:
  url: https://github.com/veldhub/veld_chain__demo_downloader/blob/main/veld_demo_02__single_download__designate_file_name.yaml
  content:
    x-veld:
      chain:
        description: chain demonstrating download from a single url where a designated
          output file name is given.
        topic: demo
    services:
      veld_demo_02__single_download__designate_file_name:
        extends:
          file: ./code/veld_code__downloader/veld.yaml
          service: veld_downloader
        volumes:
        - ./data/demo_02/output/:/veld/output/
        environment:
          url: https://www.gutenberg.org/cache/epub/52521/pg52521.txt
          out_file: Grimms_Fairy_Tales.txt
veld_chain__demo_downloader___veld_demo_03__single_download__extract.yaml:
  url: https://github.com/veldhub/veld_chain__demo_downloader/blob/main/veld_demo_03__single_download__extract.yaml
  content:
    x-veld:
      chain:
        description: chain demonstrating download from a single url where the downloaded
          file is an archive which will be automatically extracted.
        topic: demo
    services:
      veld_demo_03__single_download__extract:
        extends:
          file: ./code/veld_code__downloader/veld.yaml
          service: veld_downloader
        volumes:
        - ./data/demo_03/output/:/veld/output/
        environment:
          url: https://www.gutenberg.org/cache/epub/52521/pg52521-h.zip
          do_extract: true
veld_chain__demo_downloader___veld_demo_04__single_download__designate_file_name__extract.yaml:
  url: https://github.com/veldhub/veld_chain__demo_downloader/blob/main/veld_demo_04__single_download__designate_file_name__extract.yaml
  content:
    x-veld:
      chain:
        description: chain demonstrating download from a single url where a designated
          output file name is given, and it is an archive which will be automatically
          extracted.
        topic: demo
    services:
      veld_demo_04__single_download__designate_file_name__extract:
        extends:
          file: ./code/veld_code__downloader/veld.yaml
          service: veld_downloader
        volumes:
        - ./data/demo_04/output/:/veld/output/
        environment:
          url: https://www.gutenberg.org/cache/epub/52521/pg52521-h.zip
          out_file: Grimms_Fairy_Tales.zip
          do_extract: true
veld_chain__demo_downloader___veld_demo_05__csv_bulk_download.yaml:
  url: https://github.com/veldhub/veld_chain__demo_downloader/blob/main/veld_demo_05__csv_bulk_download.yaml
  content:
    x-veld:
      chain:
        description: chain demonstrating bulk download from a csv without any other
          configuration.
        topic: demo
    services:
      veld_demo_05__csv_bulk_download:
        extends:
          file: ./code/veld_code__downloader/veld.yaml
          service: veld_downloader
        volumes:
        - ./data/demo_05/input/:/veld/input/
        - ./data/demo_05/output/:/veld/output/
        environment:
          in_csv_file: goethe.csv
veld_chain__demo_downloader___veld_demo_06__csv_bulk_download__designate_file_name.yaml:
  url: https://github.com/veldhub/veld_chain__demo_downloader/blob/main/veld_demo_06__csv_bulk_download__designate_file_name.yaml
  content:
    x-veld:
      chain:
        description: chain demonstrating bulk download from a csv in which respective
          designated file names are given to each download link.
        topic: demo
    services:
      veld_demo_06__csv_bulk_download__designate_file_name:
        extends:
          file: ./code/veld_code__downloader/veld.yaml
          service: veld_downloader
        volumes:
        - ./data/demo_06/input/:/veld/input/
        - ./data/demo_06/output/:/veld/output/
        environment:
          in_csv_file: goethe.csv
veld_chain__demo_downloader___veld_demo_07__csv_bulk_download__extract.yaml:
  url: https://github.com/veldhub/veld_chain__demo_downloader/blob/main/veld_demo_07__csv_bulk_download__extract.yaml
  content:
    x-veld:
      chain:
        description: chain demonstrating bulk download from a csv in which each download
          link is an archive which will be automatically extracted.
        topic: demo
    services:
      veld_demo_07__csv_bulk_download__extract:
        extends:
          file: ./code/veld_code__downloader/veld.yaml
          service: veld_downloader
        volumes:
        - ./data/demo_07/input/:/veld/input/
        - ./data/demo_07/output/:/veld/output/
        environment:
          in_csv_file: goethe.csv
          do_extract: true
veld_chain__demo_downloader___veld_demo_08__csv_bulk_download__csv_no_headers.yaml:
  url: https://github.com/veldhub/veld_chain__demo_downloader/blob/main/veld_demo_08__csv_bulk_download__csv_no_headers.yaml
  content:
    x-veld:
      chain:
        description: chain demonstrating bulk download from a csv without any headers.
        topic: demo
    services:
      veld_demo_08__csv_bulk_download__csv_no_headers:
        extends:
          file: ./code/veld_code__downloader/veld.yaml
          service: veld_downloader
        volumes:
        - ./data/demo_08/input/:/veld/input/
        - ./data/demo_08/output/:/veld/output/
        environment:
          in_csv_file: goethe.csv
          csv_has_headers: false
veld_chain__demo_downloader___veld_demo_09__csv_bulk_download__designate_file_name__extract__csv_no_headers.yaml:
  url: https://github.com/veldhub/veld_chain__demo_downloader/blob/main/veld_demo_09__csv_bulk_download__designate_file_name__extract__csv_no_headers.yaml
  content:
    x-veld:
      chain:
        description: chain demonstrating bulk download from a csv in which respective
          designated file names are given to each download link, where each download
          link is an archive which will be automatically extracted, and without any
          headers.
        topic: demo
    services:
      veld_demo_09__csv_bulk_download__designate_file_name__extract__csv_no_headers:
        extends:
          file: ./code/veld_code__downloader/veld.yaml
          service: veld_downloader
        volumes:
        - ./data/demo_09/input/:/veld/input/
        - ./data/demo_09/output/:/veld/output/
        environment:
          in_csv_file: goethe.csv
          do_extract: true
          csv_has_headers: false
veld_chain__demo_downloader___veld_demo_10__invalid__out_file_and_csv.yaml:
  url: https://github.com/veldhub/veld_chain__demo_downloader/blob/main/veld_demo_10__invalid__out_file_and_csv.yaml
  content:
    x-veld:
      chain:
        description: invalid chain demonstrating that giving `in_csv_file` and `out_file`
          at the same time is invalid, since `out_file` relates to single downloads
          only and not bulk downloads.
        topic: demo
    services:
      veld_demo_11__invalid__out_file_and_csv:
        extends:
          file: ./code/veld_code__downloader/veld.yaml
          service: veld_downloader
        environment:
          in_csv_file: goethe.csv
          out_file: goethe.txt
veld_chain__demo_downloader___veld_demo_11__invalid__url_and_csv.yaml:
  url: https://github.com/veldhub/veld_chain__demo_downloader/blob/main/veld_demo_11__invalid__url_and_csv.yaml
  content:
    x-veld:
      chain:
        description: invalid chain demonstrating that giving `in_csv_file` and `url`
          at the same time is invalid, since `url` relates to single downloads only
          and not bulk downloads.
        topic: demo
    services:
      veld_demo_12__invalid__url_and_csv:
        extends:
          file: ./code/veld_code__downloader/veld.yaml
          service: veld_downloader
        environment:
          in_csv_file: goethe.csv
          url: https://www.gutenberg.org/cache/epub/52521/pg52521.txt
veld_chain__demo_flair___veld_demo_01_infer.yaml:
  url: https://github.com/veldhub/veld_chain__demo_flair/blob/main/veld_demo_01_infer.yaml
  content:
    services:
      veld_demo_01__infer_ner:
        extends:
          file: ./code/veld_code__flair/veld_infer.yaml
          service: veld_infer
        volumes:
        - ./data/demo_01_infer/in/:/veld/input/data/
        - ./data/models_cache/:/veld/input/models_cache/
        - ./data/demo_01_infer/out/:/veld/output/
        environment:
          run_interactively: false
          in_file: test.txt
          out_file: text.json
          do_split_sentences: true
          model_infer_ner: flair/ner-english-large
          model_infer_sentiment: sentiment
          model_infer_linker: linker
          model_infer_frame: frame
          model_infer_chunk: flair/chunk-english
          model_infer_relations: relations
veld_chain__demo_pypi_publisher___veld_publish.yaml:
  url: https://github.com/veldhub/veld_chain__demo_pypi_publisher/blob/main/veld_publish.yaml
  content:
    x-veld:
      chain:
        description: This code veld encapsulates a demo publishing workflow to pypi.org
          . It uses setuptools and contains a template python module that can be found
          at ./data/test_python_module/
    services:
      veld_publish:
        extends:
          file: ./code/veld_code__pypi_publisher/veld_publish.yaml
          service: veld_publish
        volumes:
        - ./data/test_python_module/:/veld/input/
veld_chain__demo_teitok-tools___veld_parseudpipe.yaml:
  url: https://github.com/veldhub/veld_chain__demo_teitok-tools/blob/main/veld_parseudpipe.yaml
  content:
    x-veld:
      chain:
        description: 'This chain veld exemplifies usage of the respective code veld.
          For more information on the underlying tool and its usage, see: https://github.com/ufal/teitok-tools?tab=readme-ov-file#parseudpipe'
        topic:
        - NLP
        - ETL
        - Tokenization
        - Universal Dependencies
    services:
      veld_parseudpipe:
        extends:
          file: ./code/veld_code__teitok-tools/veld_parseudpipe.yaml
          service: veld_parseudpipe
        volumes:
        - ./data/parseudpipe/in/:/veld/input/
        - ./data/parseudpipe/out/:/veld/output/
        environment:
          in_xml_file: DEU001_tokenized.xml
          out_xml_file: DEU001.xml
          model: german-hdt-ud-2.6-200830
          sent: p
veld_chain__demo_teitok-tools___veld_udpipe2teitok.yaml:
  url: https://github.com/veldhub/veld_chain__demo_teitok-tools/blob/main/veld_udpipe2teitok.yaml
  content:
    x-veld:
      chain:
        description: 'This chain veld exemplifies usage of the respective code veld.
          For more information on the underlying tool and its usage, see: https://github.com/ufal/teitok-tools?tab=readme-ov-file#udpipe2teitok'
        topic:
        - NLP
        - ETL
        - Tokenization
        - Universal Dependencies
    services:
      veld_udpipe2teitok:
        extends:
          file: ./code/veld_code__teitok-tools/veld_udpipe2teitok.yaml
          service: veld_udpipe2teitok
        volumes:
        - ./data/udpipe2teitok/in/:/veld/input/
        - ./data/udpipe2teitok/out/:/veld/output/
        environment:
          lang: de
          model: german-hdt-ud-2.6-200830
          mixed: true
veld_chain__demo_teitok-tools___veld_xmltokenize.yaml:
  url: https://github.com/veldhub/veld_chain__demo_teitok-tools/blob/main/veld_xmltokenize.yaml
  content:
    x-veld:
      chain:
        description: 'This chain veld exemplifies usage of the respective code veld.
          For more information on the underlying tool and its usage, see: https://github.com/ufal/teitok-tools?tab=readme-ov-file#xmltokenize'
        topic:
        - NLP
        - ETL
        - Tokenization
        - Universal Dependencies
    services:
      veld_xmltokenize:
        extends:
          file: ./code/veld_code__teitok-tools/veld_xmltokenize.yaml
          service: veld_xmltokenize
        volumes:
        - ./data/xmltokenize/in/:/veld/input/
        - ./data/xmltokenize/out/:/veld/output/
        environment:
          in_xml_file: DEU001.xml
          out_xml_file: DEU001.xml
          textnode: body
          tok: xyz
          enumerate: true
veld_chain__demo_udipe_ts-vienna-2024___veld_infer.yaml:
  url: https://github.com/veldhub/veld_chain__demo_udipe_ts-vienna-2024/blob/main/veld_infer.yaml
  content:
    x-veld:
      chain:
        description: A demonstration of a VELD chain inferencing on a txt with a self-trained
          udpipe model
        topic:
        - NLP
        - Universal Dependencies
    services:
      veld_infer:
        extends:
          file: ./code/veld_code__udpipe/veld_infer.yaml
          service: veld_infer
        volumes:
        - ./data/veld_data__demo_inference_input_ts-vienna-2024/:/veld/input/txt/
        - ./data/veld_data__demo_updipe_models_ts-vienna-2024/:/veld/input/model/
        - ./data/veld_data__demo_inference_output_ts-vienna-2024/:/veld/output/
        environment:
          in_txt_file: rumpelstiltskin.txt
          in_model_file: en_ewt-ud.udpipe
veld_chain__demo_udipe_ts-vienna-2024___veld_train.yaml:
  url: https://github.com/veldhub/veld_chain__demo_udipe_ts-vienna-2024/blob/main/veld_train.yaml
  content:
    x-veld:
      chain:
        description: A demonstration of a VELD chain training a udpipe model from
          scratch
        topic:
        - NLP
        - Universal Dependencies
    services:
      veld_train:
        extends:
          file: ./code/veld_code__udpipe/veld_train.yaml
          service: veld_train
        volumes:
        - ./data/veld_data__demo_train_data_ts-vienna-2024/:/veld/input/
        - ./data/veld_data__demo_updipe_models_ts-vienna-2024/:/veld/output/
        environment:
          train_data_path: en_ewt-ud.conllu
          model_path: en_ewt-ud.udpipe
          tokenizer_epochs: 2
          tagger_iterations: 2
          parser_iterations: 2
veld_chain__demo_wordembeddings_multiarch___veld_step_1_download.yaml:
  url: https://github.com/veldhub/veld_chain__demo_wordembeddings_multiarch/blob/main/veld_step_1_download.yaml
  content:
    x-veld:
      chain:
        description: Downloads the bible
        topic:
        - ETL
        - Bible Studies
    services:
      veld_step_1_download:
        extends:
          file: ./code/veld_code__downloader/veld.yaml
          service: veld_downloader
        volumes:
        - ./data/training_data/:/veld/output/
        environment:
          url: https://raw.githubusercontent.com/mxw/grmr/master/src/finaltests/bible.txt
          out_file: bible_unprocessed.txt
veld_chain__demo_wordembeddings_multiarch___veld_step_2_preprocess.yaml:
  url: https://github.com/veldhub/veld_chain__demo_wordembeddings_multiarch/blob/main/veld_step_2_preprocess.yaml
  content:
    x-veld:
      chain:
        description: Preprocesses the bible to be compatible with word embeddings
          training. This chain does not use a code veld but build context and code
          that is integrated into the chain repo itself, since the preprocessing is
          highly specific to this kind of data and the subsequent training.
        topic:
        - ETL
        - NLP
        - Bible Studies
    services:
      veld_step_2_preprocess:
        build: ./code/bible_preprocess/
        command: python /veld/code/bible_preprocess.py
        volumes:
        - ./code/bible_preprocess/:/veld/code/
        - ./data/training_data/:/veld/input/
        - ./data/training_data/:/veld/output/
        environment:
          in_file: bible_unprocessed.txt
          out_file: bible_processed.txt
veld_chain__demo_wordembeddings_multiarch___veld_step_3_train_fasttext.yaml:
  url: https://github.com/veldhub/veld_chain__demo_wordembeddings_multiarch/blob/main/veld_step_3_train_fasttext.yaml
  content:
    x-veld:
      chain:
        description: Trains a fasttext model on the bible and exports its vectors
          as a dict serialized into a pkl file. The training data is rather small
          and the hyperparameteres are simplistic, in order to demonstrate the reproducibility
          of this chain rather than claiming any deeper insight into the data's words
          context.
        topic:
        - ETL
        - NLP
        - Machine Learning
        - Word Embeddings
        - Bible Studies
    services:
      veld_step_3_train_fasttext:
        extends:
          file: ./code/veld_code__fasttext/veld_train.yaml
          service: veld_train
        volumes:
        - ./data/training_data/:/veld/input/
        - ./data/models/fasttext/:/veld/output/
        environment:
          in_train_data_file: bible_processed.txt
          out_model_file: m1.bin
          model_description: simple bible fasttext model
          vector_size: 200
          epochs: 100
          window_size: 10
      veld_step_3_export_fasttext:
        extends:
          file: ./code/veld_code__fasttext/veld_export.yaml
          service: veld_export
        volumes:
        - ./data/models/fasttext/:/veld/input/
        - ./data/vectors/fasttext/:/veld/output/
        environment:
          in_model_file: m1.bin
          out_vector_file: m1.pkl
        depends_on:
          veld_step_3_train_fasttext:
            condition: service_completed_successfully
veld_chain__demo_wordembeddings_multiarch___veld_step_4_train_glove.yaml:
  url: https://github.com/veldhub/veld_chain__demo_wordembeddings_multiarch/blob/main/veld_step_4_train_glove.yaml
  content:
    x-veld:
      chain:
        description: Trains a glove model on the bible and exports its vectors as
          a dict serialized into a pkl file. The training data is rather small and
          the hyperparameteres are simplistic, in order to demonstrate the reproducibility
          of this chain rather than claiming any deeper insight into the data's words
          context.
        topic:
        - ETL
        - NLP
        - Machine Learning
        - Word Embeddings
        - Bible Studies
    services:
      veld_step_4_train_glove:
        extends:
          file: ./code/veld_code__glove/veld_train.yaml
          service: veld_train
        volumes:
        - ./data/training_data/:/veld/input/
        - ./data/models/glove/:/veld/output/
        environment:
          in_corpus_file: bible_processed.txt
          out_vocab_file: m1_vocab.txt
          out_cooccurrence_file: m1_cooccurrence.bin
          out_cooccurrence_shuf_file: m1_cooccurrence_shuf.bin
          out_vector_file: m1_vector
          model_id: m1
          model_description: simple bible glove model
          vector_size: 200
          max_iter: 50
          window_size: 10
      veld_step_4_export_glove:
        extends:
          file: ./code/veld_code__glove/veld_export.yaml
          service: veld_export
        volumes:
        - ./data/models/glove/:/veld/input/
        - ./data/vectors/glove/:/veld/output/
        environment:
          in_vector_file: m1_vector.txt
          out_vector_file: m1.pkl
        depends_on:
          veld_step_4_train_glove:
            condition: service_completed_successfully
veld_chain__demo_wordembeddings_multiarch___veld_step_5_train_word2vec.yaml:
  url: https://github.com/veldhub/veld_chain__demo_wordembeddings_multiarch/blob/main/veld_step_5_train_word2vec.yaml
  content:
    x-veld:
      chain:
        description: Trains a word2vec model on the bible and exports its vectors
          as a dict serialized into a pkl file. The training data is rather small
          and the hyperparameteres are simplistic, in order to demonstrate the reproducibility
          of this chain rather than claiming any deeper insight into the data's words
          context.
        topic:
        - ETL
        - NLP
        - Machine Learning
        - Word Embeddings
        - Bible Studies
    services:
      veld_step_5_train_word2vec:
        extends:
          file: ./code/veld_code__word2vec/veld_train.yaml
          service: veld_train
        volumes:
        - ./data/training_data/:/veld/input/
        - ./data/models/word2vec/:/veld/output/
        environment:
          in_train_data_file: bible_processed.txt
          out_model_file: m1.bin
          model_description: simple bible word2vec model
          epochs: 100
          vector_size: 200
          window: 10
      veld_step_5_export_word2vec:
        extends:
          file: ./code/veld_code__word2vec/veld_export.yaml
          service: veld_export
        volumes:
        - ./data/models/word2vec/:/veld/input/
        - ./data/vectors/word2vec/:/veld/output/
        environment:
          in_model_file: m1.bin
          out_vector_file: m1.pkl
        depends_on:
          veld_step_5_train_word2vec:
            condition: service_completed_successfully
veld_chain__demo_wordembeddings_multiarch___veld_step_6_analyse_vectors.yaml:
  url: https://github.com/veldhub/veld_chain__demo_wordembeddings_multiarch/blob/main/veld_step_6_analyse_vectors.yaml
  content:
    x-veld:
      code:
        description: 'Reads in the trained word vectors from their pkl serializations
          and tests them for plausability on a few selected words which should show
          intuitive close or distant relations to each other. This chain does not
          inherit from a code veld but is defined entirely within its containing chain
          repository since its code and data are highly context-specific.

          After reproducing the entire previous sequences yourself and execution of
          the notebook, feel free to save the notebook and compare the resulting differences
          with `git diff ./code/analyse_vectors/notebooks/analyse_vectors.ipynb`,
          where the reproduced vector similarities will have only slight differences
          to the record of previously trained ones. This difference is due to randomization
          within the training, but should be small enough to indicate approximate
          reproduction.'
        topic:
        - ETL
        - NLP
        - Machine Learning
        - Word Embeddings
        - Bible Studies
    services:
      veld_step_6_analyse_vectors:
        build: ./code/analyse_vectors/
        command: jupyter notebook --allow-root --ip='*' --NotebookApp.token='' --NotebookApp.password=''
        ports:
        - 8888:8888
        working_dir: /veld/code/
        volumes:
        - ./code/analyse_vectors/notebooks/:/veld/code/
        - ./data/vectors/:/veld/input/
veld_chain__demo_wordembeddings_multiarch___veld_step_all.yaml:
  url: https://github.com/veldhub/veld_chain__demo_wordembeddings_multiarch/blob/main/veld_step_all.yaml
  content:
    x-veld:
      chain:
        description: This is a multi chain that executes all other individual chains
          in sequential order. Refer to the other veld yaml files for more information
          on each step.
        topic:
        - ETL
        - NLP
        - Machine Learning
        - Word Embeddings
        - Bible Studies
    services:
      veld_step_1_download:
        extends:
          file: ./veld_step_1_download.yaml
          service: veld_step_1_download
      veld_step_2_preprocess:
        extends:
          file: ./veld_step_2_preprocess.yaml
          service: veld_step_2_preprocess
        depends_on:
          veld_step_1_download:
            condition: service_completed_successfully
      veld_step_3_train_fasttext:
        extends:
          file: ./veld_step_3_train_fasttext.yaml
          service: veld_step_3_train_fasttext
        depends_on:
          veld_step_2_preprocess:
            condition: service_completed_successfully
      veld_step_3_export_fasttext:
        extends:
          file: ./veld_step_3_train_fasttext.yaml
          service: veld_step_3_export_fasttext
        depends_on:
          veld_step_3_train_fasttext:
            condition: service_completed_successfully
      veld_step_4_train_glove:
        extends:
          file: ./veld_step_4_train_glove.yaml
          service: veld_step_4_train_glove
        depends_on:
          veld_step_3_export_fasttext:
            condition: service_completed_successfully
      veld_step_4_export_glove:
        extends:
          file: ./veld_step_4_train_glove.yaml
          service: veld_step_4_export_glove
        depends_on:
          veld_step_4_train_glove:
            condition: service_completed_successfully
      veld_step_5_train_word2vec:
        extends:
          file: ./veld_step_5_train_word2vec.yaml
          service: veld_step_5_train_word2vec
        depends_on:
          veld_step_4_export_glove:
            condition: service_completed_successfully
      veld_step_5_export_word2vec:
        extends:
          file: ./veld_step_5_train_word2vec.yaml
          service: veld_step_5_export_word2vec
        depends_on:
          veld_step_5_train_word2vec:
            condition: service_completed_successfully
      veld_step_6_analyse_vectors:
        extends:
          file: ./veld_step_6_analyse_vectors.yaml
          service: veld_step_6_analyse_vectors
        depends_on:
          veld_step_5_export_word2vec:
            condition: service_completed_successfully
veld_chain__demo_xmlanntools___veld_simple_poetry1_all_steps.yaml:
  url: https://github.com/veldhub/veld_chain__demo_xmlanntools/blob/main/veld_simple_poetry1_all_steps.yaml
  content:
    x-veld:
      chain:
        description: a multichain aggregating all individual steps of https://github.com/czcorpus/xmlanntools/tree/main/examples#simple_poetry1
          into one single chain
        topic:
        - NLP
        - ETL
        - Tokenization
        - Universal Dependencies
    services:
      veld_simple_poetry1_step1_xml2standoff:
        extends:
          file: veld_simple_poetry1_step1_xml2standoff.yaml
          service: veld_simple_poetry1_step1_xml2standoff
      veld_simple_poetry1_step2_tag_ud:
        extends:
          file: veld_simple_poetry1_step2_tag_ud.yaml
          service: veld_simple_poetry1_step2_tag_ud
        depends_on:
          veld_simple_poetry1_step1_xml2standoff:
            condition: service_completed_successfully
      veld_simple_poetry1_step3_ann2standoff:
        extends:
          file: veld_simple_poetry1_step3_ann2standoff.yaml
          service: veld_simple_poetry1_step3_ann2standoff
        depends_on:
          veld_simple_poetry1_step2_tag_ud:
            condition: service_completed_successfully
      veld_simple_poetry1_step4_standoff2xml:
        extends:
          file: veld_simple_poetry1_step4_standoff2xml.yaml
          service: veld_simple_poetry1_step4_standoff2xml
        depends_on:
          veld_simple_poetry1_step3_ann2standoff:
            condition: service_completed_successfully
      veld_simple_poetry1_step5_xml2vrt:
        extends:
          file: veld_simple_poetry1_step5_xml2vrt.yaml
          service: veld_simple_poetry1_step5_xml2vrt
        depends_on:
          veld_simple_poetry1_step4_standoff2xml:
            condition: service_completed_successfully
veld_chain__demo_xmlanntools___veld_simple_poetry1_step1_xml2standoff.yaml:
  url: https://github.com/veldhub/veld_chain__demo_xmlanntools/blob/main/veld_simple_poetry1_step1_xml2standoff.yaml
  content:
    x-veld:
      chain:
        description: 'A demo chain veld, integrating the xml2standoff script and implementing
          the first step of the ''Simple_poetry1'' example at https://github.com/czcorpus/xmlanntools/tree/main/examples#simple_poetry1 '
        topic:
        - NLP
        - ETL
        - Tokenization
        - Universal Dependencies
    services:
      veld_simple_poetry1_step1_xml2standoff:
        extends:
          file: ./code/veld_code__xmlanntools/veld_xml2standoff.yaml
          service: veld_xml2standoff
        volumes:
        - ./data/Simple_poetry1/:/veld/input/
        - ./data/Simple_poetry1/:/veld/output/
        environment:
          in_xml_file: Simple_poetry1.xml
          out_txt_file: Simple_poetry1.txt
          out_json_file: Simple_poetry1.json
          text_elements: p,head,lb
veld_chain__demo_xmlanntools___veld_simple_poetry1_step2_tag_ud.yaml:
  url: https://github.com/veldhub/veld_chain__demo_xmlanntools/blob/main/veld_simple_poetry1_step2_tag_ud.yaml
  content:
    x-veld:
      chain:
        description: 'A demo chain veld, integrating the tag_ud script and implementing
          the second step of the ''Simple_poetry1'' example at https://github.com/czcorpus/xmlanntools/tree/main/examples#simple_poetry1 '
        topic:
        - NLP
        - ETL
        - Tokenization
        - Universal Dependencies
    services:
      veld_simple_poetry1_step2_tag_ud:
        extends:
          file: ./code/veld_code__xmlanntools/veld_tag_ud.yaml
          service: veld_tag_ud
        volumes:
        - ./data/Simple_poetry1/:/veld/input/
        - ./data/Simple_poetry1/:/veld/output/
        environment:
          in_txt_file: Simple_poetry1.txt
          out_conllu_file: Simple_poetry1.conllu
          model: czech-pdt-ud-2.15-241121
veld_chain__demo_xmlanntools___veld_simple_poetry1_step3_ann2standoff.yaml:
  url: https://github.com/veldhub/veld_chain__demo_xmlanntools/blob/main/veld_simple_poetry1_step3_ann2standoff.yaml
  content:
    x-veld:
      chain:
        description: 'A demo chain veld, integrating the ann2standoff script and implementing
          the third step of the ''Simple_poetry1'' example at https://github.com/czcorpus/xmlanntools/tree/main/examples#simple_poetry1 '
        topic:
        - NLP
        - ETL
        - Tokenization
        - Universal Dependencies
    services:
      veld_simple_poetry1_step3_ann2standoff:
        extends:
          file: ./code/veld_code__xmlanntools/veld_ann2standoff.yaml
          service: veld_ann2standoff
        volumes:
        - ./data/Simple_poetry1/:/veld/input/data/
        - ./data/Simple_poetry1/:/veld/output/
        environment:
          in_conllu_file: Simple_poetry1.conllu
          in_txt_file: Simple_poetry1.txt
          out_json_file: Simple_poetry1.ann.json
          profile_name: conllu
veld_chain__demo_xmlanntools___veld_simple_poetry1_step4_standoff2xml.yaml:
  url: https://github.com/veldhub/veld_chain__demo_xmlanntools/blob/main/veld_simple_poetry1_step4_standoff2xml.yaml
  content:
    x-veld:
      chain:
        description: 'A demo chain veld, integrating the standoff2xml script and implementing
          the fourth step of the ''Simple_poetry1'' example at https://github.com/czcorpus/xmlanntools/tree/main/examples#simple_poetry1 '
        topic:
        - NLP
        - ETL
        - Tokenization
        - Universal Dependencies
    services:
      veld_simple_poetry1_step4_standoff2xml:
        extends:
          file: ./code/veld_code__xmlanntools/veld_standoff2xml.yaml
          service: veld_standoff2xml
        volumes:
        - ./data/Simple_poetry1/:/veld/input/
        - ./data/Simple_poetry1/:/veld/output/
        environment:
          in_txt_file: Simple_poetry1.txt
          in_json_file: Simple_poetry1.json
          in_ann_json_file: Simple_poetry1.ann.json
          out_ann_xml_file: Simple_poetry1.ann.xml
veld_chain__demo_xmlanntools___veld_simple_poetry1_step5_xml2vrt.yaml:
  url: https://github.com/veldhub/veld_chain__demo_xmlanntools/blob/main/veld_simple_poetry1_step5_xml2vrt.yaml
  content:
    x-veld:
      chain:
        description: 'A demo chain veld, integrating the xml2vrt script and implementing
          the fifth step of the ''Simple_poetry1'' example at https://github.com/czcorpus/xmlanntools/tree/main/examples#simple_poetry1 '
        topic:
        - NLP
        - ETL
        - Tokenization
        - Universal Dependencies
    services:
      veld_simple_poetry1_step5_xml2vrt:
        extends:
          file: ./code/veld_code__xmlanntools/veld_xml2vrt.yaml
          service: veld_xml2vrt
        volumes:
        - ./data/Simple_poetry1/:/veld/input/data/
        - ./data/Simple_poetry1/:/veld/output/
        environment:
          in_ann_xml_file: Simple_poetry1.ann.xml
          profile_name: conllu
          out_conlluish_xml_file: Simple_poetry1.vrt
veld_chain__demo_xmlanntools___veld_tei_example1_all_steps.yaml:
  url: https://github.com/veldhub/veld_chain__demo_xmlanntools/blob/main/veld_tei_example1_all_steps.yaml
  content:
    x-veld:
      chain:
        description: a multichain aggregating all individual steps of https://github.com/czcorpus/xmlanntools/tree/main/examples#tei_example1
          into one single chain
        topic:
        - NLP
        - ETL
        - Tokenization
        - Universal Dependencies
    services:
      veld_tei_example1_step1_xml2standoff:
        extends:
          file: veld_tei_example1_step1_xml2standoff.yaml
          service: veld_tei_example1_step1_xml2standoff
      veld_tei_example1_step2_tag_ud:
        extends:
          file: veld_tei_example1_step2_tag_ud.yaml
          service: veld_tei_example1_step2_tag_ud
        depends_on:
          veld_tei_example1_step1_xml2standoff:
            condition: service_completed_successfully
      veld_tei_example1_step3_ann2standoff:
        extends:
          file: veld_tei_example1_step3_ann2standoff.yaml
          service: veld_tei_example1_step3_ann2standoff
        depends_on:
          veld_tei_example1_step2_tag_ud:
            condition: service_completed_successfully
      veld_tei_example1_step4_standoff2xml:
        extends:
          file: veld_tei_example1_step4_standoff2xml.yaml
          service: veld_tei_example1_step4_standoff2xml
        depends_on:
          veld_tei_example1_step3_ann2standoff:
            condition: service_completed_successfully
      veld_tei_example1_step5_xml2vrt:
        extends:
          file: veld_tei_example1_step5_xml2vrt.yaml
          service: veld_tei_example1_step5_xml2vrt
        depends_on:
          veld_tei_example1_step4_standoff2xml:
            condition: service_completed_successfully
veld_chain__demo_xmlanntools___veld_tei_example1_step1_xml2standoff.yaml:
  url: https://github.com/veldhub/veld_chain__demo_xmlanntools/blob/main/veld_tei_example1_step1_xml2standoff.yaml
  content:
    x-veld:
      chain:
        description: 'A demo chain veld, integrating the xml2standoff script and implementing
          the first step of the ''TEI_example1'' at https://github.com/czcorpus/xmlanntools/tree/main/examples#tei_example1 '
        topic:
        - NLP
        - ETL
        - Tokenization
        - Universal Dependencies
    services:
      veld_tei_example1_step1_xml2standoff:
        extends:
          file: ./code/veld_code__xmlanntools/veld_xml2standoff.yaml
          service: veld_xml2standoff
        volumes:
        - ./data/TEI_example1/:/veld/input/
        - ./data/TEI_example1/:/veld/output/
        environment:
          in_xml_file: TEI_example1.xml
          out_txt_file: TEI_example1.txt
          out_json_file: TEI_example1.json
          text_elements: p,head,quote,l
          exclude_elements: teiHeader,front,foreign
veld_chain__demo_xmlanntools___veld_tei_example1_step2_tag_ud.yaml:
  url: https://github.com/veldhub/veld_chain__demo_xmlanntools/blob/main/veld_tei_example1_step2_tag_ud.yaml
  content:
    x-veld:
      chain:
        description: 'A demo chain veld, integrating the tag_ud script and implementing
          the second step of the ''TEI_example1'' at https://github.com/czcorpus/xmlanntools/tree/main/examples#tei_example1 '
        topic:
        - NLP
        - ETL
        - Tokenization
        - Universal Dependencies
    services:
      veld_tei_example1_step2_tag_ud:
        extends:
          file: ./code/veld_code__xmlanntools/veld_tag_ud.yaml
          service: veld_tag_ud
        volumes:
        - ./data/TEI_example1/:/veld/input/
        - ./data/TEI_example1/:/veld/output/
        environment:
          in_txt_file: TEI_example1.txt
          out_conllu_file: TEI_example1.conllu
          model: english-ewt-ud-2.15-241121
veld_chain__demo_xmlanntools___veld_tei_example1_step3_ann2standoff.yaml:
  url: https://github.com/veldhub/veld_chain__demo_xmlanntools/blob/main/veld_tei_example1_step3_ann2standoff.yaml
  content:
    x-veld:
      chain:
        description: 'A demo chain veld, integrating the ann2standoff script and implementing
          the third step of the ''TEI_example1'' at https://github.com/czcorpus/xmlanntools/tree/main/examples#tei_example1 '
        topic:
        - NLP
        - ETL
        - Tokenization
        - Universal Dependencies
    services:
      veld_tei_example1_step3_ann2standoff:
        extends:
          file: ./code/veld_code__xmlanntools/veld_ann2standoff.yaml
          service: veld_ann2standoff
        volumes:
        - ./data/TEI_example1/:/veld/input/data/
        - ./data/TEI_example1/:/veld/output/
        environment:
          in_conllu_file: TEI_example1.conllu
          in_txt_file: TEI_example1.txt
          out_json_file: TEI_example1.ann.json
          profile_name: conllu
veld_chain__demo_xmlanntools___veld_tei_example1_step4_standoff2xml.yaml:
  url: https://github.com/veldhub/veld_chain__demo_xmlanntools/blob/main/veld_tei_example1_step4_standoff2xml.yaml
  content:
    x-veld:
      chain:
        description: 'A demo chain veld, integrating the standoff2xml script and implementing
          the fourth step of the ''TEI_example1'' at https://github.com/czcorpus/xmlanntools/tree/main/examples#tei_example1 '
        topic:
        - NLP
        - ETL
        - Tokenization
        - Universal Dependencies
    services:
      veld_tei_example1_step4_standoff2xml:
        extends:
          file: ./code/veld_code__xmlanntools/veld_standoff2xml.yaml
          service: veld_standoff2xml
        volumes:
        - ./data/TEI_example1/:/veld/input/
        - ./data/TEI_example1/:/veld/output/
        environment:
          in_txt_file: TEI_example1.txt
          in_json_file: TEI_example1.json
          in_ann_json_file: TEI_example1.ann.json
          out_ann_xml_file: TEI_example1.ann.xml
veld_chain__demo_xmlanntools___veld_tei_example1_step5_xml2vrt.yaml:
  url: https://github.com/veldhub/veld_chain__demo_xmlanntools/blob/main/veld_tei_example1_step5_xml2vrt.yaml
  content:
    x-veld:
      chain:
        description: 'A demo chain veld, integrating the xml2vrt script and implementing
          the fifth step of the ''TEI_example1'' at https://github.com/czcorpus/xmlanntools/tree/main/examples#tei_example1 '
        topic:
        - NLP
        - ETL
        - Tokenization
        - Universal Dependencies
    services:
      veld_tei_example1_step5_xml2vrt:
        extends:
          file: ./code/veld_code__xmlanntools/veld_xml2vrt.yaml
          service: veld_xml2vrt
        volumes:
        - ./data/TEI_example1/:/veld/input/data/
        - ./data/TEI_example1/:/veld/output/
        environment:
          in_ann_xml_file: TEI_example1.ann.xml
          profile_name: conllu
          out_conlluish_xml_file: TEI_example1.vrt
          include_elements: text
          exclude_elements: front
veld_chain__dta_semantic_drift_analysis___veld_step_1_download.yaml:
  url: https://github.com/veldhub/veld_chain__dta_semantic_drift_analysis/blob/main/veld_step_1_download.yaml
  content:
    x-veld:
      chain:
        description: null
        topic: null
        additional: null
    services:
      veld_step_1_download:
        extends:
          file: ./code/veld_code__downloader/veld.yaml
          service: veld_downloader
        volumes:
        - ./data/step_1_raw_data/:/veld/output/
        environment:
          url: https://www.deutschestextarchiv.de/media/download/dta-lingattr-tei_2020-07-27.zip
          do_extract: true
veld_chain__eltec_udpipe_inference___veld_step_1_preprocess.yaml:
  url: https://github.com/veldhub/veld_chain__eltec_udpipe_inference/blob/main/veld_step_1_preprocess.yaml
  content:
    x-veld:
      chain:
        description: xml / xslt transformation of ELTeC data
        topic:
        - ETL
    x-vars:
    - &id001
      file: ./code/veld_code__xml_xslt_transformer/veld.yaml
      service: veld
    - &id002
      in_xsl_file: transformation.xsl
    services:
      veld_preprocess_cze:
        extends: *id001
        volumes:
        - ./data/veld_data__eltec_original_selection/data/ELTeC-cze/level1/:/veld/input/xml/
        - ./data/xsl/:/veld/input/xsl/
        - ./data/data_tmp_txt_transformed/ELTeC-cze/level1/:/veld/output/
        environment: *id002
      veld_preprocess_deu:
        extends: *id001
        volumes:
        - ./data/veld_data__eltec_original_selection/data/ELTeC-deu/level1/:/veld/input/xml/
        - ./data/xsl/:/veld/input/xsl/
        - ./data/data_tmp_txt_transformed/ELTeC-deu/level1/:/veld/output/
        environment: *id002
      veld_preprocess_eng:
        extends: *id001
        volumes:
        - ./data/veld_data__eltec_original_selection/data/ELTeC-eng/level1/:/veld/input/xml/
        - ./data/xsl/:/veld/input/xsl/
        - ./data/data_tmp_txt_transformed/ELTeC-eng/level1/:/veld/output/
        environment: *id002
      veld_preprocess_fra:
        extends: *id001
        volumes:
        - ./data/veld_data__eltec_original_selection/data/ELTeC-fra/level1/:/veld/input/xml/
        - ./data/xsl/:/veld/input/xsl/
        - ./data/data_tmp_txt_transformed/ELTeC-fra/level1/:/veld/output/
        environment: *id002
      veld_preprocess_spa:
        extends: *id001
        volumes:
        - ./data/veld_data__eltec_original_selection/data/ELTeC-spa/level1/:/veld/input/xml/
        - ./data/xsl/:/veld/input/xsl/
        - ./data/data_tmp_txt_transformed/ELTeC-spa/level1/:/veld/output/
        environment: *id002
veld_chain__eltec_udpipe_inference___veld_step_2_download_models.yaml:
  url: https://github.com/veldhub/veld_chain__eltec_udpipe_inference/blob/main/veld_step_2_download_models.yaml
  content:
    x-veld:
      chain:
        description: udpipe model download
        topic:
        - ETL
    x-vars:
    - &id003
      file: ./code/veld_code__downloader/veld.yaml
      service: veld_downloader
    services:
      veld_download_cze:
        extends: *id003
        volumes:
        - ./data/data_tmp_udpipe_models/cze/:/veld/output/
        environment:
          url: https://lindat.mff.cuni.cz/repository/xmlui/bitstream/handle/11234/1-3131/czech-pdt-ud-2.5-191206.udpipe
      veld_download_deu:
        extends: *id003
        volumes:
        - ./data/data_tmp_udpipe_models/deu/:/veld/output/
        environment:
          url: https://lindat.mff.cuni.cz/repository/xmlui/bitstream/handle/11234/1-3131/german-hdt-ud-2.5-191206.udpipe
      veld_download_eng:
        extends: *id003
        volumes:
        - ./data/data_tmp_udpipe_models/eng/:/veld/output/
        environment:
          url: https://lindat.mff.cuni.cz/repository/xmlui/bitstream/handle/11234/1-3131/english-ewt-ud-2.5-191206.udpipe
      veld_download_fra:
        extends: *id003
        volumes:
        - ./data/data_tmp_udpipe_models/fra/:/veld/output/
        environment:
          url: https://lindat.mff.cuni.cz/repository/xmlui/bitstream/handle/11234/1-3131/french-gsd-ud-2.5-191206.udpipe
      veld_download_spa:
        extends: *id003
        volumes:
        - ./data/data_tmp_udpipe_models/spa/:/veld/output/
        environment:
          url: https://lindat.mff.cuni.cz/repository/xmlui/bitstream/handle/11234/1-3131/spanish-gsd-ud-2.5-191206.udpipe
veld_chain__eltec_udpipe_inference___veld_step_3_infer.yaml:
  url: https://github.com/veldhub/veld_chain__eltec_udpipe_inference/blob/main/veld_step_3_infer.yaml
  content:
    x-veld:
      chain:
        description: udpipe inference setup, reading in preprocessed ELTeC data
        topic:
        - NLP
        - Machine Learning
        - Tokenization
        - Lemmatization
        - Part Of Speech
        - Dependency Parsing
        - Universal Dependencies
        - Grammatical Annotation
    x-vars:
    - &id004
      file: ./code/veld_code__udpipe/veld_infer.yaml
      service: veld_infer
    - - ./data/data_tmp_txt_transformed/:/veld/input/txt/
      - ./data/data_tmp_conllu_inferenced/:/veld/output/
    services:
      veld_infer_cze:
        extends: *id004
        volumes:
        - ./data/data_tmp_txt_transformed/ELTeC-cze/level1/:/veld/input/txt/
        - ./data/data_tmp_udpipe_models/cze/:/veld/input/model/
        - ./data/data_tmp_conllu_inferenced/ELTeC-cze/level1/:/veld/output/
        environment:
          in_model_file: czech-pdt-ud-2.5-191206.udpipe
      veld_infer_deu:
        extends: *id004
        volumes:
        - ./data/data_tmp_txt_transformed/ELTeC-deu/level1/:/veld/input/txt/
        - ./data/data_tmp_udpipe_models/deu/:/veld/input/model/
        - ./data/data_tmp_conllu_inferenced/ELTeC-deu/level1/:/veld/output/
        environment:
          in_model_file: german-hdt-ud-2.5-191206.udpipe
      veld_infer_eng:
        extends: *id004
        volumes:
        - ./data/data_tmp_txt_transformed/ELTeC-eng/level1/:/veld/input/txt/
        - ./data/data_tmp_udpipe_models/eng/:/veld/input/model/
        - ./data/data_tmp_conllu_inferenced/ELTeC-eng/level1/:/veld/output/
        environment:
          in_model_file: english-ewt-ud-2.5-191206.udpipe
      veld_infer_fra:
        extends: *id004
        volumes:
        - ./data/data_tmp_txt_transformed/ELTeC-fra/level1/:/veld/input/txt/
        - ./data/data_tmp_udpipe_models/fra/:/veld/input/model/
        - ./data/data_tmp_conllu_inferenced/ELTeC-fra/level1/:/veld/output/
        environment:
          in_model_file: french-gsd-ud-2.5-191206.udpipe
      veld_infer_spa:
        extends: *id004
        volumes:
        - ./data/data_tmp_txt_transformed/ELTeC-spa/level1/:/veld/input/txt/
        - ./data/data_tmp_udpipe_models/spa/:/veld/input/model/
        - ./data/data_tmp_conllu_inferenced/ELTeC-spa/level1/:/veld/output/
        environment:
          in_model_file: spanish-gsd-ud-2.5-191206.udpipe
veld_chain__eltec_udpipe_inference___veld_step_4_analyse.yaml:
  url: https://github.com/veldhub/veld_chain__eltec_udpipe_inference/blob/main/veld_step_4_analyse.yaml
  content:
    x-veld:
      chain:
        description: chain to analyse the conllu data which was inferenced by udpipe
          on several ELTeC corpora.
        topic:
        - NLP
        - Machine Learning
        - Tokenization
        - Lemmatization
        - Part Of Speech
        - Dependency Parsing
        - Universal Dependencies
        - Grammatical Annotation
    services:
      veld_analyse:
        extends:
          file: ./code/veld_code__analyse_conllu/veld.yaml
          service: veld
        volumes:
        - ./data/data_tmp_conllu_inferenced/:/veld/input/
        - ./data/veld_data__eltec_conllu_stats/data/:/veld/output/
veld_chain__eltec_udpipe_inference___veld_step_5_inspect_with_conllueditor.yaml:
  url: https://github.com/veldhub/veld_chain__eltec_udpipe_inference/blob/main/veld_step_5_inspect_with_conllueditor.yaml
  content:
    x-veld:
      chain:
        description: inspecting the conllu files with conllueditor.
        topic:
        - NLP
        - Universal Dependencies
        - Tokenization
        - Lemmatization
        - Part Of Speech
        - Dependency Parsing
        - Grammatical Annotation
    services:
      veld_inspect_with_conllueditor:
        extends:
          file: ./code/veld_code__conllueditor/veld.yaml
          service: veld_conllueditor
        volumes:
        - ./data/data_tmp_conllu_inferenced/ELTeC-eng/level1/:/data/
        environment:
          filename: ENG18400_Trollope.conllu
veld_chain__eltec_udpipe_inference___veld_step_all.yaml:
  url: https://github.com/veldhub/veld_chain__eltec_udpipe_inference/blob/main/veld_step_all.yaml
  content:
    x-veld:
      chain:
        description: An aggregating chain, reusing and referencing all individual
          chains in a sequential processing
        topic:
        - ETL
        - NLP
        - Machine Learning
        - Tokenization
        - Lemmatization
        - Part Of Speech
        - Dependency Parsing
        - Universal Dependencies
        - Grammatical Annotation
    services:
      veld_preprocess_cze:
        extends:
          file: veld_step1_preprocess.yaml
          service: veld_preprocess_cze
      veld_preprocess_deu:
        extends:
          file: veld_step1_preprocess.yaml
          service: veld_preprocess_deu
      veld_preprocess_eng:
        extends:
          file: veld_step1_preprocess.yaml
          service: veld_preprocess_eng
      veld_preprocess_fra:
        extends:
          file: veld_step1_preprocess.yaml
          service: veld_preprocess_fra
      veld_preprocess_spa:
        extends:
          file: veld_step1_preprocess.yaml
          service: veld_preprocess_spa
      veld_download_cze:
        extends:
          file: veld_step2_download_models.yaml
          service: veld_download_cze
        depends_on:
          veld_preprocess_cze:
            condition: service_completed_successfully
      veld_download_deu:
        extends:
          file: veld_step2_download_models.yaml
          service: veld_download_deu
        depends_on:
          veld_preprocess_deu:
            condition: service_completed_successfully
      veld_download_eng:
        extends:
          file: veld_step2_download_models.yaml
          service: veld_download_eng
        depends_on:
          veld_preprocess_eng:
            condition: service_completed_successfully
      veld_download_fra:
        extends:
          file: veld_step2_download_models.yaml
          service: veld_download_fra
        depends_on:
          veld_preprocess_fra:
            condition: service_completed_successfully
      veld_download_spa:
        extends:
          file: veld_step2_download_models.yaml
          service: veld_download_spa
        depends_on:
          veld_preprocess_spa:
            condition: service_completed_successfully
      veld_infer_cze:
        extends:
          file: veld_step3_infer.yaml
          service: veld_infer_cze
        depends_on:
          veld_download_cze:
            condition: service_completed_successfully
      veld_infer_deu:
        extends:
          file: veld_step3_infer.yaml
          service: veld_infer_deu
        depends_on:
          veld_download_deu:
            condition: service_completed_successfully
      veld_infer_eng:
        extends:
          file: veld_step3_infer.yaml
          service: veld_infer_eng
        depends_on:
          veld_download_eng:
            condition: service_completed_successfully
      veld_infer_fra:
        extends:
          file: veld_step3_infer.yaml
          service: veld_infer_fra
        depends_on:
          veld_download_fra:
            condition: service_completed_successfully
      veld_infer_spa:
        extends:
          file: veld_step3_infer.yaml
          service: veld_infer_spa
        depends_on:
          veld_download_spa:
            condition: service_completed_successfully
      veld_analyse:
        extends:
          file: veld_step4_analyse.yaml
          service: veld_analyse
        depends_on:
          veld_infer_cze:
            condition: service_completed_successfully
          veld_infer_deu:
            condition: service_completed_successfully
          veld_infer_eng:
            condition: service_completed_successfully
          veld_infer_fra:
            condition: service_completed_successfully
          veld_infer_spa:
            condition: service_completed_successfully
veld_chain__gutenberg_triplestore___veld_download_gutenberg_metadata.yaml:
  url: https://github.com/veldhub/veld_chain__gutenberg_triplestore/blob/main/veld_download_gutenberg_metadata.yaml
  content:
    x-veld:
      chain:
        description: Downloads the entire gutenberg metadata RDF/XML file and extracts
          it
        topic: ETL
    services:
      veld_download_gutenberg_metadata:
        extends:
          file: ./code/veld_code__downloader/veld.yaml
          service: veld_downloader
        volumes:
        - ./data/gutenberg_rdf/:/veld/output/
        environment:
          url: https://gutenberg.org/cache/epub/feeds/rdf-files.tar.bz2
          out_file: rdf-files.tar.bz2
          do_extract: true
veld_chain__gutenberg_triplestore___veld_export.yaml:
  url: https://github.com/veldhub/veld_chain__gutenberg_triplestore/blob/main/veld_export.yaml
  content:
    x-veld:
      chain:
        description: Given rq (sparql query) files, this chain exports data from Apache
          Fuseki triplestore into json files.
        topic:
        - ETL
        - RDF
        - triplestore
    services:
      veld_export:
        extends:
          file: ./code/veld_code__apache_jena_fuseki/veld_export.yaml
          service: veld_export
        volumes:
        - ./data/queries/:/veld/input/
        - ./data/fuseki_export/:/veld/output/
        environment:
          in_query_file: sample_query__authors_with_name_containing_substring.rq
          out_file: sample_query__authors_with_name_containing_substring.json
          out_format: json
          fuseki_dataset_name: gutenberg
    networks:
      veld_fuseki: null
veld_chain__gutenberg_triplestore___veld_import_rdf.yaml:
  url: https://github.com/veldhub/veld_chain__gutenberg_triplestore/blob/main/veld_import_rdf.yaml
  content:
    x-veld:
      chain:
        description: Imports the Gutenberg RDF/XML data into the Apache Fuseki triplestore
        topic:
        - ETL
        - RDF
        - triplestore
    services:
      veld_import_rdf:
        extends:
          file: ./code/veld_code__apache_jena_fuseki/veld_import_rdf.yaml
          service: veld_import_rdf
        volumes:
        - ./data/gutenberg_rdf/rdf-files/cache/epub/:/veld/input/
        environment:
          fuseki_dataset_name: gutenberg
    networks:
      veld_fuseki: null
veld_chain__gutenberg_triplestore___veld_run_server.yaml:
  url: https://github.com/veldhub/veld_chain__gutenberg_triplestore/blob/main/veld_run_server.yaml
  content:
    x-veld:
      chain:
        description: Runs an Apache Fuseki triplestore. Configuration can be adjusted
          with the respective shiro.ini file, of which there is a default integrated
          into this chain veld.
        topic:
        - RDF
        - triplestore
    services:
      veld_run_server:
        extends:
          file: ./code/veld_code__apache_jena_fuseki/veld_run_server.yaml
          service: veld_run_server
        volumes:
        - ./data/fuseki_data/:/veld/storage/
        - ./data/fuseki_config/:/veld/input/config/
    networks:
      veld_fuseki: null
veld_chain__mara_load_and_publish_models___veld_publish_to_hf.yaml:
  url: https://github.com/veldhub/veld_chain__mara_load_and_publish_models/blob/main/veld_publish_to_hf.yaml
  content:
    x-veld:
      chain:
        description: publish SpaCy text classification models trained during the MARA
          project to huggingface
        topic:
        - NLP
    services:
      veld_publish_to_hf:
        build: ./code/mara-nlp-suite__spacy-build/
        command: python /veld/code/test.py
        volumes:
        - ./code/mara-nlp-suite__spacy-build/test.py:/veld/code/test.py
        - ./data/mara-nlp-suite-internal/data_internal/models/mo3/:/veld/input/
veld_chain__train_infer_wordembeddings_multiple_architectures__amc___veld_analyse_evaluation.yaml:
  url: https://github.com/veldhub/veld_chain__train_infer_wordembeddings_multiple_architectures__amc/blob/main/veld_analyse_evaluation.yaml
  content:
    x-veld:
      chain:
        description: data visualization of all evaluation data. In a jupyter notebook.
        topic:
        - NLP
        - Word Embeddings
        - Data Visualization
    services:
      veld_analyse_evaluation:
        extends:
          file: ./code/veld_code__wordembeddings_evaluation/veld_analyse_evaluation.yaml
          service: veld_analyse_evaluation
        volumes:
        - ./data/veld_data__wordembeddings_evaluation/evaluation_results/:/veld/input/:z
        - ./data/veld_data__wordembeddings_evaluation/evaluation_results/:/veld/output/:z
        environment:
          in_evaluation_summary_file: summary.yaml
          out_visualization_html_file: summary_visualized.html
          out_visualization_png_file: summary_visualized.png
veld_chain__train_infer_wordembeddings_multiple_architectures__amc___veld_analyse_evaluation_non_interactive.yaml:
  url: https://github.com/veldhub/veld_chain__train_infer_wordembeddings_multiple_architectures__amc/blob/main/veld_analyse_evaluation_non_interactive.yaml
  content:
    x-veld:
      chain:
        description: data visualization of all evaluation data. non-interactive version
          of the juypter code.
        topic:
        - NLP
        - Word Embeddings
        - Data Visualization
    services:
      veld_analyse_evaluation_non_interactive:
        extends:
          file: ./code/veld_code__wordembeddings_evaluation/veld_analyse_evaluation_non_interactive.yaml
          service: veld_analyse_evaluation
        volumes:
        - ./data/veld_data__wordembeddings_evaluation/evaluation_results/:/veld/input/:z
        - ./data/veld_data__wordembeddings_evaluation/evaluation_results/:/veld/output/:z
        environment:
          in_evaluation_summary_file: summary.yaml
          out_visualization_html_file: summary_visualized.html
          out_visualization_png_file: summary_visualized.png
veld_chain__train_infer_wordembeddings_multiple_architectures__amc___veld_eval_fasttext.yaml:
  url: https://github.com/veldhub/veld_chain__train_infer_wordembeddings_multiple_architectures__amc/blob/main/veld_eval_fasttext.yaml
  content:
    x-veld:
      chain:
        description: custom evaluation logic on fasttext word embeddings.
        topic:
        - NLP
        - Machine Learning
        - Evaluation
    services:
      veld_eval_fasttext:
        extends:
          file: ./code/veld_code__wordembeddings_evaluation/veld_eval_fasttext.yaml
          service: veld_eval_fasttext
        volumes:
        - ./data/veld_data__fasttext_models/m9/:/veld/input/1/:z
        - ./data/veld_data__wordembeddings_evaluation/evaluation_gold_data/lowercase/:/veld/input/2/:z
        - ./data/veld_data__wordembeddings_evaluation/evaluation_results/:/veld/output/1/:z
        - ./data/veld_data__wordembeddings_evaluation/evaluation_results/logs/fasttext/:/veld/output/2:z
        environment:
          in_1_model_file: m9.bin
          in_1_model_metadata_file: veld.yaml
          in_2_eval_gold_data_file: eval_data_lowercase.yaml
          out_1_eval_summary_file: summary.yaml
          out_2_eval_log_file: m9.txt
        depends_on:
          veld_train_fasttext:
            condition: service_completed_successfully
veld_chain__train_infer_wordembeddings_multiple_architectures__amc___veld_eval_glove.yaml:
  url: https://github.com/veldhub/veld_chain__train_infer_wordembeddings_multiple_architectures__amc/blob/main/veld_eval_glove.yaml
  content:
    x-veld:
      chain: null
    services:
      veld_eval_glove:
        extends:
          file: ./code/veld_code__wordembeddings_evaluation/veld_eval_glove.yaml
          service: veld_eval_glove
        volumes:
        - ./data/veld_data__glove_models/data/m3/:/veld/input/1/:z
        - ./data/veld_data__wordembeddings_evaluation/evaluation_gold_data/lowercase/:/veld/input/2/:z
        - ./data/veld_data__wordembeddings_evaluation/evaluation_results/:/veld/output/1/:z
        - ./data/veld_data__wordembeddings_evaluation/evaluation_results/logs/glove/:/veld/output/2/:z
        environment:
          in_1_vector_file: m3_vector.txt
          model_id: m3
          in_1_model_metadata_file: veld.yaml
          in_2_eval_gold_data_file: eval_data_lowercase.yaml
          out_1_eval_summary_file: summary.yaml
          out_2_eval_log_file: m3.txt
veld_chain__train_infer_wordembeddings_multiple_architectures__amc___veld_eval_word2vec.yaml:
  url: https://github.com/veldhub/veld_chain__train_infer_wordembeddings_multiple_architectures__amc/blob/main/veld_eval_word2vec.yaml
  content:
    x-veld:
      chain: null
    services:
      veld_eval_word2vec:
        extends:
          file: ./code/veld_code__wordembeddings_evaluation/veld_eval_word2vec.yaml
          service: veld_eval_word2vec
        volumes:
        - ./data/veld_data__word2vec_models/m9/:/veld/input/1/:z
        - ./data/veld_data__wordembeddings_evaluation/evaluation_gold_data/lowercase/:/veld/input/2/:z
        - ./data/veld_data__wordembeddings_evaluation/evaluation_results/:/veld/output/1/:z
        - ./data/veld_data__wordembeddings_evaluation/evaluation_results/logs/word2vec/:/veld/output/2:z
        environment:
          in_1_model_file: m9.bin
          in_1_model_metadata_file: veld.yaml
          in_2_eval_gold_data_file: eval_data_lowercase.yaml
          out_1_eval_summary_file: summary.yaml
          out_2_eval_log_file: m9.txt
veld_chain__train_infer_wordembeddings_multiple_architectures__amc___veld_jupyter_notebook_fasttext.yaml:
  url: https://github.com/veldhub/veld_chain__train_infer_wordembeddings_multiple_architectures__amc/blob/main/veld_jupyter_notebook_fasttext.yaml
  content:
    x-veld:
      chain: null
    services:
      veld_jupyter_notebook_fasttext:
        extends:
          file: ./code/veld_code__fasttext/veld_jupyter_notebook.yaml
          service: veld_jupyter_notebook
        ports:
        - 8889:8888
        volumes:
        - ./data/veld_data__amc_we_training_data/:/veld/storage/data/veld_data__amc_we_training_data/:z
        - ./data/veld_data__fasttext_models/:/veld/storag./data/veld_data__fasttext_models/:z
veld_chain__train_infer_wordembeddings_multiple_architectures__amc___veld_jupyter_notebook_glove.yaml:
  url: https://github.com/veldhub/veld_chain__train_infer_wordembeddings_multiple_architectures__amc/blob/main/veld_jupyter_notebook_glove.yaml
  content:
    x-veld:
      chain: null
    services:
      veld_jupyter_notebook_glove:
        extends:
          file: ./code/veld_code__glove/veld_jupyter_notebook.yaml
          service: veld_jupyter_notebook
        ports:
        - 8890:8888
        volumes:
        - ./data/veld_data__amc_we_training_data/:/veld/storage/data/veld_data__amc_we_training_data/:z
        - ./data/veld_data__glove_models/:/veld/storag./data/veld_data__glove_models/:z
veld_chain__train_infer_wordembeddings_multiple_architectures__amc___veld_jupyter_notebook_word2vec.yaml:
  url: https://github.com/veldhub/veld_chain__train_infer_wordembeddings_multiple_architectures__amc/blob/main/veld_jupyter_notebook_word2vec.yaml
  content:
    x-veld:
      chain: null
    services:
      veld_jupyter_notebook_word2vec:
        extends:
          file: ./code/veld_code__word2vec/veld_jupyter_notebook.yaml
          service: veld_jupyter_notebook
        ports:
        - 8891:8888
        volumes:
        - ./data/veld_data__amc_we_training_data/:/veld/storage/data/veld_data__amc_we_training_data/:z
        - ./data/veld_data__word2vec_models/:/veld/storag./data/veld_data__word2vec_models/:z
veld_chain__train_infer_wordembeddings_multiple_architectures__amc___veld_preprocess_clean.yaml:
  url: https://github.com/veldhub/veld_chain__train_infer_wordembeddings_multiple_architectures__amc/blob/main/veld_preprocess_clean.yaml
  content:
    x-veld:
      code:
        description: Removes lines that don't reach a threshold regarding the ratio
          of textual content to non-textual (numbers, special characters) content.
        topic:
        - NLP
        - Preprocessing
        - ETL
    services:
      veld_preprocess_clean:
        extends:
          file: ./code/veld_code__wordembeddings_preprocessing/veld_preprocess_clean.yaml
          service: veld_preprocess_clean
        volumes:
        - ./data/veld_data__amc_we_training_data/data/203_vert_rftt_inhalt_nodup__uniq__stripped__lowercased__punctuation_removed/:/veld/input/:z
        - ./data/veld_data__amc_we_training_data/data/203_vert_rftt_inhalt_nodup__uniq__stripped__lowercased__punctuation_removed__cleaned/:/veld/output/1/:z
        - ./tmp_clean/:/veld/output/2/clean/:z
        - ./tmp_dirty/:/veld/output/2/dirty/:z
        environment:
          in_file: data.txt
          out_file_clean: data.txt
          out_file_dirty: data_dirty.txt
          min_percentage_char: 80
          out_data_description: 'AMC data: stripped from non-alphanumeric lines, 10%
            sampled, lowercased, punctuation removed, cleaned from lines not having
            enough text'
          cpu_count: 15
          buffer_segments: 100
veld_chain__train_infer_wordembeddings_multiple_architectures__amc___veld_preprocess_lowercase.yaml:
  url: https://github.com/veldhub/veld_chain__train_infer_wordembeddings_multiple_architectures__amc/blob/main/veld_preprocess_lowercase.yaml
  content:
    x-veld:
      chain:
        description: makes entire text lowercase
        topic:
        - NLP
        - Preprocessing
        - ETL
    services:
      veld_preprocess_lowercase:
        extends:
          file: ./code/veld_code__wordembeddings_preprocessing/veld_preprocess_lowercase.yaml
          service: veld_preprocess_lowercase
        volumes:
        - ./data/veld_data__amc_we_training_data/data/203_vert_rftt_inhalt_nodup__uniq__stripped__sampled/:/veld/input/:z
        - ./data/veld_data__amc_we_training_data/data/203_vert_rftt_inhalt_nodup__uniq__stripped__sampled__lowercased/:/veld/output/:z
        environment:
          in_txt_file: data.txt
          out_txt_file: data.txt
          out_data_description: 'AMC data: stripped from non-alphanumeric lines, 10%
            sampled, lowercased.'
veld_chain__train_infer_wordembeddings_multiple_architectures__amc___veld_preprocess_remove_punctuation.yaml:
  url: https://github.com/veldhub/veld_chain__train_infer_wordembeddings_multiple_architectures__amc/blob/main/veld_preprocess_remove_punctuation.yaml
  content:
    x-veld:
      chain:
        description: removes punctuation from text with spaCy pretrained models
        topic:
        - NLP
        - Preprocessing
        - ETL
    services:
      veld_preprocess_remove_punctuation:
        extends:
          file: ./code/veld_code__wordembeddings_preprocessing/veld_preprocess_remove_punctuation.yaml
          service: veld_preprocess_remove_punctuation
        volumes:
        - ./data/veld_data__amc_we_training_data/data/203_vert_rftt_inhalt_nodup__uniq__stripped__lowercased/:/veld/input/:z
        - ./tmp/:/veld/output/2/:z
        - ./data/veld_data__amc_we_training_data/data/203_vert_rftt_inhalt_nodup__uniq__stripped__lowercased__punctuation_removed/:/veld/output/1/:z
        environment:
          in_txt_file: data.txt
          out_txt_file: data.txt
          out_data_description: 'AMC data: stripped from non-alphanumeric lines, lowercased,
            punctuation removed.'
          cpu_count: 14
          buffer_segments: 1000
veld_chain__train_infer_wordembeddings_multiple_architectures__amc___veld_preprocess_sample.yaml:
  url: https://github.com/veldhub/veld_chain__train_infer_wordembeddings_multiple_architectures__amc/blob/main/veld_preprocess_sample.yaml
  content:
    x-veld:
      chain:
        description: takes a random sample of lines from a txt file. Randomness can
          be set with a seed too
        topic:
        - NLP
        - Preprocessing
        - ETL
    services:
      veld_preprocess_sample:
        extends:
          file: ./code/veld_code__wordembeddings_preprocessing/veld_preprocess_sample.yaml
          service: veld_preprocess_sample
        volumes:
        - ./data/veld_data__amc_we_training_data/data/203_vert_rftt_inhalt_nodup__uniq__stripped/:/veld/input/:z
        - ./exp_bert_tmp/:/veld/output/:z
        environment:
          in_file: data.txt
          out_file: data.txt
          out_data_description: 10% of AMC
          percentage_sample: 0.01
          sample_random_seed: 42
          buffer_segments: 100
veld_chain__train_infer_wordembeddings_multiple_architectures__amc___veld_preprocess_strip.yaml:
  url: https://github.com/veldhub/veld_chain__train_infer_wordembeddings_multiple_architectures__amc/blob/main/veld_preprocess_strip.yaml
  content:
    x-veld:
      chain:
        description: removes all lines before and after given line numbers
        topic:
        - NLP
        - Preprocessing
        - ETL
    services:
      veld_preprocess_strip:
        extends:
          file: ./code/veld_code__wordembeddings_preprocessing/veld_preprocess_strip.yaml
          service: veld_preprocess_strip
        volumes:
        - ./data/veld_data__amc_we_training_data/data/203_vert_rftt_inhalt_nodup__uniq/:/veld/input/:z
        - ./data/veld_data__amc_we_training_data/data/203_vert_rftt_inhalt_nodup__uniq__stripped/:/veld/output/:z
        environment:
          in_file: data.txt
          out_file: data.txt
          line_start: 54993
          line_end: 521781020
veld_chain__train_infer_wordembeddings_multiple_architectures__amc___veld_train_fasttext.yaml:
  url: https://github.com/veldhub/veld_chain__train_infer_wordembeddings_multiple_architectures__amc/blob/main/veld_train_fasttext.yaml
  content:
    x-veld:
      chain:
        description: A fasttext training setup.
        topic:
        - NLP
        - Machine Learning
        - Word Embeddings
    services:
      veld_train_fasttext:
        extends:
          file: ./code/veld_code__fasttext/veld_train.yaml
          service: veld_train
        volumes:
        - ./veld_data_amc_we_training_data/203_vert_rftt_inhalt_nodup__uniq__stripped__lowercased__punctuation_removed__cleaned/:/veld/input/:z
        - ./veld_data_fasttext_models/m9/:/veld/output/:z
        environment:
          in_train_data_file: data.txt
          out_model_file: m9.bin
          model_description: 100% AMC model
          vector_size: 300
          epochs: 10
          window_size: 10
veld_chain__train_infer_wordembeddings_multiple_architectures__amc___veld_train_glove.yaml:
  url: https://github.com/veldhub/veld_chain__train_infer_wordembeddings_multiple_architectures__amc/blob/main/veld_train_glove.yaml
  content:
    x-veld:
      chain:
        description: A GloVe training setup.
        topic:
        - NLP
        - Machine Learning
        - Word Embeddings
    services:
      veld_train_glove:
        extends:
          file: ./code/veld_code__glove/veld_train.yaml
          service: veld_train
        volumes:
        - ./data/veld_data__amc_we_training_data/data/203_vert_rftt_inhalt_nodup__uniq__stripped__sampled__lowercased__punctuation_removed__cleaned/:/veld/input/:z
        - ./data/veld_data__glove_models/data/m4/:/veld/output/:z
        environment:
          in_corpus_file: data.txt
          out_vocab_file: m4_vocab.txt
          out_cooccurrence_file: m4_cooccurrence.bin
          out_cooccurrence_shuf_file: m4_cooccurrence_shuf.bin
          out_vector_file: m4_vector
          model_id: m4
          model_description: 10% AMC model
          verbose: 2
          memory: 4.0
          vocab_min_count: 5
          vector_size: 200
          max_iter: 10
          window_size: 15
          binary: 2
          num_threads: 14
          x_max: 10
veld_chain__train_infer_wordembeddings_multiple_architectures__amc___veld_train_word2vec.yaml:
  url: https://github.com/veldhub/veld_chain__train_infer_wordembeddings_multiple_architectures__amc/blob/main/veld_train_word2vec.yaml
  content:
    x-veld:
      chain:
        description: A word2vec training setup
        topic:
        - NLP
        - Machine Learning
        - Word Embeddings
    services:
      veld_train_word2vec:
        extends:
          file: ./code/veld_code__word2vec/veld_train.yaml
          service: veld_train
        volumes:
        - ./data/veld_data__amc_we_training_data/data/203_vert_rftt_inhalt_nodup__uniq__stripped__lowercased__punctuation_removed__cleaned/:/veld/input/:z
        - ./data/veld_data__word2vec_models/m8/:/veld/output/:z
        environment:
          in_train_data_file: data.txt
          out_model_file: m8.bin
          model_description: 100% AMC model
          epochs: 10
          vector_size: 300
          window: 10
veld_chain__train_infer_wordembeddings_multiple_architectures__wikipedia___veld_playground_jupyter_notebook_fasttext.yaml:
  url: https://github.com/veldhub/veld_chain__train_infer_wordembeddings_multiple_architectures__wikipedia/blob/main/veld_playground_jupyter_notebook_fasttext.yaml
  content:
    x-veld:
      chain:
        description: jupyter notebook for playing with fasttext models
        topic: NLP
    services:
      veld_jupyter_notebook_fasttext:
        extends:
          file: ./code/veld_code__fasttext/veld_jupyter_notebook.yaml
          service: veld_jupyter_notebook
        volumes:
        - ./data/training_data/:/veld/storage/training_data/:z
        - ./data/models/fasttext/:/veld/storage/models/:z
veld_chain__train_infer_wordembeddings_multiple_architectures__wikipedia___veld_playground_jupyter_notebook_glove.yaml:
  url: https://github.com/veldhub/veld_chain__train_infer_wordembeddings_multiple_architectures__wikipedia/blob/main/veld_playground_jupyter_notebook_glove.yaml
  content:
    x-veld:
      chain:
        description: jupyter notebook for playing with glove models
        topic: NLP
    services:
      veld_jupyter_notebook_glove:
        extends:
          file: ./code/veld_code__glove/veld_jupyter_notebook.yaml
          service: veld_jupyter_notebook
        volumes:
        - ./data/training_data/:/veld/storage/training_data/:z
        - ./data/models/glove/:/veld/storage/models/:z
veld_chain__train_infer_wordembeddings_multiple_architectures__wikipedia___veld_playground_jupyter_notebook_word2vec.yaml:
  url: https://github.com/veldhub/veld_chain__train_infer_wordembeddings_multiple_architectures__wikipedia/blob/main/veld_playground_jupyter_notebook_word2vec.yaml
  content:
    x-veld:
      chain:
        description: jupyter notebook for playing with word2vec models
        topic: NLP
    services:
      veld_jupyter_notebook_word2vec:
        extends:
          file: ./code/veld_code__word2vec/veld_jupyter_notebook.yaml
          service: veld_jupyter_notebook
        volumes:
        - ./data/training_data/:/veld/storage/training_data/:z
        - ./data/models/word2vec/:/veld/storage/models/:z
? veld_chain__train_infer_wordembeddings_multiple_architectures__wikipedia___veld_step_01_preprocess_download_and_extract.yaml
: url: https://github.com/veldhub/veld_chain__train_infer_wordembeddings_multiple_architectures__wikipedia/blob/main/veld_step_01_preprocess_download_and_extract.yaml
  content:
    x-veld:
      chain:
        description: downloading wikipedia archive and extracting each article to
          a json file.
        topic:
        - NLP
        - ETL
    services:
      veld_preprocess_download_and_extract:
        extends:
          file: ./code/veld_code__wikipedia_nlp_preprocessing/veld_download_and_extract.yaml
          service: veld_download_and_extract
        volumes:
        - ./data/training_data/extracted/:/veld/output/:z
        environment:
          wikipedia_dump_url: https://dumps.wikimedia.org/dewiki/latest/dewiki-latest-pages-articles.xml.bz2
? veld_chain__train_infer_wordembeddings_multiple_architectures__wikipedia___veld_step_02_preprocess_transform_wiki_json_to_txt.yaml
: url: https://github.com/veldhub/veld_chain__train_infer_wordembeddings_multiple_architectures__wikipedia/blob/main/veld_step_02_preprocess_transform_wiki_json_to_txt.yaml
  content:
    x-veld:
      chain:
        description: transforming wikipedia jsons to a single txt file.
        topic:
        - NLP
        - ETL
    services:
      veld_preprocess_transform_wiki_json_to_txt_articles:
        extends:
          file: ./code/veld_code__wikipedia_nlp_preprocessing/veld_transform_wiki_json_to_txt.yaml
          service: veld_transform_wiki_json_to_txt
        volumes:
        - ./data/training_data/extracted/data/:/veld/input/:z
        - ./data/training_data/extracted__txt_article_per_line/:/veld/output/:z
        environment:
          out_txt_file: data.txt
          out_data_description: 10% german wikipedia, transformed from json files
            into one txt file, each json file's content persisted with each each article
            in a single line.
          set_split_sentences: false
          sample_size_percentage: 10
          cpu_count: 14
          buffer_segments: 10
      veld_preprocess_transform_wiki_json_to_txt_sentences:
        extends:
          file: ./code/veld_code__wikipedia_nlp_preprocessing/veld_transform_wiki_json_to_txt.yaml
          service: veld_transform_wiki_json_to_txt
        volumes:
        - ./data/training_data/extracted/data/:/veld/input/:z
        - ./data/training_data/extracted__txt_sentence_per_line/:/veld/output/:z
        environment:
          out_txt_file: data.txt
          out_data_description: 10% german wikipedia, transformed from json files
            into one txt file, each json file's content persisted with each sentence
            in a single line.
          set_split_sentences: true
          sample_size_percentage: 10
          cpu_count: 14
          buffer_segments: 10
        depends_on:
          veld_preprocess_transform_wiki_json_to_txt_articles:
            condition: service_completed_successfully
veld_chain__train_infer_wordembeddings_multiple_architectures__wikipedia___veld_step_03_preprocess_lowercase.yaml:
  url: https://github.com/veldhub/veld_chain__train_infer_wordembeddings_multiple_architectures__wikipedia/blob/main/veld_step_03_preprocess_lowercase.yaml
  content:
    x-veld:
      chain:
        description: preprocessing by making the entire text lowercase.
        topic:
        - NLP
        - ETL
    services:
      veld_preprocess_lowercase_articles:
        extends:
          file: ./code/veld_code__wordembeddings_preprocessing/veld_preprocess_lowercase.yaml
          service: veld_preprocess_lowercase
        volumes:
        - ./data/training_data/extracted__txt_article_per_line/:/veld/input/:z
        - ./data/training_data/extracted__txt_article_per_line__lowercased/:/veld/output/:z
        environment:
          in_txt_file: data.txt
          out_txt_file: data.txt
          out_data_description: all data lowercased
      veld_preprocess_lowercase_sentences:
        extends:
          file: ./code/veld_code__wordembeddings_preprocessing/veld_preprocess_lowercase.yaml
          service: veld_preprocess_lowercase
        volumes:
        - ./data/training_data/extracted__txt_sentence_per_line/:/veld/input/:z
        - ./data/training_data/extracted__txt_sentence_per_line__lowercased/:/veld/output/:z
        environment:
          in_txt_file: data.txt
          out_txt_file: data.txt
          out_data_description: all data lowercased
        depends_on:
          veld_preprocess_lowercase_articles:
            condition: service_completed_successfully
veld_chain__train_infer_wordembeddings_multiple_architectures__wikipedia___veld_step_04_preprocess_remove_punctuation.yaml:
  url: https://github.com/veldhub/veld_chain__train_infer_wordembeddings_multiple_architectures__wikipedia/blob/main/veld_step_04_preprocess_remove_punctuation.yaml
  content:
    x-veld:
      chain:
        description: preprocessing by removing punctuation of the entire text.
        topic:
        - NLP
        - ETL
    services:
      veld_preprocess_remove_punctuation_articles:
        extends:
          file: ./code/veld_code__wordembeddings_preprocessing/veld_preprocess_remove_punctuation.yaml
          service: veld_preprocess_remove_punctuation
        volumes:
        - ./data/training_data/extracted__txt_article_per_line__lowercased/:/veld/input/:z
        - ./data/training_data/extracted__txt_article_per_line__lowercased__removed_punctuation/:/veld/output/txt/:z
        environment:
          in_txt_file: data.txt
          out_txt_file: data.txt
          out_data_description: all data lowercased, punctuation removed
          cpu_count: 14
          buffer_segments: 100
      veld_preprocess_remove_punctuation_sentences:
        extends:
          file: ./code/veld_code__wordembeddings_preprocessing/veld_preprocess_remove_punctuation.yaml
          service: veld_preprocess_remove_punctuation
        volumes:
        - ./data/training_data/extracted__txt_sentence_per_line__lowercased/:/veld/input/:z
        - ./data/training_data/extracted__txt_sentence_per_line__lowercased__removed_punctuation/:/veld/output/txt/:z
        environment:
          in_txt_file: data.txt
          out_txt_file: data.txt
          out_data_description: all data lowercased, punctuation removed
          cpu_count: 14
          buffer_segments: 100
        depends_on:
          veld_preprocess_remove_punctuation_articles:
            condition: service_completed_successfully
veld_chain__train_infer_wordembeddings_multiple_architectures__wikipedia___veld_step_05_train_fasttext.yaml:
  url: https://github.com/veldhub/veld_chain__train_infer_wordembeddings_multiple_architectures__wikipedia/blob/main/veld_step_05_train_fasttext.yaml
  content:
    x-veld:
      chain:
        description: training a fasttext model on wikipediaa
        topic: NLP
    services:
      veld_train_fasttext:
        extends:
          file: ./code/veld_code__fasttext/veld_train.yaml
          service: veld_train
        volumes:
        - ./data/training_data/extracted__txt_sentence_per_line__lowercased__removed_punctuation/:/veld/input/:z
        - ./data/models/fasttext/m1/:/veld/output/:z
        environment:
          in_train_data_file: data.txt
          out_model_file: m1.bin
          model_description: 10% wikipedia test model
          vector_size: 200
          epochs: 5
          window_size: 5
veld_chain__train_infer_wordembeddings_multiple_architectures__wikipedia___veld_step_06_train_word2vec.yaml:
  url: https://github.com/veldhub/veld_chain__train_infer_wordembeddings_multiple_architectures__wikipedia/blob/main/veld_step_06_train_word2vec.yaml
  content:
    x-veld:
      chain:
        description: training a word2vec model on wikipediaa
        topic: NLP
    services:
      veld_train_word2vec:
        extends:
          file: ./code/veld_code__word2vec/veld_train.yaml
          service: veld_train
        volumes:
        - ./data/training_data/extracted__txt_sentence_per_line__lowercased__removed_punctuation/:/veld/input/:z
        - ./data/models/word2vec/m1/:/veld/output/:z
        environment:
          in_train_data_file: data.txt
          out_model_file: m1.bin
          model_description: 10% wikipedia test model
          epochs: 5
          vector_size: 200
          window: 5
veld_chain__train_infer_wordembeddings_multiple_architectures__wikipedia___veld_step_07_train_glove.yaml:
  url: https://github.com/veldhub/veld_chain__train_infer_wordembeddings_multiple_architectures__wikipedia/blob/main/veld_step_07_train_glove.yaml
  content:
    x-veld:
      chain:
        description: training a glove model on wikipediaa
        topic: NLP
    services:
      veld_train_glove:
        extends:
          file: ./code/veld_code__glove/veld_train.yaml
          service: veld_train
        volumes:
        - ./data/training_data/extracted__txt_article_per_line__lowercased__removed_punctuation/:/veld/input/:z
        - ./data/models/glove/m1/:/veld/output/:z
        environment:
          in_corpus_file: data.txt
          out_vocab_file: m1_vocab.txt
          out_cooccurrence_file: m1_cooccurrence.bin
          out_cooccurrence_shuf_file: m1_cooccurrence_shuf.bin
          out_vector_file: m1_vector
          model_id: m1
          model_description: 10% wikipedia test model
          verbose: 2
          memory: 1.0
          vocab_min_count: 5
          vector_size: 200
          max_iter: 5
          window_size: 5
          binary: 2
          num_threads: 11
          x_max: 10
veld_chain__train_infer_wordembeddings_multiple_architectures__wikipedia___veld_step_08_eval_fasttext.yaml:
  url: https://github.com/veldhub/veld_chain__train_infer_wordembeddings_multiple_architectures__wikipedia/blob/main/veld_step_08_eval_fasttext.yaml
  content:
    x-veld:
      chain:
        description: evaluate fasttext model against evaluation gold data
        topic:
        - NLP
        - Evaluation
    services:
      veld_eval_fasttext:
        extends:
          file: ./code/veld_code__wordembeddings_evaluation/veld_eval_fasttext.yaml
          service: veld_eval_fasttext
        volumes:
        - ./data/models/fasttext/m1/:/veld/input/model/:z
        - ./data/veld_data__wordembeddings_evaluation/evaluation_gold_data/lowercase/:/veld/input/eval_data/:z
        - ./data/veld_data__wordembeddings_evaluation/evaluation_results/:/veld/output/summary/:z
        - ./data/veld_data__wordembeddings_evaluation/evaluation_results/logs/fasttext/:/veld/output/log/:z
        environment:
          in_model_file: m1.bin
          in_model_metadata_file: veld.yaml
          in_eval_gold_data_file: eval_data_lowercase.yaml
          out_eval_summary_file: summary.yaml
          out_eval_log_file: m1.txt
veld_chain__train_infer_wordembeddings_multiple_architectures__wikipedia___veld_step_09_eval_word2vec.yaml:
  url: https://github.com/veldhub/veld_chain__train_infer_wordembeddings_multiple_architectures__wikipedia/blob/main/veld_step_09_eval_word2vec.yaml
  content:
    x-veld:
      chain:
        description: evaluate word2vec model against evaluation gold data
        topic:
        - NLP
        - Evaluation
    services:
      veld_eval_word2vec:
        extends:
          file: ./code/veld_code__wordembeddings_evaluation/veld_eval_word2vec.yaml
          service: veld_eval_word2vec
        volumes:
        - ./data/models/word2vec/m1/:/veld/input/model/:z
        - ./data/veld_data__wordembeddings_evaluation/evaluation_gold_data/lowercase/:/veld/input/eval_data/:z
        - ./data/veld_data__wordembeddings_evaluation/evaluation_results/:/veld/output/summary/:z
        - ./data/veld_data__wordembeddings_evaluation/evaluation_results/logs/word2vec/:/veld/output/log/:z
        environment:
          in_model_file: m1.bin
          in_model_metadata_file: veld.yaml
          in_eval_gold_data_file: eval_data_lowercase.yaml
          out_eval_summary_file: summary.yaml
          out_eval_log_file: m1.txt
veld_chain__train_infer_wordembeddings_multiple_architectures__wikipedia___veld_step_10_eval_glove.yaml:
  url: https://github.com/veldhub/veld_chain__train_infer_wordembeddings_multiple_architectures__wikipedia/blob/main/veld_step_10_eval_glove.yaml
  content:
    x-veld:
      chain:
        description: evaluate glove model against evaluation gold data
        topic:
        - NLP
        - Evaluation
    services:
      veld_eval_glove:
        extends:
          file: ./code/veld_code__wordembeddings_evaluation/veld_eval_glove.yaml
          service: veld_eval_glove
        volumes:
        - ./data/models/glove/m1/:/veld/input/model/:z
        - ./data/veld_data__wordembeddings_evaluation/evaluation_gold_data/lowercase/:/veld/input/eval_data/:z
        - ./data/veld_data__wordembeddings_evaluation/evaluation_results/:/veld/output/summary/:z
        - ./data/veld_data__wordembeddings_evaluation/evaluation_results/logs/glove/:/veld/output/log/:z
        environment:
          in_vector_file: m1_vector.txt
          model_id: m1
          in_model_metadata_file: veld.yaml
          in_eval_gold_data_file: eval_data_lowercase.yaml
          out_eval_summary_file: summary.yaml
          out_eval_log_file: m1.txt
veld_chain__train_infer_wordembeddings_multiple_architectures__wikipedia___veld_step_11_analyse_evaluation.yaml:
  url: https://github.com/veldhub/veld_chain__train_infer_wordembeddings_multiple_architectures__wikipedia/blob/main/veld_step_11_analyse_evaluation.yaml
  content:
    x-veld:
      chain:
        description: chain of analysing and evaluating models trained on wikipedia
        topic:
        - NLP
        - Evaluation
    services:
      veld_analyse_evaluation:
        extends:
          file: ./code/veld_code__wordembeddings_evaluation/veld_analyse_evaluation.yaml
          service: veld_analyse_evaluation
        volumes:
        - ./data/veld_data__wordembeddings_evaluation/evaluation_results/:/veld/input/:z
        - ./data/veld_data__wordembeddings_evaluation/evaluation_results/:/veld/output/:z
        environment:
          in_evaluation_summary_file: summary.yaml
          out_visualization_html_file: summary_visualized.html
          out_visualization_png_file: summary_visualized.png
veld_chain__train_infer_wordembeddings_multiple_architectures__wikipedia___veld_step_all_multi_chain.yaml:
  url: https://github.com/veldhub/veld_chain__train_infer_wordembeddings_multiple_architectures__wikipedia/blob/main/veld_step_all_multi_chain.yaml
  content:
    x-veld:
      chain:
        description: An entire multi chain, going through everything (fetching, preprocessing,
          training, evaluation in one service. This chain is composed of the other
          chains and is rather meant as a demonstration of the entire setup
        topic: NLP
    services:
      veld_preprocess_transform_wiki_json_to_txt_fasttext-word2vec:
        extends:
          file: ./veld_code_20_wikipedia_nlp_preprocessing/veld_transform_wiki_json_to_txt.yaml
          service: veld_transform_wiki_json_to_txt
        volumes:
        - ./data_local/training_data/extracted/:/veld/input/:z
        - ./data_local/training_data/extracted__txt_sentence_per_line/:/veld/output/:z
        environment:
          in_json_folder: data
          out_txt_file: de_wiki_sample.txt
          out_data_description: sample wikipedia, transformed from json files into
            one txt file, each json file's content is split into sentences and persisted
            per line. Best for fastText and word2vec.
          sample_size_percentage: 10
          set_split_sentences: true
          cpu_count: 14
          sample_random_seed: 42
          info_interval: 100
      veld_preprocess_transform_wiki_json_to_txt_glove:
        extends:
          file: ./veld_code_20_wikipedia_nlp_preprocessing/veld_transform_wiki_json_to_txt.yaml
          service: veld_transform_wiki_json_to_txt
        volumes:
        - ./data_local/training_data/extracted/:/veld/input/:z
        - ./data_local/training_data/extracted__txt_article_per_line/:/veld/output/:z
        environment:
          in_json_folder: data
          out_txt_file: de_wiki_sample.txt
          out_data_description: sample wikipedia, transformed from json files into
            one txt file, each json file's content is persisted per line. Best for
            GloVe.
          sample_size_percentage: 10
          set_split_sentences: false
          cpu_count: 14
          sample_random_seed: 42
          info_interval: 100
        depends_on:
          veld_preprocess_transform_wiki_json_to_txt_fasttext-word2vec:
            condition: service_completed_successfully
      veld_preprocess_lowercase_fasttext-word2vec:
        extends:
          file: ./veld_code_19_we_preprocessing/veld_preprocess_lowercase.yaml
          service: veld_preprocess_lowercase
        volumes:
        - ./data_local/training_data/extracted__txt_sentence_per_line/:/veld/input/:z
        - ./data_local/training_data/extracted__txt_sentence_per_line__lowercased/:/veld/output/:z
        environment:
          in_txt_file: de_wiki_sample.txt
          out_txt_file: de_wiki_sample.txt
          out_data_description: sample wikipedia, single txt, one sentence per line,
            lowercased,
        depends_on:
          veld_preprocess_transform_wiki_json_to_txt_glove:
            condition: service_completed_successfully
      veld_preprocess_lowercase_glove:
        extends:
          file: ./veld_code_19_we_preprocessing/veld_preprocess_lowercase.yaml
          service: veld_preprocess_lowercase
        volumes:
        - ./data_local/training_data/extracted__txt_article_per_line/:/veld/input/:z
        - ./data_local/training_data/extracted__txt_article_per_line__lowercased/:/veld/output/:z
        environment:
          in_txt_file: de_wiki_sample.txt
          out_txt_file: de_wiki_sample.txt
          out_data_description: sample wikipedia, single txt, one article per line,
            lowercased
        depends_on:
          veld_preprocess_lowercase_fasttext-word2vec:
            condition: service_completed_successfully
      veld_preprocess_remove_punctuation_fasttext-word2vec:
        extends:
          file: ./veld_code_19_we_preprocessing/veld_preprocess_remove_punctuation.yaml
          service: veld_preprocess_remove_punctuation
        volumes:
        - ./data_local/training_data/extracted__txt_sentence_per_line__lowercased/:/veld/input/:z
        - ./data_local/training_data/extracted__txt_sentence_per_line__lowercased__removed_punctuation/:/veld/output/:z
        environment:
          in_txt_file: de_wiki_sample.txt
          out_txt_file: de_wiki_sample.txt
          out_data_description: sample wikipedia, single txt, one sentence per line,
            lowercased, removed punctuation
          cpu_count: 14
          info_interval: 100
        depends_on:
          veld_preprocess_lowercase_glove:
            condition: service_completed_successfully
      veld_preprocess_remove_punctuation_glove:
        extends:
          file: ./veld_code_19_we_preprocessing/veld_preprocess_remove_punctuation.yaml
          service: veld_preprocess_remove_punctuation
        volumes:
        - ./data_local/training_data/extracted__txt_article_per_line__lowercased/:/veld/input/:z
        - ./data_local/training_data/extracted__txt_article_per_line__lowercased__removed_punctuation/:/veld/output/:z
        environment:
          in_txt_file: de_wiki_sample.txt
          out_txt_file: de_wiki_sample.txt
          out_data_description: sample wikipedia, single txt, one article per line,
            lowercased, removed punctuation
          cpu_count: 14
          info_interval: 100
        depends_on:
          veld_preprocess_remove_punctuation_fasttext-word2vec:
            condition: service_completed_successfully
      veld_train_fasttext:
        extends:
          file: ./veld_code_12_fasttext/veld_train.yaml
          service: veld_train
        volumes:
        - ./data_local/training_data/extracted__txt_sentence_per_line__lowercased__removed_punctuation/:/veld/input/:z
        - ./data_local/models/fasttext/m1/:/veld/output/:z
        environment:
          in_train_data_file: de_wiki_sample.txt
          model_id: m1
          model_description: fasttext test model
          vector_size: 200
          epochs: 10
        depends_on:
          veld_preprocess_remove_punctuation_glove:
            condition: service_completed_successfully
      veld_train_word2vec:
        extends:
          file: ./veld_code_13_word2vec/veld_train.yaml
          service: veld_train
        volumes:
        - ./data_local/training_data/extracted__txt_sentence_per_line__lowercased__removed_punctuation/:/veld/input/:z
        - ./data_local/models/word2vec/m1/:/veld/output/:z
        environment:
          in_train_data_file: de_wiki_sample.txt
          model_id: m1
          model_description: word2vec test model
          epochs: 10
          vector_size: 200
          window: 5
          min_count: 5
        depends_on:
          veld_train_fasttext:
            condition: service_completed_successfully
      veld_train_glove:
        extends:
          file: ./veld_code_17_glove/veld_train.yaml
          service: veld_train
        volumes:
        - ./data_local/training_data/extracted__txt_article_per_line__lowercased__removed_punctuation/:/veld/input/:z
        - ./data_local/models/glove/m1/:/veld/output/:z
        environment:
          in_corpus_file: de_wiki_sample.txt
          out_vocab_file: m1_vocab.txt
          out_cooccurrence_file: m1_cooccurrence.bin
          out_cooccurrence_shuf_file: m1_cooccurrence_shuf.bin
          out_vector_file: m1_vector
          model_id: m1
          model_description: glove test model
          verbose: 2
          memory: 4.0
          vocab_min_count: 5
          vector_size: 200
          max_iter: 10
          window_size: 15
          binary: 2
          num_threads: 14
          x_max: 10
        depends_on:
          veld_train_word2vec:
            condition: service_completed_successfully
      veld_eval_fasttext:
        extends:
          file: ./veld_code_14_we_evaluation/veld_eval_fasttext.yaml
          service: veld_eval_fasttext
        volumes:
        - ./data_local/models/fasttext/m1/:/veld/input/1/:z
        - ./veld_data_10_we_evaluation/evaluation_gold_data/lowercase/:/veld/input/2/:z
        - ./veld_data_10_we_evaluation/evaluation_results/:/veld/output/1/:z
        - ./veld_data_10_we_evaluation/evaluation_results/logs/fasttext/:/veld/output/2:z
        environment:
          in_model_file: m1.bin
          in_model_metadata_file: veld.yaml
          in_eval_gold_data_file: eval_data_lowercase.yaml
          out_eval_summary_file: summary.yaml
          out_eval_log_file: m1.txt
        depends_on:
          veld_train_glove:
            condition: service_completed_successfully
      veld_eval_word2vec:
        extends:
          file: ./veld_code_14_we_evaluation/veld_eval_word2vec.yaml
          service: veld_eval_word2vec
        volumes:
        - ./data_local/models/word2vec/m1/:/veld/input/1/:z
        - ./veld_data_10_we_evaluation/evaluation_gold_data/lowercase/:/veld/input/2/:z
        - ./veld_data_10_we_evaluation/evaluation_results/:/veld/output/1/:z
        - ./veld_data_10_we_evaluation/evaluation_results/logs/word2vec/:/veld/output/2:z
        environment:
          in_model_file: m1.bin
          in_model_metadata_file: veld.yaml
          in_eval_gold_data_file: eval_data_lowercase.yaml
          out_eval_summary_file: summary.yaml
          out_eval_log_file: m1.txt
        depends_on:
          veld_eval_fasttext:
            condition: service_completed_successfully
      veld_eval_glove:
        extends:
          file: ./veld_code_14_we_evaluation/veld_eval_glove.yaml
          service: veld_eval_glove
        volumes:
        - ./data_local/models/glove/m1/:/veld/input/1/:z
        - ./veld_data_10_we_evaluation/evaluation_gold_data/lowercase/:/veld/input/2/:z
        - ./veld_data_10_we_evaluation/evaluation_results/:/veld/output/1/:z
        - ./veld_data_10_we_evaluation/evaluation_results/logs/glove/:/veld/output/2/:z
        environment:
          in_vector_file: m1_vector.txt
          model_id: m1
          in_model_metadata_file: veld.yaml
          in_eval_gold_data_file: eval_data_lowercase.yaml
          out_eval_summary_file: summary.yaml
          out_eval_log_file: m1.txt
        depends_on:
          veld_eval_word2vec:
            condition: service_completed_successfully
veld_chain__train_spacy_apis_ner___veld_analysis.yaml:
  url: https://github.com/veldhub/veld_chain__train_spacy_apis_ner/blob/main/veld_analysis.yaml
  content:
    x-veld:
      chain:
        description: Analyses out-of vocabulary occurrences of training data.
        topic:
        - NLP
        - Machine Learning
        - Named Entity Recognition
        - Analysis
    services:
      veld_analysis:
        extends:
          file: ./code/analysis/compose.yaml
          service: veld_analysis
        volumes:
        - ./data/:/veld/input/
veld_chain__train_spacy_apis_ner___veld_convert.yaml:
  url: https://github.com/veldhub/veld_chain__train_spacy_apis_ner/blob/main/veld_convert.yaml
  content:
    x-veld:
      chain:
        description: Cleaning and converting json into spaCy docbin
        topic:
        - ETL
        - NLP
        - Machine Learning
    services:
      veld_convert:
        extends:
          file: ./code/veld_code__spacy/veld_convert.yaml
          service: veld_convert
        volumes:
        - ./data/veld_data__apis_oebl__ner_gold/data_cleaned_simplified/:/veld/input/
        - ./data/docbin/:/veld/output/docbin/
        - ./:/veld/output/log/
        environment:
          in_json_file: cleaned_simplified.json
          out_log_file: veld_convert.log
          model_base: de_core_news_lg
veld_chain__train_spacy_apis_ner___veld_create_config.yaml:
  url: https://github.com/veldhub/veld_chain__train_spacy_apis_ner/blob/main/veld_create_config.yaml
  content:
    x-veld:
      chain:
        description: Creates a spacy training config according to passed arguments.
          See https://spacy.io/usage/training/#config for the target outcome.
        topic:
        - NLP
        - Machine Learning
    services:
      veld_create_config:
        extends:
          file: ./code/veld_code__spacy/veld_create_config.yaml
          service: veld_create_config
        volumes:
        - ./data/configs/:/veld/output/
        environment:
          out_config_file: config_1.cfg
          lang: de
          ner: true
          optimize_accuracy: true
          pretraining: true
veld_chain__train_spacy_apis_ner___veld_publish_to_hf.yaml:
  url: https://github.com/veldhub/veld_chain__train_spacy_apis_ner/blob/main/veld_publish_to_hf.yaml
  content:
    x-veld:
      chain:
        description: Pushing spacy model to huggingface.
        topic: NLP
    services:
      veld_publish_to_hf:
        extends:
          file: ./code/veld_code__spacy/veld_publish_to_hf.yaml
          service: veld_publish_to_hf
        volumes:
        - ./data/veld_data__apis_spacy_ner_models/m1/model-best/:/veld/input/
        environment:
          model_name: m1
          version: '1.0'
veld_chain__train_spacy_apis_ner___veld_train.yaml:
  url: https://github.com/veldhub/veld_chain__train_spacy_apis_ner/blob/main/veld_train.yaml
  content:
    x-veld:
      chain:
        description: A NER trainig setup, utilizing spaCy 3's config system.
        topic:
        - NLP
        - Machine Learning
        - Named Entity Recognition
    services:
      veld_train:
        extends:
          file: ./code/veld_code__spacy/veld_train.yaml
          service: veld_train
        volumes:
        - ./data/docbin/:/veld/input/docbin/
        - ./data/configs/:/veld/input/config/
        - ./data/veld_data__apis_spacy_ner_models/m2/:/veld/output/
        environment:
          in_train_docbin_file: train.spacy
          in_dev_docbin_file: dev.spacy
          in_eval_docbin_file: eval.spacy
          in_spacy_config: config_2.cfg
          model_base: de_core_news_lg
          out_train_log_file: train.log
          out_eval_log_file: eval.log
